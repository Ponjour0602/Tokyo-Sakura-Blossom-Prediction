{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd4165c7-d2d6-48fe-8fb7-4e540ed713fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67d56aa-5464-483a-954d-c7634c178128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>年</th>\n",
       "      <th>月</th>\n",
       "      <th>日</th>\n",
       "      <th>當地氣壓</th>\n",
       "      <th>海平面氣壓</th>\n",
       "      <th>最大降水量</th>\n",
       "      <th>一小時降水量</th>\n",
       "      <th>10分鐘降水量</th>\n",
       "      <th>平均氣溫</th>\n",
       "      <th>最高氣溫</th>\n",
       "      <th>最低氣溫</th>\n",
       "      <th>平均濕度</th>\n",
       "      <th>最小濕度</th>\n",
       "      <th>日照時間</th>\n",
       "      <th>開花日</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1011.7</td>\n",
       "      <td>1012.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>41.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1020.2</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>51.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1021.3</td>\n",
       "      <td>1022.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1004.6</td>\n",
       "      <td>1005.3</td>\n",
       "      <td>20.2</td>\n",
       "      <td>13.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1016.3</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23371</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>1006.9</td>\n",
       "      <td>1009.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>12.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>51.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23372</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>1008.1</td>\n",
       "      <td>1011.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23373</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>1013.4</td>\n",
       "      <td>1016.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23374</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>1017.1</td>\n",
       "      <td>1020.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>53.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23375</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>1003.4</td>\n",
       "      <td>1006.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>55.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23376 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          年   月   日    當地氣壓   海平面氣壓  最大降水量  一小時降水量  10分鐘降水量  平均氣溫  最高氣溫  最低氣溫  \\\n",
       "0      1961   1   1  1011.7  1012.4    0.0     0.0      0.0   2.1   7.9  -3.9   \n",
       "1      1961   1   2  1020.2  1021.0    0.0     0.0      0.0   1.5   9.2  -3.3   \n",
       "2      1961   1   3  1021.3  1022.1    0.1     0.8      0.0   2.5   7.3  -2.4   \n",
       "3      1961   1   4  1004.6  1005.3   20.2    13.9      3.2   4.7  11.5   0.6   \n",
       "4      1961   1   5  1016.3  1017.0    0.0     0.0      0.0   3.8   7.7   1.4   \n",
       "...     ...  ..  ..     ...     ...    ...     ...      ...   ...   ...   ...   \n",
       "23371  2024  12  27  1006.9  1009.9    0.0     0.0      0.0   7.4  12.7   3.8   \n",
       "23372  2024  12  28  1008.1  1011.1    0.0     0.0      0.0   5.4  11.5   1.4   \n",
       "23373  2024  12  29  1013.4  1016.4    0.0     0.0      0.0   6.0  12.3   0.5   \n",
       "23374  2024  12  30  1017.1  1020.1    0.0     0.0      0.0   6.2  10.3   3.5   \n",
       "23375  2024  12  31  1003.4  1006.4    0.0     0.0      0.0   8.0  14.6   2.8   \n",
       "\n",
       "       平均濕度  最小濕度  日照時間  開花日  \n",
       "0      41.0  15.0   8.6    0  \n",
       "1      51.0  26.0   8.7    0  \n",
       "2      58.0  37.0   5.4    0  \n",
       "3      60.0  38.0   1.0    0  \n",
       "4      33.0  19.0   8.3    0  \n",
       "...     ...   ...   ...  ...  \n",
       "23371  51.0  38.0   6.1    0  \n",
       "23372  59.0  36.0   7.5    0  \n",
       "23373  54.0  31.0   8.9    0  \n",
       "23374  53.0  32.0   5.0    0  \n",
       "23375  55.0  37.0   7.6    0  \n",
       "\n",
       "[23376 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 讀資料\n",
    "df = pd.read_csv('Dataset/weather_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39c9676-dde6-478f-8bd1-115bcc9b7b1f",
   "metadata": {},
   "source": [
    "### 將年, 月, 日欄位重新命名為 year, month, day ，合併成 date 並轉為 datetime格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d58e4b0d-1fb1-47fb-ad98-b084f7a79ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新命名 年 月 日 的欄位\n",
    "df = df.rename(columns={'年': 'year', '月': 'month', '日': 'day'})\n",
    "\n",
    "# 合併為 datetime 欄位\n",
    "df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "\n",
    "# 排序\n",
    "df = df.sort_values(['year', 'month', 'day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1f6c9b-5c62-427f-945d-a7988726d1e3",
   "metadata": {},
   "source": [
    "### 選定訓練時需要的特徵值，並只取每年前120日的氣象資料當作模型的 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4ffa14-d7cd-44e8-a891-3087ff86fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 特徵挑選與目標\n",
    "feature_cols = ['當地氣壓', '海平面氣壓', '平均氣溫', '最高氣溫', '最大降水量', '平均濕度']\n",
    "\n",
    "yearly_sequences = []\n",
    "\n",
    "for year, group in df.groupby('year'):\n",
    "    # 只取該年按日期排序後的前120筆\n",
    "    sub = group.sort_values('date').iloc[:120]\n",
    "    # 取 feature_cols 對應的欄位\n",
    "    if len(sub) == 120:  # 避免資料天數不足\n",
    "        yearly_sequences.append(sub[feature_cols].to_numpy())\n",
    "    else:\n",
    "        print(f'⚠️ {year} 年資料不足120天，已略過')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d0d260-1e57-4871-8dff-5044a127754e",
   "metadata": {},
   "source": [
    "### 將每年開花所需的日數當作模型的 y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f0c634b-019e-4264-932e-4bb61e14b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = np.stack(yearly_sequences)  # shape=(年數, 120, 特徵數)\n",
    "y = []\n",
    "for year, group in df.groupby('year'):\n",
    "    # 排序後的資料\n",
    "    group_sorted = group.sort_values('date')\n",
    "    # 找到開花日=1的那一行\n",
    "    bloom_rows = group_sorted[group_sorted['開花日'] == 1]\n",
    "    if len(bloom_rows) > 0:\n",
    "        # 計算開花日是該年的第幾天 (0-based)\n",
    "        first_date = group_sorted['date'].iloc[0]\n",
    "        bloom_date = bloom_rows['date'].iloc[0]\n",
    "        days_diff = (bloom_date - first_date).days\n",
    "        y.append(days_diff)\n",
    "    else:\n",
    "        print(f\"警告: {year}年沒有開花日記錄\")\n",
    "        # 跳過這一年的資料\n",
    "# y 已經是一個 list，長度等於 yearly_sequences\n",
    "y_np = np.array(y)   # shape=(年數, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56994de1-f8ef-4893-90a8-925baefff414",
   "metadata": {},
   "source": [
    "### 將 X 標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a93914-9d41-4c07-a0a3-5a52fe006d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假設 X_np.shape = (年數, 120, 6)\n",
    "X_flat = X_np.reshape((X_np.shape[0], -1))\n",
    "\n",
    "# 對每個特徵單獨標準化\n",
    "X_scaled = np.zeros_like(X_np)\n",
    "for i in range(X_np.shape[2]):  # 遍歷6個特徵\n",
    "    feature_data = X_np[:, :, i]  # (年數, 120)\n",
    "    scaler = StandardScaler()\n",
    "    # 將所有年份的該特徵數據平攤用於擬合scaler\n",
    "    scaler.fit(feature_data.reshape(-1, 1))\n",
    "    # 對每年的該特徵進行轉換\n",
    "    for j in range(X_np.shape[0]):  # 遍歷每一年\n",
    "        X_scaled[j, :, i] = scaler.transform(X_np[j, :, i].reshape(-1, 1)).flatten()\n",
    "\n",
    "# 然後再平攤用於模型輸入\n",
    "X_flat_scaled = X_scaled.reshape((X_scaled.shape[0], -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c03e3d0-7a2e-4cfd-812f-a6af61e24f7c",
   "metadata": {},
   "source": [
    "### 將 X, y 以 8:2 年代前後順序做切分訓練集與測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90048689-896e-4d65-b192-e939ee1f5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時間順序分割 (最後20%作為測試集)\n",
    "split_index = int(0.8 * len(X_flat_scaled))\n",
    "X_train, X_test = X_flat_scaled[:split_index], X_flat_scaled[split_index:]\n",
    "y_train, y_test = y_np[:split_index], y_np[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfb7fb6f-f625-48ec-aeb7-275f0f625c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轉換為張量\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c924906-a7e3-4b1f-822a-2ab2bbb0b64c",
   "metadata": {},
   "source": [
    "### 設定random seed（50）\n",
    "### 建立MLP模型：3 of Fully Connected Layers、Loss：MSE、Adam Optimizer、early stop\n",
    "### 設定網格搜索：hidden state, learning rate, weight Decay, Dropout Rate, Batch Size, Patience\n",
    "### 使用 R^2 評估模型\n",
    "### Loss 數據視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7547bba5-233d-44fb-bdba-119bd4993def",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始網格搜索 - 總共 1296 種參數組合\n",
      "\n",
      "組合 1/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5920, 訓練了 297 epochs\n",
      "  目前最佳 RMSE: 4.5920\n",
      "\n",
      "組合 2/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4266, 訓練了 320 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 3/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4266, 訓練了 325 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 4/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5464, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 5/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5464, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 6/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5464, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 7/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 40.5061, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 8/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 40.5061, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 9/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 40.5061, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 10/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 75.0155, 訓練了 386 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 11/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 71.9676, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 12/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 71.9676, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 13/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2773, 訓練了 327 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 14/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7201, 訓練了 378 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 15/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7201, 訓練了 383 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 16/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.4441, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 17/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.4441, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 18/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.4441, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 19/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 54.4503, 訓練了 367 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 20/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 54.4503, 訓練了 372 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 21/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 54.4503, 訓練了 377 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 22/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 75.7999, 訓練了 350 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 23/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 75.7999, 訓練了 355 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 24/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 72.9246, 訓練了 478 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 25/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0744, 訓練了 285 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 26/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0744, 訓練了 290 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 27/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5699, 訓練了 371 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 28/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 15.1040, 訓練了 431 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 29/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0902, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 30/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0902, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 31/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 48.1465, 訓練了 447 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 32/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 42.1725, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 33/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 42.1725, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 34/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 74.5568, 訓練了 379 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 35/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 71.2397, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 36/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 71.2397, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 37/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0531, 訓練了 322 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 38/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0531, 訓練了 327 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 39/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0531, 訓練了 332 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 40/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3759, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 41/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3759, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 42/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3759, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 43/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 53.0573, 訓練了 413 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 44/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 44.1794, 訓練了 495 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 45/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 42.8292, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 46/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 75.2145, 訓練了 385 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 47/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 72.1963, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 48/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 72.1963, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.4266\n",
      "\n",
      "組合 49/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.5597, 訓練了 343 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 50/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.5597, 訓練了 348 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 51/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.5597, 訓練了 353 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 52/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0512, 訓練了 498 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 53/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0512, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 54/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0512, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 55/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 56.1820, 訓練了 348 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 56/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 54.3162, 訓練了 372 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 57/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 54.3162, 訓練了 377 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 58/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 75.3133, 訓練了 350 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 59/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 75.3133, 訓練了 355 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 60/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 71.6889, 訓練了 478 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 61/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.7058, 訓練了 323 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 62/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.7058, 訓練了 328 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 63/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.7058, 訓練了 333 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 64/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.4243, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 65/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.4243, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 66/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.4243, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 67/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 46.1302, 訓練了 471 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 68/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 41.0413, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 69/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 41.0413, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 70/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 74.5482, 訓練了 379 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 71/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 74.5482, 訓練了 384 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 72/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 74.5482, 訓練了 389 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 73/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2532, 訓練了 316 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 74/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2532, 訓練了 321 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 75/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2532, 訓練了 326 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 76/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2850, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 77/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2850, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 78/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2850, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 79/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 61.9900, 訓練了 329 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 80/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 40.8568, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 81/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 40.8568, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 82/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 75.1756, 訓練了 386 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 83/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 72.5823, 訓練了 481 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 84/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 71.8662, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 85/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2334, 訓練了 332 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 86/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2334, 訓練了 337 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 87/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2334, 訓練了 342 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 88/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 27.0029, 訓練了 367 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 89/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.3485, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 90/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.3485, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 91/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 59.6627, 訓練了 329 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 92/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 40.3410, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 93/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 40.3410, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 94/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 75.8008, 訓練了 350 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 95/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 75.8008, 訓練了 355 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 96/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 72.9226, 訓練了 478 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 97/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1019, 訓練了 316 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 98/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1019, 訓練了 321 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 99/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8803, 訓練了 350 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 100/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.0143, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 101/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.0143, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 102/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.0143, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 103/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 59.3103, 訓練了 329 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 104/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 38.0322, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 105/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 38.0322, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 106/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 75.2195, 訓練了 349 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 107/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 70.9840, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 108/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 70.9840, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 109/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3875, 訓練了 200 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 110/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3875, 訓練了 205 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 111/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0889, 訓練了 231 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 112/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1835, 訓練了 258 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 113/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1835, 訓練了 263 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 114/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1835, 訓練了 268 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 115/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0257, 訓練了 433 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 116/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0257, 訓練了 438 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 117/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0257, 訓練了 443 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 118/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 46.1985, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 119/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 46.1985, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 120/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 46.1985, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 121/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.5618, 訓練了 185 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 122/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.5618, 訓練了 190 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 123/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.5618, 訓練了 195 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 124/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1896, 訓練了 280 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 125/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1896, 訓練了 285 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 126/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1896, 訓練了 290 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 127/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4570, 訓練了 471 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 128/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4570, 訓練了 476 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 129/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4570, 訓練了 481 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 130/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 45.0415, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 131/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 45.0415, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 132/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 45.0415, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 133/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1378, 訓練了 167 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 134/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1378, 訓練了 172 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 135/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1378, 訓練了 177 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 136/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.5999, 訓練了 259 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 137/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.5999, 訓練了 264 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 138/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2268, 訓練了 293 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 139/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7130, 訓練了 458 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 140/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7130, 訓練了 463 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 141/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7130, 訓練了 468 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 142/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 59.9119, 訓練了 386 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 143/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 59.9119, 訓練了 391 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 144/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 48.1471, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 145/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.8147, 訓練了 179 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 146/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.8147, 訓練了 184 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 147/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.8147, 訓練了 189 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 148/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2479, 訓練了 261 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 149/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2479, 訓練了 266 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 150/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7813, 訓練了 292 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 151/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4179, 訓練了 434 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 152/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4179, 訓練了 439 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 153/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4179, 訓練了 444 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 154/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 46.2498, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 155/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 46.2498, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 156/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 46.2498, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 157/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0814, 訓練了 181 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 158/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0814, 訓練了 186 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 159/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0814, 訓練了 191 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 160/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2119, 訓練了 278 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 161/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2119, 訓練了 283 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 162/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2119, 訓練了 288 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 163/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.7839, 訓練了 408 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 164/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2255, 訓練了 494 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 165/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2255, 訓練了 499 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 166/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 45.0778, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 167/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 45.0778, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 168/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 45.0778, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 169/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7518, 訓練了 164 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 170/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7518, 訓練了 169 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 171/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7518, 訓練了 174 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 172/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2689, 訓練了 283 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 173/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2689, 訓練了 288 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 174/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2689, 訓練了 293 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 175/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0255, 訓練了 413 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 176/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1752, 訓練了 439 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 177/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8862, 訓練了 468 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 178/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 59.9584, 訓練了 386 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 179/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 59.9584, 訓練了 391 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 180/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 48.0958, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 181/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7806, 訓練了 159 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 182/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5639, 訓練了 184 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 183/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5639, 訓練了 189 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 184/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9107, 訓練了 271 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 185/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9107, 訓練了 276 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 186/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9107, 訓練了 281 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 187/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2038, 訓練了 453 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 188/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2038, 訓練了 458 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 189/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2038, 訓練了 463 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 190/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 46.3627, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 191/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 46.3627, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 192/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 46.3627, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 193/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0395, 訓練了 186 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 194/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0395, 訓練了 191 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 195/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0395, 訓練了 196 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 196/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2811, 訓練了 257 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 197/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2811, 訓練了 262 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 198/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2811, 訓練了 267 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 199/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.8120, 訓練了 425 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 200/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6334, 訓練了 473 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 201/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6334, 訓練了 478 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 202/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 44.7732, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 203/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 44.7732, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 204/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 44.7732, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 205/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8317, 訓練了 207 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 206/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8317, 訓練了 212 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 207/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8317, 訓練了 217 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 208/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6562, 訓練了 271 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 209/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6562, 訓練了 276 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 210/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6562, 訓練了 281 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 211/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 13.4035, 訓練了 367 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 212/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1410, 訓練了 475 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 213/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1410, 訓練了 480 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 214/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 74.3041, 訓練了 224 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 215/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 51.5334, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 216/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 51.5334, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 217/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.9561, 訓練了 78 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 218/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.9561, 訓練了 83 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 219/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.9561, 訓練了 88 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 220/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7563, 訓練了 105 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 221/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7563, 訓練了 110 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 222/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7563, 訓練了 115 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 223/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5852, 訓練了 170 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 224/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5852, 訓練了 175 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 225/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5852, 訓練了 180 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 226/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3542, 訓練了 361 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 227/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3542, 訓練了 366 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 228/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3542, 訓練了 371 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 229/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9830, 訓練了 71 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 230/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9830, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 231/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9830, 訓練了 81 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 232/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0552, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 233/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0552, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 234/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0552, 訓練了 112 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 235/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5811, 訓練了 171 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 236/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5811, 訓練了 176 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 237/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5811, 訓練了 181 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 238/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.8567, 訓練了 328 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 239/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.8567, 訓練了 333 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 240/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.8567, 訓練了 338 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 241/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7339, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 242/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7339, 訓練了 78 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 243/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7339, 訓練了 83 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 244/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5486, 訓練了 109 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 245/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5486, 訓練了 114 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 246/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5486, 訓練了 119 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 247/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8796, 訓練了 183 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 248/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8796, 訓練了 188 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 249/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4515, 訓練了 218 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 250/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.9688, 訓練了 324 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 251/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.9688, 訓練了 329 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 252/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.9688, 訓練了 334 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 253/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0614, 訓練了 61 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 254/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0614, 訓練了 66 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 255/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0614, 訓練了 71 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 256/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3392, 訓練了 111 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 257/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3392, 訓練了 116 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 258/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3392, 訓練了 121 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 259/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3940, 訓練了 168 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 260/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3940, 訓練了 173 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 261/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3940, 訓練了 178 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 262/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3578, 訓練了 361 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 263/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3578, 訓練了 366 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 264/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3578, 訓練了 371 epochs\n",
      "  目前最佳 RMSE: 3.5597\n",
      "\n",
      "組合 265/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.1171, 訓練了 62 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 266/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.1171, 訓練了 67 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 267/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.1171, 訓練了 72 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 268/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9571, 訓練了 108 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 269/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9571, 訓練了 113 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 270/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9571, 訓練了 118 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 271/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0536, 訓練了 155 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 272/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0536, 訓練了 160 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 273/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0536, 訓練了 165 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 274/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.8681, 訓練了 328 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 275/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.8681, 訓練了 333 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 276/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.8681, 訓練了 338 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 277/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7921, 訓練了 81 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 278/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7921, 訓練了 86 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 279/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7921, 訓練了 91 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 280/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6278, 訓練了 99 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 281/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6278, 訓練了 104 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 282/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6278, 訓練了 109 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 283/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1076, 訓練了 169 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 284/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1076, 訓練了 174 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 285/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1076, 訓練了 179 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 286/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.9665, 訓練了 325 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 287/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.9665, 訓練了 330 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 288/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.9665, 訓練了 335 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 289/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3672, 訓練了 65 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 290/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3672, 訓練了 70 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 291/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3672, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 292/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4326, 訓練了 114 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 293/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4326, 訓練了 119 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 294/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4326, 訓練了 124 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 295/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4216, 訓練了 157 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 296/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4216, 訓練了 162 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 297/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4216, 訓練了 167 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 298/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5816, 訓練了 341 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 299/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5816, 訓練了 346 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 300/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5816, 訓練了 351 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 301/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.8052, 訓練了 63 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 302/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.8052, 訓練了 68 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 303/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.8052, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 304/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0503, 訓練了 103 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 305/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0503, 訓練了 108 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 306/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0503, 訓練了 113 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 307/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0695, 訓練了 166 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 308/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0695, 訓練了 171 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 309/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0695, 訓練了 176 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 310/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5304, 訓練了 336 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 311/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5304, 訓練了 341 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 312/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5304, 訓練了 346 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 313/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4121, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 314/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4121, 訓練了 106 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 315/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4121, 訓練了 111 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 316/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8003, 訓練了 94 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 317/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8003, 訓練了 99 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 318/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8003, 訓練了 104 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 319/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3001, 訓練了 173 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 320/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3001, 訓練了 178 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 321/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3001, 訓練了 183 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 322/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.6522, 訓練了 309 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 323/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.6522, 訓練了 314 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 324/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.6522, 訓練了 319 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 325/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2881, 訓練了 255 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 326/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2881, 訓練了 260 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 327/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2881, 訓練了 265 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 328/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4144, 訓練了 357 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 329/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4144, 訓練了 362 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 330/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4144, 訓練了 367 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 331/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 51.9256, 訓練了 301 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 332/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 17.8176, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 333/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 17.8176, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 334/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 78.9087, 訓練了 16 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 335/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 64.3757, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 336/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 64.3757, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 337/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0162, 訓練了 220 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 338/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0162, 訓練了 225 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 339/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0162, 訓練了 230 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 340/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0693, 訓練了 394 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 341/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0693, 訓練了 399 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 342/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0693, 訓練了 404 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 343/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 34.3669, 訓練了 397 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 344/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 14.1989, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 345/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 14.1989, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 346/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 78.9066, 訓練了 16 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 347/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 69.0566, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 348/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 69.0566, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 349/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6542, 訓練了 252 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 350/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5906, 訓練了 286 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 351/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5906, 訓練了 291 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 352/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1788, 訓練了 372 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 353/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1788, 訓練了 377 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 354/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0489, 訓練了 425 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 355/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 53.7569, 訓練了 301 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 356/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 19.8966, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 357/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 19.8966, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 358/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 78.9121, 訓練了 16 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 359/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 78.9121, 訓練了 21 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 360/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 66.9378, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 361/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9156, 訓練了 263 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 362/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9156, 訓練了 268 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 363/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9156, 訓練了 273 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 364/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.6392, 訓練了 345 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 365/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2855, 訓練了 397 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 366/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2855, 訓練了 402 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 367/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 16.6545, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 368/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 16.6545, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 369/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 16.6545, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 370/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 78.9086, 訓練了 16 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 371/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 64.8039, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 372/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 64.8039, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 373/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.7271, 訓練了 268 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 374/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.7271, 訓練了 273 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 375/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.7271, 訓練了 278 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 376/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.6528, 訓練了 382 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 377/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.6528, 訓練了 387 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 378/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.6528, 訓練了 392 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 379/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 15.5747, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 380/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 15.5747, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 381/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 15.5747, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 382/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 78.9061, 訓練了 16 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 383/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 68.9438, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 384/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 68.9438, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 385/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6651, 訓練了 234 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 386/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0054, 訓練了 298 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 387/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0054, 訓練了 303 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 388/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.1268, 訓練了 409 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 389/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1268, 訓練了 414 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 390/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1268, 訓練了 419 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 391/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 19.5440, 訓練了 491 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 392/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 16.1243, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 393/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 16.1243, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 394/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 78.9119, 訓練了 16 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 395/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 78.9119, 訓練了 21 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 396/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 66.9387, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 397/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1432, 訓練了 241 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 398/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1432, 訓練了 246 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 399/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1432, 訓練了 251 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 400/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1380, 訓練了 391 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 401/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1380, 訓練了 396 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 402/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1380, 訓練了 401 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 403/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 19.2844, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 404/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 19.2844, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 405/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 19.2844, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 406/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 78.9079, 訓練了 16 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 407/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 64.5989, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 408/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 64.5989, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 409/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.5419, 訓練了 247 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 410/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.5419, 訓練了 252 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 411/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.5419, 訓練了 257 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 412/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.4771, 訓練了 385 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 413/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.4771, 訓練了 390 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 414/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.4771, 訓練了 395 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 415/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 17.5002, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 416/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 17.5002, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 417/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 17.5002, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 418/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 78.9060, 訓練了 16 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 419/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 72.9444, 訓練了 402 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 420/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 68.9315, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 421/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.7576, 訓練了 267 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 422/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.7576, 訓練了 272 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 423/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.7576, 訓練了 277 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 424/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.9140, 訓練了 424 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 425/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.9140, 訓練了 429 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 426/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.9140, 訓練了 434 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 427/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 22.0716, 訓練了 489 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 428/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 22.0716, 訓練了 494 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 429/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 19.1661, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 430/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 78.9117, 訓練了 16 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 431/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 78.9117, 訓練了 21 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 432/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 68.2588, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 433/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3229, 訓練了 131 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 434/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3229, 訓練了 136 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 435/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3229, 訓練了 141 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 436/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.9399, 訓練了 205 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 437/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.9399, 訓練了 210 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 438/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.9399, 訓練了 215 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 439/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2003, 訓練了 306 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 440/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2003, 訓練了 311 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 441/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2003, 訓練了 316 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 442/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 28.9861, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 443/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 28.9861, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 444/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 28.9861, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 445/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.8769, 訓練了 147 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 446/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.8769, 訓練了 152 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 447/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.8769, 訓練了 157 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 448/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4572, 訓練了 193 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 449/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4572, 訓練了 198 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 450/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4572, 訓練了 203 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 451/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.1007, 訓練了 301 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 452/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7546, 訓練了 376 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 453/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7546, 訓練了 381 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 454/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 31.0349, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 455/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 31.0349, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 456/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 31.0349, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 457/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9570, 訓練了 124 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 458/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9570, 訓練了 129 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 459/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9570, 訓練了 134 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 460/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4908, 訓練了 199 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 461/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4908, 訓練了 204 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 462/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4908, 訓練了 209 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 463/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0789, 訓練了 331 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 464/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0789, 訓練了 336 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 465/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0789, 訓練了 341 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 466/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 29.0918, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 467/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 29.0918, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 468/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 29.0918, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 469/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7107, 訓練了 122 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 470/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7107, 訓練了 127 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 471/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7107, 訓練了 132 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 472/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9338, 訓練了 194 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 473/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9338, 訓練了 199 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 474/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7601, 訓練了 226 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 475/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.8158, 訓練了 309 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 476/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.8158, 訓練了 314 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 477/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.8158, 訓練了 319 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 478/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 28.0958, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 479/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 28.0958, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 480/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 28.0958, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 481/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6137, 訓練了 136 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 482/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6137, 訓練了 141 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 483/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6137, 訓練了 146 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 484/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2598, 訓練了 195 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 485/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2598, 訓練了 200 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 486/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2598, 訓練了 205 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 487/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.9183, 訓練了 356 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 488/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.9183, 訓練了 361 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 489/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.9183, 訓練了 366 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 490/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 31.3563, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 491/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 31.3563, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 492/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 31.3563, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 493/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4421, 訓練了 135 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 494/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4421, 訓練了 140 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 495/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4421, 訓練了 145 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 496/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9547, 訓練了 185 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 497/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9547, 訓練了 190 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 498/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9547, 訓練了 195 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 499/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0619, 訓練了 318 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 500/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0619, 訓練了 323 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 501/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0393, 訓練了 368 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 502/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 31.1967, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 503/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 31.1967, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 504/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 31.1967, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 505/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0165, 訓練了 140 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 506/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0165, 訓練了 145 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 507/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0165, 訓練了 150 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 508/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3405, 訓練了 199 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 509/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3405, 訓練了 204 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 510/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3405, 訓練了 209 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 511/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1383, 訓練了 363 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 512/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1383, 訓練了 368 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 513/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1383, 訓練了 373 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 514/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 30.0046, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 515/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 30.0046, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 516/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 30.0046, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 517/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.8599, 訓練了 147 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 518/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.8599, 訓練了 152 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 519/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.8599, 訓練了 157 epochs\n",
      "  目前最佳 RMSE: 3.1171\n",
      "\n",
      "組合 520/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 2.9084, 訓練了 243 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 521/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 2.9084, 訓練了 248 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 522/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 2.9084, 訓練了 253 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 523/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.6615, 訓練了 340 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 524/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.6615, 訓練了 345 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 525/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.6615, 訓練了 350 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 526/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 34.2385, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 527/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 34.2385, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 528/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 34.2385, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 529/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9902, 訓練了 124 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 530/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9902, 訓練了 129 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 531/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9902, 訓練了 134 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 532/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1453, 訓練了 214 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 533/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1453, 訓練了 219 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 534/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1453, 訓練了 224 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 535/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 13.1554, 訓練了 280 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 536/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.7484, 訓練了 323 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 537/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.7484, 訓練了 328 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 538/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 60.0707, 訓練了 322 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 539/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 31.2724, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 540/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 31.2724, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 541/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5667, 訓練了 45 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 542/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5667, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 543/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5667, 訓練了 55 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 544/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6330, 訓練了 77 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 545/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6330, 訓練了 82 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 546/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6330, 訓練了 87 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 547/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9548, 訓練了 120 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 548/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9548, 訓練了 125 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 549/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9548, 訓練了 130 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 550/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5708, 訓練了 266 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 551/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5708, 訓練了 271 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 552/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5708, 訓練了 276 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 553/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.8204, 訓練了 56 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 554/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.8204, 訓練了 61 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 555/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.8204, 訓練了 66 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 556/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.1249, 訓練了 77 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 557/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.1249, 訓練了 82 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 558/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.1249, 訓練了 87 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 559/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8754, 訓練了 121 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 560/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8754, 訓練了 126 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 561/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8754, 訓練了 131 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 562/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2920, 訓練了 232 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 563/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2920, 訓練了 237 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 564/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2920, 訓練了 242 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 565/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6369, 訓練了 54 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 566/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6369, 訓練了 59 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 567/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6369, 訓練了 64 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 568/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4843, 訓練了 86 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 569/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4843, 訓練了 91 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 570/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4843, 訓練了 96 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 571/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4424, 訓練了 122 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 572/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4424, 訓練了 127 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 573/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4424, 訓練了 132 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 574/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9260, 訓練了 257 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 575/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9260, 訓練了 262 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 576/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9260, 訓練了 267 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 577/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6975, 訓練了 49 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 578/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6975, 訓練了 54 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 579/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6975, 訓練了 59 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 580/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0751, 訓練了 83 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 581/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0751, 訓練了 88 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 582/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0751, 訓練了 93 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 583/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.0001, 訓練了 129 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 584/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.4523, 訓練了 155 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 585/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.4523, 訓練了 160 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 586/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.4812, 訓練了 261 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 587/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.4812, 訓練了 266 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 588/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.4812, 訓練了 271 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 589/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6884, 訓練了 64 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 590/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0337, 訓練了 98 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 591/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0337, 訓練了 103 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 592/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0341, 訓練了 70 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 593/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0341, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 594/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0341, 訓練了 80 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 595/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.7510, 訓練了 108 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 596/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.7510, 訓練了 113 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 597/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.7510, 訓練了 118 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 598/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2972, 訓練了 232 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 599/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2972, 訓練了 237 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 600/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2972, 訓練了 242 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 601/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.9033, 訓練了 70 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 602/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.9033, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 603/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.9033, 訓練了 80 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 604/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7588, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 605/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7588, 訓練了 81 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 606/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7588, 訓練了 86 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 607/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5319, 訓練了 146 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 608/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5319, 訓練了 151 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 609/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5319, 訓練了 156 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 610/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9290, 訓練了 257 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 611/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9290, 訓練了 262 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 612/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9290, 訓練了 267 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 613/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0506, 訓練了 48 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 614/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0506, 訓練了 53 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 615/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0506, 訓練了 58 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 616/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2456, 訓練了 71 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 617/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2456, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 618/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2456, 訓練了 81 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 619/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.4067, 訓練了 135 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 620/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.4067, 訓練了 140 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 621/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.4067, 訓練了 145 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 622/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9478, 訓練了 244 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 623/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9478, 訓練了 249 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 624/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9478, 訓練了 254 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 625/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5590, 訓練了 52 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 626/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5590, 訓練了 57 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 627/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5590, 訓練了 62 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 628/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7975, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 629/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7975, 訓練了 80 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 630/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7975, 訓練了 85 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 631/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3462, 訓練了 112 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 632/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3462, 訓練了 117 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 633/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3462, 訓練了 122 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 634/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2811, 訓練了 239 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 635/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2811, 訓練了 244 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 636/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2811, 訓練了 249 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 637/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7561, 訓練了 52 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 638/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3023, 訓練了 88 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 639/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3023, 訓練了 93 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 640/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8845, 訓練了 82 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 641/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8845, 訓練了 87 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 642/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8845, 訓練了 92 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 643/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0074, 訓練了 119 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 644/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0074, 訓練了 124 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 645/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0074, 訓練了 129 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 646/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.4834, 訓練了 250 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 647/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.4834, 訓練了 255 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 648/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.4834, 訓練了 260 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 649/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5520, 訓練了 177 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 650/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5520, 訓練了 182 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 651/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5520, 訓練了 187 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 652/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1103, 訓練了 269 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 653/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1103, 訓練了 274 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 654/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6454, 訓練了 304 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 655/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2563, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 656/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2563, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 657/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2563, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 658/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 51.0091, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 659/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 51.0091, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 660/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 51.0091, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 661/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7593, 訓練了 168 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 662/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0951, 訓練了 216 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 663/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0951, 訓練了 221 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 664/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0617, 訓練了 283 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 665/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0617, 訓練了 288 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 666/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0617, 訓練了 293 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 667/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 65.1954, 訓練了 182 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 668/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.6710, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 669/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.6710, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 670/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 76.7728, 訓練了 168 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 671/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 76.7728, 訓練了 173 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 672/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 58.0638, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 673/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.4023, 訓練了 256 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 674/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.4023, 訓練了 261 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 675/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.4023, 訓練了 266 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 676/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4976, 訓練了 269 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 677/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4976, 訓練了 274 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 678/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4976, 訓練了 279 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 679/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3934, 訓練了 425 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 680/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.4581, 訓練了 481 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 681/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.4581, 訓練了 486 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 682/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 74.5888, 訓練了 229 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 683/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 74.5888, 訓練了 234 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 684/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 60.1975, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 685/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3616, 訓練了 185 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 686/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3616, 訓練了 190 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 687/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3616, 訓練了 195 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 688/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3391, 訓練了 256 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 689/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3391, 訓練了 261 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 690/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3391, 訓練了 266 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 691/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1369, 訓練了 464 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 692/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1369, 訓練了 469 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 693/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1369, 訓練了 474 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 694/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 49.5554, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 695/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 49.5554, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 696/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 49.5554, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 697/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2605, 訓練了 211 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 698/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2605, 訓練了 216 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 699/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2605, 訓練了 221 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 700/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7541, 訓練了 286 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 701/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6384, 訓練了 310 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 702/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6384, 訓練了 315 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 703/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 9.3832, 訓練了 470 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 704/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 9.3832, 訓練了 475 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 705/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.9656, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 706/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 76.7853, 訓練了 168 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 707/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 74.4553, 訓練了 234 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 708/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 57.6632, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 709/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8087, 訓練了 199 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 710/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8087, 訓練了 204 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 711/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8087, 訓練了 209 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 712/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0236, 訓練了 294 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 713/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0236, 訓練了 299 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 714/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0236, 訓練了 304 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 715/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.1286, 訓練了 445 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 716/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0544, 訓練了 468 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 717/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0544, 訓練了 473 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 718/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 74.5820, 訓練了 229 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 719/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 74.5820, 訓練了 234 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 720/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 60.1587, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 721/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.6427, 訓練了 191 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 722/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.1963, 訓練了 212 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 723/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.1963, 訓練了 217 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 724/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.4182, 訓練了 255 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 725/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.4182, 訓練了 260 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 726/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.4182, 訓練了 265 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 727/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5989, 訓練了 477 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 728/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5989, 訓練了 482 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 729/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.4500, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 730/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 49.5945, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 731/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 49.5945, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 732/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 49.5945, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 733/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6648, 訓練了 176 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 734/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.6843, 訓練了 207 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 735/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.6843, 訓練了 212 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 736/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.6927, 訓練了 256 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 737/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.6927, 訓練了 261 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 738/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.6927, 訓練了 266 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 739/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 22.0752, 訓練了 373 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 740/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9464, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 741/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9464, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 742/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 74.4350, 訓練了 229 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 743/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 74.4350, 訓練了 234 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 744/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 74.4350, 訓練了 239 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 745/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.6211, 訓練了 201 epochs\n",
      "  目前最佳 RMSE: 2.9084\n",
      "\n",
      "組合 746/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 2.8442, 訓練了 233 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 747/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 2.8442, 訓練了 238 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 748/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.5044, 訓練了 289 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 749/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.5044, 訓練了 294 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 750/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.5044, 訓練了 299 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 751/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.4401, 訓練了 448 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 752/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2971, 訓練了 490 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 753/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2971, 訓練了 495 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 754/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 74.4288, 訓練了 229 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 755/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 74.4288, 訓練了 234 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 756/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 59.0896, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 757/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3046, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 758/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3046, 訓練了 106 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 759/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3046, 訓練了 111 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 760/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3828, 訓練了 146 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 761/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3828, 訓練了 151 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 762/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3828, 訓練了 156 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 763/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.8900, 訓練了 268 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 764/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.8900, 訓練了 273 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 765/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.8900, 訓練了 278 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 766/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.0033, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 767/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.0033, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 768/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.0033, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 769/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.4944, 訓練了 92 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 770/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.4944, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 771/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.4944, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 772/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5106, 訓練了 142 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 773/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5106, 訓練了 147 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 774/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5106, 訓練了 152 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 775/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.9159, 訓練了 224 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 776/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.9159, 訓練了 229 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 777/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.9159, 訓練了 234 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 778/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 22.4987, 訓練了 463 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 779/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 17.2210, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 780/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 17.2210, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 781/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.7469, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 782/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.7469, 訓練了 106 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 783/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.7469, 訓練了 111 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 784/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9932, 訓練了 137 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 785/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9932, 訓練了 142 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 786/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9932, 訓練了 147 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 787/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.2801, 訓練了 228 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 788/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.2801, 訓練了 233 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 789/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.4057, 訓練了 261 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 790/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 31.7010, 訓練了 447 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 791/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 23.2473, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 792/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 23.2473, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 793/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8123, 訓練了 113 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 794/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8123, 訓練了 118 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 795/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8123, 訓練了 123 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 796/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5392, 訓練了 141 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 797/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5392, 訓練了 146 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 798/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5392, 訓練了 151 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 799/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.1748, 訓練了 269 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 800/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1748, 訓練了 274 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 801/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1748, 訓練了 279 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 802/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2828, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 803/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2828, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 804/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2828, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 805/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1526, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 806/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1526, 訓練了 112 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 807/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.7353, 訓練了 162 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 808/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3021, 訓練了 150 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 809/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3021, 訓練了 155 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 810/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3021, 訓練了 160 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 811/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.8818, 訓練了 228 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 812/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.8818, 訓練了 233 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 813/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.8818, 訓練了 238 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 814/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 16.4819, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 815/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 16.4819, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 816/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 16.4819, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 817/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1903, 訓練了 94 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 818/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1903, 訓練了 99 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 819/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1820, 訓練了 150 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 820/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.8401, 訓練了 154 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 821/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.8401, 訓練了 159 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 822/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.8401, 訓練了 164 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 823/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5737, 訓練了 245 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 824/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5737, 訓練了 250 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 825/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5737, 訓練了 255 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 826/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 25.3655, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 827/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 25.3655, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 828/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 25.3655, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 829/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0226, 訓練了 115 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 830/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0226, 訓練了 120 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 831/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0226, 訓練了 125 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 832/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2554, 訓練了 137 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 833/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2554, 訓練了 142 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 834/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2554, 訓練了 147 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 835/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9718, 訓練了 256 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 836/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9718, 訓練了 261 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 837/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9718, 訓練了 266 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 838/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.9981, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 839/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.9981, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 840/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.9981, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 841/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.5482, 訓練了 99 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 842/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.5482, 訓練了 104 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 843/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.0707, 訓練了 151 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 844/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.9828, 訓練了 148 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 845/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.9828, 訓練了 153 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 846/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.9828, 訓練了 158 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 847/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8191, 訓練了 240 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 848/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8191, 訓練了 245 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 849/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8191, 訓練了 250 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 850/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 36.2738, 訓練了 373 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 851/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 36.2738, 訓練了 378 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 852/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 17.5469, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 853/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.5915, 訓練了 95 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 854/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.5915, 訓練了 100 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 855/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.5915, 訓練了 105 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 856/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3347, 訓練了 138 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 857/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3347, 訓練了 143 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 858/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3347, 訓練了 148 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 859/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0335, 訓練了 233 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 860/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9002, 訓練了 256 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 861/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9002, 訓練了 261 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 862/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 65.2238, 訓練了 229 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 863/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 20.2023, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 864/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 20.2023, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 865/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0439, 訓練了 40 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 866/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0439, 訓練了 45 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 867/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0439, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 868/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2200, 訓練了 56 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 869/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2200, 訓練了 61 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 870/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2200, 訓練了 66 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 871/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9072, 訓練了 111 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 872/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9072, 訓練了 116 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 873/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9072, 訓練了 121 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 874/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9568, 訓練了 196 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 875/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9568, 訓練了 201 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 876/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9568, 訓練了 206 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 877/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2872, 訓練了 42 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 878/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2872, 訓練了 47 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 879/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2872, 訓練了 52 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 880/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5361, 訓練了 61 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 881/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5361, 訓練了 66 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 882/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5361, 訓練了 71 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 883/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.7855, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 884/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.7855, 訓練了 106 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 885/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.7855, 訓練了 111 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 886/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5243, 訓練了 197 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 887/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5243, 訓練了 202 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 888/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5243, 訓練了 207 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 889/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5035, 訓練了 43 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 890/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5035, 訓練了 48 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 891/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5035, 訓練了 53 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 892/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5665, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 893/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5665, 訓練了 80 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 894/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5665, 訓練了 85 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 895/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4626, 訓練了 88 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 896/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4626, 訓練了 93 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 897/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4626, 訓練了 98 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 898/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.4844, 訓練了 236 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 899/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.4844, 訓練了 241 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 900/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.4844, 訓練了 246 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 901/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3500, 訓練了 40 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 902/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3500, 訓練了 45 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 903/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3500, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 904/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0819, 訓練了 67 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 905/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0819, 訓練了 72 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 906/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0819, 訓練了 77 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 907/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2361, 訓練了 132 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 908/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2361, 訓練了 137 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 909/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2361, 訓練了 142 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 910/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6432, 訓練了 196 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 911/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6432, 訓練了 201 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 912/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6432, 訓練了 206 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 913/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.5153, 訓練了 58 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 914/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.5153, 訓練了 63 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 915/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.5153, 訓練了 68 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 916/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0378, 訓練了 57 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 917/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0378, 訓練了 62 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 918/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0378, 訓練了 67 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 919/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8057, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 920/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8057, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 921/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8057, 訓練了 112 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 922/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5378, 訓練了 197 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 923/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5378, 訓練了 202 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 924/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5378, 訓練了 207 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 925/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2987, 訓練了 125 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 926/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2987, 訓練了 130 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 927/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2987, 訓練了 135 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 928/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5873, 訓練了 66 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 929/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5873, 訓練了 71 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 930/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3670, 訓練了 117 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 931/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1579, 訓練了 92 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 932/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1579, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 933/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1579, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 934/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.5278, 訓練了 263 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 935/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.5278, 訓練了 268 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 936/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.5278, 訓練了 273 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 937/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9331, 訓練了 57 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 938/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9331, 訓練了 62 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 939/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9331, 訓練了 67 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 940/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2884, 訓練了 59 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 941/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2884, 訓練了 64 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 942/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1507, 訓練了 92 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 943/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.1510, 訓練了 144 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 944/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.1510, 訓練了 149 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 945/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.1510, 訓練了 154 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 946/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0630, 訓練了 209 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 947/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0630, 訓練了 214 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 948/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0630, 訓練了 219 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 949/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5054, 訓練了 53 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 950/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5054, 訓練了 58 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 951/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5054, 訓練了 63 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 952/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6380, 訓練了 56 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 953/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6380, 訓練了 61 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 954/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6380, 訓練了 66 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 955/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5902, 訓練了 109 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 956/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5902, 訓練了 114 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 957/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5902, 訓練了 119 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 958/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.6750, 訓練了 191 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 959/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.6750, 訓練了 196 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 960/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.6750, 訓練了 201 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 961/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.9841, 訓練了 40 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 962/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.9841, 訓練了 45 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 963/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.9841, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 964/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2209, 訓練了 59 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 965/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2209, 訓練了 64 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 966/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2209, 訓練了 69 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 967/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0150, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 968/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0150, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 969/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0150, 訓練了 112 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 970/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8677, 訓練了 252 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 971/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8677, 訓練了 257 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 972/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8677, 訓練了 262 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 973/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1167, 訓練了 111 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 974/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1167, 訓練了 116 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 975/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1167, 訓練了 121 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 976/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2415, 訓練了 181 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 977/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2415, 訓練了 186 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 978/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2415, 訓練了 191 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 979/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0683, 訓練了 355 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 980/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0683, 訓練了 360 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 981/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0683, 訓練了 365 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 982/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 30.9956, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 983/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 30.9956, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 984/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 30.9956, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 985/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2078, 訓練了 116 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 986/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2078, 訓練了 121 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 987/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2078, 訓練了 126 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 988/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8219, 訓練了 197 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 989/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8219, 訓練了 202 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 990/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8219, 訓練了 207 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 991/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.1679, 訓練了 284 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 992/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.1679, 訓練了 289 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 993/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.1679, 訓練了 294 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 994/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 35.6113, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 995/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 35.6113, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 996/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 35.6113, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 997/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5042, 訓練了 144 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 998/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5042, 訓練了 149 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 999/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5042, 訓練了 154 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1000/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9108, 訓練了 178 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1001/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9108, 訓練了 183 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1002/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9108, 訓練了 188 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1003/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.8813, 訓練了 284 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1004/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.8813, 訓練了 289 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1005/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.8813, 訓練了 294 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1006/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 73.6286, 訓練了 168 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1007/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 45.8880, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1008/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 45.8880, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1009/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2259, 訓練了 134 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1010/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2259, 訓練了 139 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1011/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2259, 訓練了 144 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1012/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5007, 訓練了 209 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1013/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5007, 訓練了 214 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1014/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5007, 訓練了 219 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1015/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.4574, 訓練了 374 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1016/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.4574, 訓練了 379 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1017/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.4574, 訓練了 384 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1018/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 29.8504, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1019/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 29.8504, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1020/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 29.8504, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1021/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5849, 訓練了 128 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1022/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5849, 訓練了 133 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1023/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4931, 訓練了 159 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1024/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9293, 訓練了 179 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1025/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9293, 訓練了 184 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1026/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9293, 訓練了 189 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1027/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2817, 訓練了 297 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1028/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2817, 訓練了 302 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1029/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2817, 訓練了 307 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1030/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 36.1536, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1031/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 36.1536, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1032/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 36.1536, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1033/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7935, 訓練了 152 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1034/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7935, 訓練了 157 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1035/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7935, 訓練了 162 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1036/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1737, 訓練了 183 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1037/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1737, 訓練了 188 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1038/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1737, 訓練了 193 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1039/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8925, 訓練了 284 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1040/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8925, 訓練了 289 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1041/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8925, 訓練了 294 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1042/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 73.6280, 訓練了 168 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1043/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 45.7637, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1044/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 45.7637, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1045/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4509, 訓練了 127 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1046/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4509, 訓練了 132 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1047/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4509, 訓練了 137 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1048/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5768, 訓練了 202 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1049/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5768, 訓練了 207 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1050/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5768, 訓練了 212 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1051/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1524, 訓練了 343 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1052/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1524, 訓練了 348 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1053/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1524, 訓練了 353 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1054/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 32.2167, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1055/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 32.2167, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1056/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 32.2167, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1057/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.8851, 訓練了 134 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1058/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.8851, 訓練了 139 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1059/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.8851, 訓練了 144 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1060/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4684, 訓練了 185 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1061/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4684, 訓練了 190 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1062/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4684, 訓練了 195 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1063/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3044, 訓練了 298 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1064/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3044, 訓練了 303 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1065/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3044, 訓練了 308 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1066/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 36.0242, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1067/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 36.0242, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1068/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 36.0242, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1069/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.1477, 訓練了 141 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1070/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1477, 訓練了 146 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1071/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1477, 訓練了 151 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1072/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6387, 訓練了 185 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1073/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6387, 訓練了 190 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1074/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6387, 訓練了 195 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1075/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.9950, 訓練了 303 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1076/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.9950, 訓練了 308 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1077/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.9950, 訓練了 313 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1078/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 43.2748, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1079/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 43.2748, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1080/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 43.2748, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1081/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2674, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1082/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2674, 訓練了 80 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1083/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.8209, 訓練了 148 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1084/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2904, 訓練了 108 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1085/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2904, 訓練了 113 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1086/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2904, 訓練了 118 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1087/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.4997, 訓練了 214 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1088/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.4997, 訓練了 219 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1089/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.4997, 訓練了 224 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1090/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3651, 訓練了 432 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1091/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3651, 訓練了 437 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1092/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3651, 訓練了 442 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1093/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7955, 訓練了 63 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1094/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7955, 訓練了 68 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1095/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7955, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1096/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7389, 訓練了 94 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1097/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7389, 訓練了 99 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1098/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7389, 訓練了 104 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1099/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7767, 訓練了 170 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1100/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7767, 訓練了 175 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1101/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7767, 訓練了 180 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1102/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.0691, 訓練了 369 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1103/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.0691, 訓練了 374 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1104/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.0691, 訓練了 379 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1105/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5015, 訓練了 79 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1106/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5015, 訓練了 84 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1107/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5015, 訓練了 89 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1108/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7074, 訓練了 103 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1109/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7074, 訓練了 108 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1110/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7074, 訓練了 113 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1111/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.6882, 訓練了 159 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1112/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.6882, 訓練了 164 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1113/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.6882, 訓練了 169 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1114/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 14.9798, 訓練了 438 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1115/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 14.4992, 訓練了 462 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1116/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 14.4992, 訓練了 467 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1117/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4588, 訓練了 77 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1118/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4588, 訓練了 82 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1119/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4588, 訓練了 87 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1120/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8132, 訓練了 103 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1121/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8132, 訓練了 108 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1122/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8132, 訓練了 113 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1123/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4341, 訓練了 193 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1124/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4341, 訓練了 198 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1125/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4341, 訓練了 203 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1126/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.8610, 訓練了 432 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1127/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.8610, 訓練了 437 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1128/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.8610, 訓練了 442 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1129/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0615, 訓練了 94 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1130/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0615, 訓練了 99 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1131/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0615, 訓練了 104 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1132/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.2500, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1133/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.2500, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1134/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.2500, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1135/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1134, 訓練了 161 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1136/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1134, 訓練了 166 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1137/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1134, 訓練了 171 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1138/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5562, 訓練了 369 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1139/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5562, 訓練了 374 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1140/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5562, 訓練了 379 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1141/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3803, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1142/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1153, 訓練了 100 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1143/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1153, 訓練了 105 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1144/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6960, 訓練了 103 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1145/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6960, 訓練了 108 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1146/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6960, 訓練了 113 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1147/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.9210, 訓練了 153 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1148/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9434, 訓練了 203 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1149/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9434, 訓練了 208 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1150/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 18.6747, 訓練了 363 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1151/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 16.4390, 訓練了 404 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1152/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 14.9558, 訓練了 434 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1153/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9511, 訓練了 90 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1154/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9511, 訓練了 95 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1155/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1497, 訓練了 154 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1156/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8253, 訓練了 103 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1157/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8253, 訓練了 108 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1158/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8253, 訓練了 113 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1159/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3443, 訓練了 223 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1160/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3443, 訓練了 228 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1161/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3443, 訓練了 233 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1162/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8789, 訓練了 434 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1163/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8789, 訓練了 439 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1164/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8789, 訓練了 444 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1165/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0081, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1166/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0081, 訓練了 81 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1167/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0081, 訓練了 86 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1168/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3676, 訓練了 95 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1169/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3676, 訓練了 100 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1170/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3676, 訓練了 105 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1171/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8429, 訓練了 198 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1172/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8429, 訓練了 203 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1173/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8429, 訓練了 208 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1174/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.7920, 訓練了 370 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1175/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.7920, 訓練了 375 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1176/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.7920, 訓練了 380 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1177/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5585, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1178/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5585, 訓練了 78 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1179/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5585, 訓練了 83 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1180/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8717, 訓練了 100 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1181/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8717, 訓練了 105 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1182/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8717, 訓練了 110 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1183/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6150, 訓練了 175 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1184/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6150, 訓練了 180 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1185/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6150, 訓練了 185 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1186/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 21.3270, 訓練了 343 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1187/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 21.3270, 訓練了 348 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1188/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 21.3270, 訓練了 353 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1189/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3250, 訓練了 53 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1190/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3250, 訓練了 58 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1191/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3250, 訓練了 63 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1192/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5604, 訓練了 48 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1193/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3640, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1194/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1235, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1195/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5368, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1196/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5368, 訓練了 81 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1197/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5368, 訓練了 86 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1198/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8297, 訓練了 150 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1199/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8297, 訓練了 155 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1200/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8297, 訓練了 160 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1201/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0528, 訓練了 32 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1202/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0528, 訓練了 37 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1203/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4128, 訓練了 66 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1204/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.3813, 訓練了 59 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1205/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.3813, 訓練了 64 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1206/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.3813, 訓練了 69 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1207/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2332, 訓練了 69 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1208/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2332, 訓練了 74 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1209/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2332, 訓練了 79 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1210/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3055, 訓練了 157 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1211/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3055, 訓練了 162 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1212/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3055, 訓練了 167 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1213/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.1440, 訓練了 32 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1214/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1440, 訓練了 37 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1215/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.5892, 訓練了 72 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1216/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5443, 訓練了 46 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1217/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5443, 訓練了 51 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1218/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5443, 訓練了 56 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1219/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.4952, 訓練了 71 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1220/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.4952, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1221/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.4952, 訓練了 81 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1222/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 10.8170, 訓練了 159 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1223/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 10.8170, 訓練了 164 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1224/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.3973, 訓練了 227 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1225/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3674, 訓練了 31 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1226/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3674, 訓練了 36 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1227/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3674, 訓練了 41 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1228/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0731, 訓練了 44 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1229/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0731, 訓練了 49 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1230/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0731, 訓練了 54 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1231/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3164, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1232/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.6701, 訓練了 99 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1233/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.6701, 訓練了 104 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1234/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9354, 訓練了 148 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1235/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9354, 訓練了 153 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1236/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9354, 訓練了 158 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1237/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1485, 訓練了 31 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1238/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1485, 訓練了 36 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1239/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1485, 訓練了 41 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1240/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.7445, 訓練了 43 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1241/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5467, 訓練了 67 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1242/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5467, 訓練了 72 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1243/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3199, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1244/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6875, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1245/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3988, 訓練了 127 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1246/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5119, 訓練了 154 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1247/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5119, 訓練了 159 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1248/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5119, 訓練了 164 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1249/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.1479, 訓練了 40 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1250/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1479, 訓練了 45 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1251/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1479, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1252/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0865, 訓練了 45 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1253/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0865, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1254/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0865, 訓練了 55 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1255/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6950, 訓練了 71 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1256/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6950, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1257/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6950, 訓練了 81 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1258/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 11.2223, 訓練了 166 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1259/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.0225, 訓練了 213 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1260/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.0225, 訓練了 218 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1261/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7956, 訓練了 31 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1262/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7956, 訓練了 36 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1263/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7956, 訓練了 41 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1264/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6028, 訓練了 43 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1265/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6028, 訓練了 48 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1266/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6028, 訓練了 53 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1267/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1697, 訓練了 72 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1268/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.9126, 訓練了 94 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1269/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.9126, 訓練了 99 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1270/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5385, 訓練了 148 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1271/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5385, 訓練了 153 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1272/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5385, 訓練了 158 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1273/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6549, 訓練了 57 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1274/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6549, 訓練了 62 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1275/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6549, 訓練了 67 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1276/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3916, 訓練了 43 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1277/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3916, 訓練了 48 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1278/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3916, 訓練了 53 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1279/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0147, 訓練了 70 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1280/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0147, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1281/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0147, 訓練了 80 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1282/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1761, 訓練了 139 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1283/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1761, 訓練了 144 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1284/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1761, 訓練了 149 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1285/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.7363, 訓練了 46 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1286/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.7363, 訓練了 51 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1287/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.7363, 訓練了 56 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1288/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3781, 訓練了 54 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1289/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3781, 訓練了 59 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1290/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.9002, 訓練了 96 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1291/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9960, 訓練了 92 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1292/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9960, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1293/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9960, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1294/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3983, 訓練了 147 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1295/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3983, 訓練了 152 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "組合 1296/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3983, 訓練了 157 epochs\n",
      "  目前最佳 RMSE: 2.8442\n",
      "\n",
      "網格搜索完成!\n",
      "總耗時: 7238.88 秒\n",
      "\n",
      "最佳參數組合:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "最佳測試 RMSE: 2.8442\n",
      "\n",
      "使用最佳參數建立最終模型...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "最終模型評估結果:\n",
      "測試集 MSE: 8.0897\n",
      "測試集 RMSE: 2.8442 天\n",
      "R^2 分數: 0.7360\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 設置隨機種子，確保結果可重現\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(50)  # 固定隨機種子\n",
    "\n",
    "# MLP 模型定義\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size=720, hidden_sizes=[256, 128, 64], output_size=1, dropout_rate=0.3):\n",
    "        super(MLPModel, self).__init__()\n",
    "        \n",
    "        # 第一個隱藏層\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_sizes[0])\n",
    "        \n",
    "        # 第二個隱藏層\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_sizes[1])\n",
    "        \n",
    "        # 第三個隱藏層\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_sizes[2])\n",
    "        \n",
    "        # 輸出層\n",
    "        self.fc_out = nn.Linear(hidden_sizes[2], output_size)\n",
    "        \n",
    "        # Dropout 層\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# 訓練和評估模型的函數\n",
    "def train_and_evaluate(model, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, \n",
    "                      optimizer, criterion, num_epochs=500, batch_size=8, patience=20, min_delta=0.001):\n",
    "    \n",
    "    # 準備 DataLoader\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 早停相關變數\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    wait = 0\n",
    "    stopped_epoch = 0\n",
    "    \n",
    "    # 記錄訓練過程\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    # 訓練循環\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # 計算平均訓練損失\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        # 計算測試損失\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test_tensor)\n",
    "            test_loss = criterion(test_outputs, y_test_tensor).item()\n",
    "            test_losses.append(test_loss)\n",
    "        \n",
    "        # 早停判斷\n",
    "        if test_loss < best_loss - min_delta:\n",
    "            best_loss = test_loss\n",
    "            wait = 0\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                stopped_epoch = epoch + 1\n",
    "                break\n",
    "    \n",
    "    # 如果完成所有 epoch\n",
    "    if stopped_epoch == 0:\n",
    "        stopped_epoch = num_epochs\n",
    "    \n",
    "    # 載入最佳模型\n",
    "    if best_model is not None:\n",
    "        model.load_state_dict(best_model)\n",
    "    \n",
    "    # 最終評估\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_predictions = model(X_test_tensor)\n",
    "        final_test_loss = criterion(test_predictions, y_test_tensor).item()\n",
    "        final_test_rmse = np.sqrt(final_test_loss)\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'final_test_loss': final_test_loss,\n",
    "        'final_test_rmse': final_test_rmse,\n",
    "        'epochs_trained': stopped_epoch,\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "        'best_epoch': stopped_epoch - wait if wait < patience else stopped_epoch\n",
    "    }\n",
    "\n",
    "# 網格搜索函數\n",
    "def grid_search(X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, param_grid, verbose=True):\n",
    "    # 生成所有參數組合\n",
    "    param_combinations = list(itertools.product(*param_grid.values()))\n",
    "    param_keys = list(param_grid.keys())\n",
    "    \n",
    "    # 最佳結果追蹤\n",
    "    best_rmse = float('inf')\n",
    "    best_params = None\n",
    "    best_result = None\n",
    "    all_results = []\n",
    "    \n",
    "    # 總組合數\n",
    "    total_combinations = len(param_combinations)\n",
    "    \n",
    "    print(f\"開始網格搜索 - 總共 {total_combinations} 種參數組合\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 逐一嘗試每種參數組合\n",
    "    for i, combination in enumerate(param_combinations):\n",
    "        # 構建當前參數字典\n",
    "        current_params = {param_keys[j]: combination[j] for j in range(len(param_keys))}\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n組合 {i+1}/{total_combinations}:\")\n",
    "            for k, v in current_params.items():\n",
    "                print(f\"  {k}: {v}\")\n",
    "        \n",
    "        # 設置隨機種子確保公平比較\n",
    "        set_seed(50)\n",
    "        \n",
    "        # 初始化模型和優化器\n",
    "        hidden_sizes = current_params.get('hidden_sizes', [256, 128, 64])\n",
    "        dropout_rate = current_params.get('dropout_rate', 0.3)\n",
    "        \n",
    "        model = MLPModel(\n",
    "            input_size=X_train_tensor.shape[1], \n",
    "            hidden_sizes=hidden_sizes, \n",
    "            output_size=1, \n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "        \n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(), \n",
    "            lr=current_params.get('learning_rate', 0.001),\n",
    "            weight_decay=current_params.get('weight_decay', 1e-5)\n",
    "        )\n",
    "        \n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # 訓練和評估\n",
    "        result = train_and_evaluate(\n",
    "            model, \n",
    "            X_train_tensor, y_train_tensor, \n",
    "            X_test_tensor, y_test_tensor,\n",
    "            optimizer, \n",
    "            criterion,\n",
    "            num_epochs=current_params.get('num_epochs', 500),\n",
    "            batch_size=current_params.get('batch_size', 8),\n",
    "            patience=current_params.get('patience', 20)\n",
    "        )\n",
    "        \n",
    "        # 儲存結果\n",
    "        result_entry = {\n",
    "            'params': current_params,\n",
    "            'test_rmse': result['final_test_rmse'],\n",
    "            'epochs_trained': result['epochs_trained'],\n",
    "            'best_epoch': result['best_epoch']\n",
    "        }\n",
    "        all_results.append(result_entry)\n",
    "        \n",
    "        # 更新最佳結果\n",
    "        if result['final_test_rmse'] < best_rmse:\n",
    "            best_rmse = result['final_test_rmse']\n",
    "            best_params = current_params\n",
    "            best_result = result\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  訓練完成: RMSE = {result['final_test_rmse']:.4f}, 訓練了 {result['epochs_trained']} epochs\")\n",
    "            print(f\"  目前最佳 RMSE: {best_rmse:.4f}\")\n",
    "    \n",
    "    # 總耗時\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(\"\\n網格搜索完成!\")\n",
    "    print(f\"總耗時: {total_time:.2f} 秒\")\n",
    "    print(\"\\n最佳參數組合:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(f\"最佳測試 RMSE: {best_rmse:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'best_params': best_params,\n",
    "        'best_result': best_result,\n",
    "        'all_results': all_results\n",
    "    }\n",
    "\n",
    "# 使用方式 (假設您已經準備好了資料)\n",
    "# 這裡先確保 X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor 已經準備好\n",
    "\n",
    "# 定義網格搜索的參數範圍\n",
    "param_grid = {\n",
    "    'hidden_sizes': [\n",
    "        [64, 32, 16],\n",
    "        [128, 64, 32],\n",
    "        [256, 128, 64],\n",
    "        [512, 256, 128]\n",
    "    ],\n",
    "    'learning_rate': [0.0005, 0.001, 0.003],\n",
    "    'weight_decay': [1e-6, 1e-5, 1e-4],\n",
    "    'dropout_rate': [0.2, 0.3, 0.4],\n",
    "    'batch_size': [4, 8, 16, 32],\n",
    "    'patience': [15, 20, 25]\n",
    "}\n",
    "\n",
    "# 執行網格搜索\n",
    "grid_results = grid_search(X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, param_grid)\n",
    "\n",
    "# 使用最佳參數建立最終模型\n",
    "best_params = grid_results['best_params']\n",
    "print(\"\\n使用最佳參數建立最終模型...\")\n",
    "\n",
    "# 設置隨機種子\n",
    "set_seed(50)\n",
    "\n",
    "# 初始化最終模型\n",
    "final_model = MLPModel(\n",
    "    input_size=X_train_tensor.shape[1], \n",
    "    hidden_sizes=best_params['hidden_sizes'], \n",
    "    output_size=1, \n",
    "    dropout_rate=best_params['dropout_rate']\n",
    ")\n",
    "\n",
    "final_optimizer = optim.Adam(\n",
    "    final_model.parameters(), \n",
    "    lr=best_params['learning_rate'],\n",
    "    weight_decay=best_params['weight_decay']\n",
    ")\n",
    "\n",
    "final_criterion = nn.MSELoss()\n",
    "\n",
    "# 訓練最終模型\n",
    "final_result = train_and_evaluate(\n",
    "    final_model, \n",
    "    X_train_tensor, y_train_tensor, \n",
    "    X_test_tensor, y_test_tensor,\n",
    "    final_optimizer, \n",
    "    final_criterion,\n",
    "    num_epochs=500,  # 可以設置為更大的值\n",
    "    batch_size=best_params['batch_size'],\n",
    "    patience=best_params['patience']\n",
    ")\n",
    "\n",
    "# 繪製最終模型的損失曲線\n",
    "plt.rcParams['font.family'] = 'Heiti TC'  # 設置中文字體\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(final_result['train_losses']) + 1), final_result['train_losses'], label='訓練損失', color='blue')\n",
    "plt.plot(range(1, len(final_result['test_losses']) + 1), final_result['test_losses'], label='測試損失', color='red')\n",
    "plt.axvline(x=final_result['best_epoch'], color='green', linestyle='--', label=f'最佳模型 (epoch {final_result[\"best_epoch\"]})')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('損失 (MSE)')\n",
    "plt.title('最終模型訓練過程')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('final_model_loss_curve_feature6.png')\n",
    "plt.show()\n",
    "\n",
    "# 評估最終模型\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    # 測試集評估\n",
    "    test_predictions = final_model(X_test_tensor)\n",
    "    test_mse = final_criterion(test_predictions, y_test_tensor).item()\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    \n",
    "    # 計算 R^2 分數\n",
    "    y_test_mean = torch.mean(y_test_tensor)\n",
    "    ss_tot = torch.sum((y_test_tensor - y_test_mean) ** 2)\n",
    "    ss_res = torch.sum((y_test_tensor - test_predictions) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    print(\"\\n最終模型評估結果:\")\n",
    "    print(f'測試集 MSE: {test_mse:.4f}')\n",
    "    print(f'測試集 RMSE: {test_rmse:.4f} 天')\n",
    "    print(f'R^2 分數: {r2.item():.4f}')\n",
    "    \n",
    "    # 繪製實際值與預測值的比較圖\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # 轉換為 numpy 數組以便繪圖\n",
    "    y_test_np = y_test_tensor.cpu().numpy().flatten()\n",
    "    test_pred_np = test_predictions.cpu().numpy().flatten()\n",
    "    \n",
    "    # 繪製散點圖\n",
    "    plt.scatter(y_test_np, test_pred_np, color='blue', label='預測 vs 實際')\n",
    "    \n",
    "    # 繪製理想線 (y=x)\n",
    "    min_val = min(y_test_np.min(), test_pred_np.min())\n",
    "    max_val = max(y_test_np.max(), test_pred_np.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='理想線 (y=x)')\n",
    "    \n",
    "    plt.xlabel('實際開花日 (天)')\n",
    "    plt.ylabel('預測開花日 (天)')\n",
    "    plt.title('最終模型: 實際開花日 vs 預測開花日')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('final_model_predictions_feature6.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcd79585-2d6f-431d-aa9c-1a60697bbbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 繪製實際值與預測值的比較圖\n",
    "plt.figure(figsize=(5, 5))\n",
    "    \n",
    "# 轉換為 numpy 數組以便繪圖\n",
    "y_test_np = y_test_tensor.cpu().numpy().flatten()\n",
    "test_pred_np = test_predictions.cpu().numpy().flatten()\n",
    "    \n",
    "# 繪製散點圖\n",
    "plt.scatter(y_test_np, test_pred_np, color='lightpink', edgecolor='black', label='預測 vs 實際')\n",
    "    \n",
    " # 繪製理想線 (y=x)\n",
    "min_val = min(y_test_np.min(), test_pred_np.min())\n",
    "max_val = max(y_test_np.max(), test_pred_np.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='理想線 (y=x)')\n",
    "    \n",
    "plt.xlabel('實際開花所需日數')\n",
    "plt.ylabel('預測開花所需日數')\n",
    "plt.title('預測 vs 實際')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('final_model_predictions_feature6.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Data_Analysis]",
   "language": "python",
   "name": "conda-env-Data_Analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
