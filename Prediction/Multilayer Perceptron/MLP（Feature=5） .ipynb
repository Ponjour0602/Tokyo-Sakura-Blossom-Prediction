{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd4165c7-d2d6-48fe-8fb7-4e540ed713fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67d56aa-5464-483a-954d-c7634c178128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>年</th>\n",
       "      <th>月</th>\n",
       "      <th>日</th>\n",
       "      <th>當地氣壓</th>\n",
       "      <th>海平面氣壓</th>\n",
       "      <th>最大降水量</th>\n",
       "      <th>一小時降水量</th>\n",
       "      <th>10分鐘降水量</th>\n",
       "      <th>平均氣溫</th>\n",
       "      <th>最高氣溫</th>\n",
       "      <th>最低氣溫</th>\n",
       "      <th>平均濕度</th>\n",
       "      <th>最小濕度</th>\n",
       "      <th>日照時間</th>\n",
       "      <th>開花日</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1011.7</td>\n",
       "      <td>1012.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>41.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1020.2</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>51.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1021.3</td>\n",
       "      <td>1022.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1004.6</td>\n",
       "      <td>1005.3</td>\n",
       "      <td>20.2</td>\n",
       "      <td>13.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1016.3</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23371</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>1006.9</td>\n",
       "      <td>1009.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>12.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>51.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23372</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>1008.1</td>\n",
       "      <td>1011.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23373</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>1013.4</td>\n",
       "      <td>1016.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23374</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>1017.1</td>\n",
       "      <td>1020.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>53.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23375</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>1003.4</td>\n",
       "      <td>1006.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>55.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23376 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          年   月   日    當地氣壓   海平面氣壓  最大降水量  一小時降水量  10分鐘降水量  平均氣溫  最高氣溫  最低氣溫  \\\n",
       "0      1961   1   1  1011.7  1012.4    0.0     0.0      0.0   2.1   7.9  -3.9   \n",
       "1      1961   1   2  1020.2  1021.0    0.0     0.0      0.0   1.5   9.2  -3.3   \n",
       "2      1961   1   3  1021.3  1022.1    0.1     0.8      0.0   2.5   7.3  -2.4   \n",
       "3      1961   1   4  1004.6  1005.3   20.2    13.9      3.2   4.7  11.5   0.6   \n",
       "4      1961   1   5  1016.3  1017.0    0.0     0.0      0.0   3.8   7.7   1.4   \n",
       "...     ...  ..  ..     ...     ...    ...     ...      ...   ...   ...   ...   \n",
       "23371  2024  12  27  1006.9  1009.9    0.0     0.0      0.0   7.4  12.7   3.8   \n",
       "23372  2024  12  28  1008.1  1011.1    0.0     0.0      0.0   5.4  11.5   1.4   \n",
       "23373  2024  12  29  1013.4  1016.4    0.0     0.0      0.0   6.0  12.3   0.5   \n",
       "23374  2024  12  30  1017.1  1020.1    0.0     0.0      0.0   6.2  10.3   3.5   \n",
       "23375  2024  12  31  1003.4  1006.4    0.0     0.0      0.0   8.0  14.6   2.8   \n",
       "\n",
       "       平均濕度  最小濕度  日照時間  開花日  \n",
       "0      41.0  15.0   8.6    0  \n",
       "1      51.0  26.0   8.7    0  \n",
       "2      58.0  37.0   5.4    0  \n",
       "3      60.0  38.0   1.0    0  \n",
       "4      33.0  19.0   8.3    0  \n",
       "...     ...   ...   ...  ...  \n",
       "23371  51.0  38.0   6.1    0  \n",
       "23372  59.0  36.0   7.5    0  \n",
       "23373  54.0  31.0   8.9    0  \n",
       "23374  53.0  32.0   5.0    0  \n",
       "23375  55.0  37.0   7.6    0  \n",
       "\n",
       "[23376 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 讀資料\n",
    "df = pd.read_csv('Dataset/weather_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c647df-5e9e-4145-94be-fbea9b0809b2",
   "metadata": {},
   "source": [
    "### 將年, 月, 日欄位重新命名為 year, month, day ，合併成 date 並轉為 datetime格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d58e4b0d-1fb1-47fb-ad98-b084f7a79ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新命名 年 月 日 的欄位\n",
    "df = df.rename(columns={'年': 'year', '月': 'month', '日': 'day'})\n",
    "\n",
    "# 合併為 datetime 欄位\n",
    "df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "\n",
    "# 排序\n",
    "df = df.sort_values(['year', 'month', 'day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b02fb0-c906-43d3-9825-b630ca7e89b8",
   "metadata": {},
   "source": [
    "### 選定訓練時需要的特徵值，並只取每年前120日的氣象資料當作模型的 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4ffa14-d7cd-44e8-a891-3087ff86fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 特徵挑選與目標\n",
    "feature_cols = ['當地氣壓', '海平面氣壓', '平均氣溫', '最大降水量', '平均濕度']\n",
    "\n",
    "yearly_sequences = []\n",
    "\n",
    "for year, group in df.groupby('year'):\n",
    "    # 只取該年按日期排序後的前120筆\n",
    "    sub = group.sort_values('date').iloc[:120]\n",
    "    # 取 feature_cols 對應的欄位\n",
    "    if len(sub) == 120:  # 避免資料天數不足\n",
    "        yearly_sequences.append(sub[feature_cols].to_numpy())\n",
    "    else:\n",
    "        print(f'⚠️ {year} 年資料不足120天，已略過')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e34a261-3f43-4581-8c75-9f662e09b85b",
   "metadata": {},
   "source": [
    "### 將每年開花所需的日數當作模型的 y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f0c634b-019e-4264-932e-4bb61e14b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = np.stack(yearly_sequences)  # shape=(年數, 120, 特徵數)\n",
    "y = []\n",
    "for year, group in df.groupby('year'):\n",
    "    # 排序後的資料\n",
    "    group_sorted = group.sort_values('date')\n",
    "    # 找到開花日=1的那一行\n",
    "    bloom_rows = group_sorted[group_sorted['開花日'] == 1]\n",
    "    if len(bloom_rows) > 0:\n",
    "        # 計算開花日是該年的第幾天 (0-based)\n",
    "        first_date = group_sorted['date'].iloc[0]\n",
    "        bloom_date = bloom_rows['date'].iloc[0]\n",
    "        days_diff = (bloom_date - first_date).days\n",
    "        y.append(days_diff)\n",
    "    else:\n",
    "        print(f\"警告: {year}年沒有開花日記錄\")\n",
    "        # 跳過這一年的資料\n",
    "# y 已經是一個 list，長度等於 yearly_sequences\n",
    "y_np = np.array(y)   # shape=(年數, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e27a50-1c63-4cdb-9be9-23e9fd7d9823",
   "metadata": {},
   "source": [
    "### 將 X 標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a93914-9d41-4c07-a0a3-5a52fe006d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假設 X_np.shape = (年數, 120, 6)\n",
    "X_flat = X_np.reshape((X_np.shape[0], -1))\n",
    "\n",
    "# 對每個特徵單獨標準化\n",
    "X_scaled = np.zeros_like(X_np)\n",
    "for i in range(X_np.shape[2]):  # 遍歷6個特徵\n",
    "    feature_data = X_np[:, :, i]  # (年數, 120)\n",
    "    scaler = StandardScaler()\n",
    "    # 將所有年份的該特徵數據平攤用於擬合scaler\n",
    "    scaler.fit(feature_data.reshape(-1, 1))\n",
    "    # 對每年的該特徵進行轉換\n",
    "    for j in range(X_np.shape[0]):  # 遍歷每一年\n",
    "        X_scaled[j, :, i] = scaler.transform(X_np[j, :, i].reshape(-1, 1)).flatten()\n",
    "\n",
    "# 然後再平攤用於模型輸入\n",
    "X_flat_scaled = X_scaled.reshape((X_scaled.shape[0], -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23ef34e-68a5-4d8b-8d2d-5a5e33d34e90",
   "metadata": {},
   "source": [
    "### 將 X, y 以 8:2 年代前後順序做切分訓練集與測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90048689-896e-4d65-b192-e939ee1f5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時間順序分割 (最後20%作為測試集)\n",
    "split_index = int(0.8 * len(X_flat_scaled))\n",
    "X_train, X_test = X_flat_scaled[:split_index], X_flat_scaled[split_index:]\n",
    "y_train, y_test = y_np[:split_index], y_np[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfb7fb6f-f625-48ec-aeb7-275f0f625c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轉換為張量\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3569558b-0282-4de5-852a-d061bd6c691d",
   "metadata": {},
   "source": [
    "### 設定random seed（50）\n",
    "### 建立MLP模型：3 of Fully Connected Layers、Loss：MSE、Adam Optimizer、early stop\n",
    "### 設定網格搜索：hidden state, learning rate, weight Decay, Dropout Rate, Batch Size, Patience\n",
    "### 使用 R^2 評估模型\n",
    "### Loss 數據視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7547bba5-233d-44fb-bdba-119bd4993def",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始網格搜索 - 總共 1296 種參數組合\n",
      "\n",
      "組合 1/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5020, 訓練了 349 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 2/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5020, 訓練了 354 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 3/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5020, 訓練了 359 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 4/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2725, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 5/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2725, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 6/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2725, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 7/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 42.8347, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 8/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 42.8347, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 9/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 42.8347, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 10/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 73.2440, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 11/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 73.2440, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 12/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 73.2440, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 13/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6581, 訓練了 332 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 14/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6581, 訓練了 337 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 15/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6581, 訓練了 342 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 16/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7356, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 17/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7356, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 18/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7356, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 19/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 44.4154, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 20/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 44.4154, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 21/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 44.4154, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 22/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 72.5024, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 23/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 72.5024, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 24/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 72.5024, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 25/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3415, 訓練了 325 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 26/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9924, 訓練了 352 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 27/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9924, 訓練了 357 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 28/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.5744, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 29/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.5744, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 30/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.5744, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 31/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 42.7844, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 32/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 42.7844, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 33/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 42.7844, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 34/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 79.0113, 訓練了 17 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 35/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 70.9079, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 36/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 70.9079, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 37/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5704, 訓練了 323 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 38/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5704, 訓練了 328 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 39/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5704, 訓練了 333 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 40/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.0720, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 41/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.0720, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 42/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.0720, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 43/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 47.1941, 訓練了 492 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 44/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 46.2796, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 45/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 46.2796, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 46/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 72.9837, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 47/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 72.9837, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 48/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 72.9837, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 49/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4350, 訓練了 311 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 50/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2568, 訓練了 333 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 51/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2568, 訓練了 338 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 52/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9268, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 53/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9268, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 54/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9268, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 55/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 41.5886, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 56/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 41.5886, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 57/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 41.5886, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 58/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 72.4352, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 59/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 72.4352, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 60/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 72.4352, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 61/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 9.3738, 訓練了 286 epochs\n",
      "  目前最佳 RMSE: 4.5020\n",
      "\n",
      "組合 62/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.8918, 訓練了 379 epochs\n",
      "  目前最佳 RMSE: 3.8918\n",
      "\n",
      "組合 63/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.5171, 訓練了 411 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 64/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1600, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 65/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1600, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 66/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1600, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 67/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 52.9412, 訓練了 424 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 68/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 43.6576, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 69/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 43.6576, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 70/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 79.0118, 訓練了 17 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 71/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 77.0559, 訓練了 288 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 72/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 71.3631, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 73/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0275, 訓練了 345 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 74/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0275, 訓練了 350 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 75/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0275, 訓練了 355 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 76/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2819, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 77/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2819, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 78/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2819, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 79/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 78.0904, 訓練了 94 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 80/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 44.8158, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 81/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 44.8158, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 82/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 73.2107, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 83/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 73.2107, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 84/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 73.2107, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 85/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4075, 訓練了 334 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 86/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4075, 訓練了 339 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 87/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4075, 訓練了 344 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 88/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.2492, 訓練了 497 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 89/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.4741, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 90/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.4741, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 91/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 40.1022, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 92/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 40.1022, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 93/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 40.1022, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 94/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 71.3086, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 95/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 71.3086, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 96/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 71.3086, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 97/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9464, 訓練了 362 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 98/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9464, 訓練了 367 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 99/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9464, 訓練了 372 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 100/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 14.4139, 訓練了 441 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 101/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5073, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 102/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5073, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 103/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 45.5096, 訓練了 492 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 104/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 45.5096, 訓練了 497 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 105/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 45.5096, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 106/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 79.0124, 訓練了 17 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 107/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 71.6322, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 108/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 71.6322, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 109/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8947, 訓練了 162 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 110/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8947, 訓練了 167 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 111/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8947, 訓練了 172 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 112/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2631, 訓練了 271 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 113/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2631, 訓練了 276 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 114/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2631, 訓練了 281 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 115/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9326, 訓練了 462 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 116/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9326, 訓練了 467 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 117/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9326, 訓練了 472 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 118/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 49.9271, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 119/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 49.9271, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 120/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 49.9271, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 121/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6240, 訓練了 167 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 122/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6240, 訓練了 172 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 123/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6240, 訓練了 177 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 124/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7259, 訓練了 286 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 125/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7259, 訓練了 291 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 126/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7259, 訓練了 296 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 127/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5796, 訓練了 468 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 128/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5796, 訓練了 473 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 129/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5796, 訓練了 478 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 130/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 47.9641, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 131/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 47.9641, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 132/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 47.9641, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 133/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2065, 訓練了 167 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 134/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2065, 訓練了 172 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 135/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2065, 訓練了 177 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 136/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9714, 訓練了 267 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 137/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.8528, 訓練了 296 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 138/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.8528, 訓練了 301 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 139/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7095, 訓練了 480 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 140/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7095, 訓練了 485 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 141/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7095, 訓練了 490 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 142/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 47.7437, 訓練了 496 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 143/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 46.5845, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 144/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 46.5845, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 145/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4988, 訓練了 157 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 146/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4988, 訓練了 162 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 147/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4988, 訓練了 167 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 148/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9911, 訓練了 264 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 149/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9911, 訓練了 269 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 150/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9911, 訓練了 274 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 151/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.6968, 訓練了 415 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 152/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.6968, 訓練了 420 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 153/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6333, 訓練了 454 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 154/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 48.7168, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 155/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 48.7168, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 156/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 48.7168, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 157/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6305, 訓練了 165 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 158/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6305, 訓練了 170 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 159/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6305, 訓練了 175 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 160/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0035, 訓練了 273 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 161/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0035, 訓練了 278 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 162/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0035, 訓練了 283 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 163/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 17.5201, 訓練了 343 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 164/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8654, 訓練了 475 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 165/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8654, 訓練了 480 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 166/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 48.4802, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 167/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 48.4802, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 168/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 48.4802, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 169/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3011, 訓練了 183 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 170/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3011, 訓練了 188 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 171/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3011, 訓練了 193 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 172/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3515, 訓練了 292 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 173/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3515, 訓練了 297 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 174/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3515, 訓練了 302 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 175/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3900, 訓練了 427 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 176/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3900, 訓練了 432 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 177/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3900, 訓練了 437 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 178/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 45.7424, 訓練了 496 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 179/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 45.1946, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 180/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 45.1946, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 181/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6859, 訓練了 173 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 182/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6859, 訓練了 178 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 183/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6859, 訓練了 183 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 184/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8635, 訓練了 277 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 185/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8635, 訓練了 282 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 186/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8635, 訓練了 287 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 187/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.7898, 訓練了 441 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 188/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.7898, 訓練了 446 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 189/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.7898, 訓練了 451 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 190/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 47.1360, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 191/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 47.1360, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 192/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 47.1360, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 193/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3028, 訓練了 187 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 194/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3028, 訓練了 192 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 195/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3028, 訓練了 197 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 196/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8245, 訓練了 290 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 197/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8245, 訓練了 295 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 198/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8245, 訓練了 300 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 199/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.6577, 訓練了 409 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 200/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.6577, 訓練了 414 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 201/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5160, 訓練了 478 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 202/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 53.1223, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 203/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 53.1223, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 204/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 53.1223, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 205/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1957, 訓練了 196 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 206/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1957, 訓練了 201 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 207/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1957, 訓練了 206 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 208/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4317, 訓練了 264 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 209/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4317, 訓練了 269 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 210/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4317, 訓練了 274 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 211/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9255, 訓練了 436 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 212/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9255, 訓練了 441 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 213/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9255, 訓練了 446 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 214/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 47.4500, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 215/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 47.4500, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 216/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 47.4500, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 217/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0990, 訓練了 62 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 218/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0990, 訓練了 67 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 219/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0990, 訓練了 72 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 220/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7909, 訓練了 93 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 221/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7909, 訓練了 98 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 222/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7909, 訓練了 103 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 223/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.8381, 訓練了 154 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 224/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.8381, 訓練了 159 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 225/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.8381, 訓練了 164 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 226/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4336, 訓練了 346 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 227/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4336, 訓練了 351 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 228/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4336, 訓練了 356 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 229/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3966, 訓練了 84 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 230/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3966, 訓練了 89 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 231/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3966, 訓練了 94 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 232/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9753, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 233/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9753, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 234/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9753, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 235/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9666, 訓練了 162 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 236/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9666, 訓練了 167 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 237/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9666, 訓練了 172 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 238/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4810, 訓練了 348 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 239/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4810, 訓練了 353 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 240/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4810, 訓練了 358 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 241/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2958, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 242/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2958, 訓練了 81 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 243/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2958, 訓練了 86 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 244/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5134, 訓練了 98 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 245/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5134, 訓練了 103 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 246/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5134, 訓練了 108 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 247/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0314, 訓練了 161 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 248/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0314, 訓練了 166 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 249/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0314, 訓練了 171 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 250/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.8283, 訓練了 304 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 251/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5156, 訓練了 333 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 252/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5156, 訓練了 338 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 253/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1587, 訓練了 61 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 254/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1587, 訓練了 66 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 255/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1587, 訓練了 71 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 256/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.7189, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 257/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.7189, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 258/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.7189, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 259/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3457, 訓練了 169 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 260/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3457, 訓練了 174 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 261/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3457, 訓練了 179 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 262/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6944, 訓練了 347 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 263/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6944, 訓練了 352 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 264/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6944, 訓練了 357 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 265/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9060, 訓練了 63 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 266/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9060, 訓練了 68 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 267/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9060, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 268/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2000, 訓練了 92 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 269/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2000, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 270/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2000, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 271/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6876, 訓練了 164 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 272/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6876, 訓練了 169 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 273/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6876, 訓練了 174 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 274/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3691, 訓練了 348 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 275/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3691, 訓練了 353 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 276/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3691, 訓練了 358 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 277/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5682, 訓練了 64 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 278/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5682, 訓練了 69 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 279/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5682, 訓練了 74 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 280/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9982, 訓練了 99 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 281/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9982, 訓練了 104 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 282/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9982, 訓練了 109 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 283/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9637, 訓練了 162 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 284/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9637, 訓練了 167 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 285/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9637, 訓練了 172 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 286/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5755, 訓練了 301 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 287/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5755, 訓練了 306 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 288/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5755, 訓練了 311 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 289/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1063, 訓練了 66 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 290/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1063, 訓練了 71 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 291/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1063, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 292/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.1134, 訓練了 108 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 293/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.1134, 訓練了 113 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 294/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.1134, 訓練了 118 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 295/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2246, 訓練了 162 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 296/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2246, 訓練了 167 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 297/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2246, 訓練了 172 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 298/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.7166, 訓練了 358 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 299/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.7166, 訓練了 363 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 300/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.7166, 訓練了 368 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 301/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5152, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 302/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5152, 訓練了 78 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 303/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5152, 訓練了 83 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 304/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1618, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 305/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1618, 訓練了 112 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 306/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1618, 訓練了 117 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 307/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0193, 訓練了 150 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 308/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0193, 訓練了 155 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 309/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0193, 訓練了 160 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 310/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8759, 訓練了 345 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 311/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8759, 訓練了 350 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 312/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0337, 訓練了 430 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 313/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9201, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 314/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9201, 訓練了 78 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 315/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9201, 訓練了 83 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 316/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7467, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 317/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7467, 訓練了 106 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 318/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7467, 訓練了 111 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 319/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5151, 訓練了 161 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 320/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5151, 訓練了 166 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 321/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5151, 訓練了 171 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 322/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5544, 訓練了 328 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 323/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5544, 訓練了 333 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 324/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5544, 訓練了 338 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 325/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8543, 訓練了 220 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 326/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8543, 訓練了 225 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 327/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8543, 訓練了 230 epochs\n",
      "  目前最佳 RMSE: 3.5171\n",
      "\n",
      "組合 328/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.4391, 訓練了 375 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 329/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.4391, 訓練了 380 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 330/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.4391, 訓練了 385 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 331/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 38.8006, 訓練了 380 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 332/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 16.3048, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 333/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 16.3048, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 334/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 59.9924, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 335/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 59.9924, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 336/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 59.9924, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 337/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8092, 訓練了 244 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 338/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8092, 訓練了 249 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 339/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8092, 訓練了 254 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 340/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8179, 訓練了 342 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 341/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8179, 訓練了 347 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 342/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8179, 訓練了 352 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 343/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 40.4729, 訓練了 361 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 344/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 15.4565, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 345/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 15.4565, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 346/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 69.0433, 訓練了 381 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 347/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 69.0433, 訓練了 386 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 348/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 69.0433, 訓練了 391 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 349/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1283, 訓練了 252 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 350/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1283, 訓練了 257 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 351/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0926, 訓練了 286 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 352/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3762, 訓練了 380 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 353/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3762, 訓練了 385 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 354/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3762, 訓練了 390 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 355/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 35.7958, 訓練了 380 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 356/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 16.7931, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 357/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 16.7931, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 358/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 71.9981, 訓練了 293 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 359/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 71.9981, 訓練了 298 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 360/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 71.5135, 訓練了 340 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 361/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1779, 訓練了 225 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 362/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1779, 訓練了 230 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 363/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1779, 訓練了 235 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 364/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4210, 訓練了 360 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 365/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4210, 訓練了 365 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 366/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4210, 訓練了 370 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 367/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 18.8312, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 368/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 18.8312, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 369/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 18.8312, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 370/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 59.9702, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 371/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 59.9702, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 372/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 59.9702, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 373/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9918, 訓練了 229 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 374/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5461, 訓練了 253 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 375/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5461, 訓練了 258 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 376/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.5529, 訓練了 395 epochs\n",
      "  目前最佳 RMSE: 3.4391\n",
      "\n",
      "組合 377/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.3855, 訓練了 416 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 378/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.3855, 訓練了 421 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 379/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 39.3422, 訓練了 361 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 380/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 19.0427, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 381/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 19.0427, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 382/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 75.1647, 訓練了 236 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 383/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 69.0689, 訓練了 386 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 384/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 69.0689, 訓練了 391 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 385/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0694, 訓練了 226 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 386/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0563, 訓練了 249 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 387/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0563, 訓練了 254 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 388/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4034, 訓練了 410 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 389/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2220, 訓練了 432 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 390/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2220, 訓練了 437 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 391/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 37.6450, 訓練了 380 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 392/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 17.7912, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 393/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 17.7912, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 394/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 71.9999, 訓練了 293 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 395/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 71.9999, 訓練了 298 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 396/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 71.5114, 訓練了 340 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 397/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6838, 訓練了 236 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 398/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6838, 訓練了 241 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 399/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6838, 訓練了 246 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 400/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.6650, 訓練了 359 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 401/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8662, 訓練了 404 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 402/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8662, 訓練了 409 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 403/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 38.1842, 訓練了 380 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 404/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 18.3120, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 405/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 18.3120, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 406/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 60.9872, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 407/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 60.9872, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 408/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 60.9872, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 409/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0240, 訓練了 242 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 410/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0240, 訓練了 247 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 411/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0240, 訓練了 252 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 412/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5023, 訓練了 382 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 413/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5023, 訓練了 387 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 414/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5023, 訓練了 392 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 415/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 17.5202, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 416/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 17.5202, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 417/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 17.5202, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 418/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 74.0461, 訓練了 236 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 419/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 64.1585, 訓練了 488 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 420/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 63.6029, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 421/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.6546, 訓練了 261 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 422/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.6546, 訓練了 266 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 423/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.6546, 訓練了 271 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 424/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4820, 訓練了 370 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 425/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4820, 訓練了 375 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 426/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4820, 訓練了 380 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 427/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 15.7134, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 428/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 15.7134, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 429/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 15.7134, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 430/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 71.4936, 訓練了 293 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 431/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 68.9771, 訓練了 386 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 432/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 68.9771, 訓練了 391 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 433/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2995, 訓練了 118 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 434/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2995, 訓練了 123 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 435/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2995, 訓練了 128 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 436/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0746, 訓練了 207 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 437/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0746, 訓練了 212 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 438/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0746, 訓練了 217 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 439/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.9785, 訓練了 326 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 440/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.9785, 訓練了 331 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 441/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.9785, 訓練了 336 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 442/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 23.7515, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 443/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 23.7515, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 444/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 23.7515, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 445/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7552, 訓練了 135 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 446/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7552, 訓練了 140 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 447/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7552, 訓練了 145 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 448/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2687, 訓練了 198 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 449/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2687, 訓練了 203 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 450/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2687, 訓練了 208 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 451/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1990, 訓練了 322 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 452/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1990, 訓練了 327 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 453/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1990, 訓練了 332 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 454/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 47.1531, 訓練了 381 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 455/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 29.6829, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 456/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 29.6829, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 457/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6291, 訓練了 133 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 458/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6291, 訓練了 138 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 459/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3218, 訓練了 170 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 460/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3198, 訓練了 199 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 461/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3198, 訓練了 204 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 462/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3198, 訓練了 209 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 463/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0073, 訓練了 326 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 464/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0073, 訓練了 331 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 465/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0073, 訓練了 336 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 466/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 66.3362, 訓練了 236 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 467/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 66.3362, 訓練了 241 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 468/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 35.7906, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 469/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1987, 訓練了 123 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 470/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1987, 訓練了 128 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 471/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1987, 訓練了 133 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 472/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6661, 訓練了 200 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 473/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6661, 訓練了 205 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 474/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6661, 訓練了 210 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 475/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0599, 訓練了 328 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 476/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0599, 訓練了 333 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 477/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0599, 訓練了 338 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 478/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 23.4477, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 479/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 23.4477, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 480/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 23.4477, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 481/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4134, 訓練了 122 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 482/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4134, 訓練了 127 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 483/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4134, 訓練了 132 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 484/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4100, 訓練了 191 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 485/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4100, 訓練了 196 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 486/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4100, 訓練了 201 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 487/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7634, 訓練了 324 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 488/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7634, 訓練了 329 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 489/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7634, 訓練了 334 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 490/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 28.8330, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 491/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 28.8330, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 492/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 28.8330, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 493/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7337, 訓練了 150 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 494/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7337, 訓練了 155 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 495/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7337, 訓練了 160 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 496/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7813, 訓練了 203 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 497/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7813, 訓練了 208 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 498/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7813, 訓練了 213 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 499/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9741, 訓練了 332 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 500/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9501, 訓練了 353 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 501/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9501, 訓練了 358 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 502/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 66.3251, 訓練了 236 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 503/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 66.3251, 訓練了 241 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 504/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 35.8033, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 505/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.6475, 訓練了 116 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 506/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.6475, 訓練了 121 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 507/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.6475, 訓練了 126 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 508/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4512, 訓練了 198 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 509/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4512, 訓練了 203 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 510/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4512, 訓練了 208 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 511/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.1877, 訓練了 319 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 512/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1877, 訓練了 324 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 513/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1877, 訓練了 329 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 514/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 22.1457, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 515/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 22.1457, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 516/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 22.1457, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 517/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2397, 訓練了 135 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 518/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2397, 訓練了 140 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 519/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2302, 訓練了 166 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 520/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9505, 訓練了 192 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 521/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9505, 訓練了 197 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 522/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9505, 訓練了 202 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 523/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9611, 訓練了 285 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 524/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1911, 訓練了 320 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 525/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1911, 訓練了 325 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 526/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 70.4682, 訓練了 190 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 527/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 30.9603, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 528/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 30.9603, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 529/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7732, 訓練了 132 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 530/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7732, 訓練了 137 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 531/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6576, 訓練了 181 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 532/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2620, 訓練了 182 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 533/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2620, 訓練了 187 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 534/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2620, 訓練了 192 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 535/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6397, 訓練了 331 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 536/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6397, 訓練了 336 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 537/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6397, 訓練了 341 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 538/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 62.1019, 訓練了 271 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 539/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 30.6264, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 540/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 30.6264, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 541/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2316, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 542/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2316, 訓練了 55 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 543/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2316, 訓練了 60 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 544/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7729, 訓練了 79 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 545/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7729, 訓練了 84 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 546/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7729, 訓練了 89 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 547/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5551, 訓練了 123 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 548/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5551, 訓練了 128 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 549/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5551, 訓練了 133 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 550/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.6277, 訓練了 240 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 551/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.6277, 訓練了 245 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 552/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.6277, 訓練了 250 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 553/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9717, 訓練了 48 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 554/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9717, 訓練了 53 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 555/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9717, 訓練了 58 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 556/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2564, 訓練了 84 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 557/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2564, 訓練了 89 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 558/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2564, 訓練了 94 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 559/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.1584, 訓練了 120 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 560/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.1584, 訓練了 125 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 561/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.1584, 訓練了 130 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 562/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2481, 訓練了 254 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 563/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2481, 訓練了 259 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 564/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2481, 訓練了 264 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 565/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6035, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 566/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6035, 訓練了 55 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 567/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6035, 訓練了 60 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 568/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9997, 訓練了 90 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 569/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9997, 訓練了 95 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 570/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9997, 訓練了 100 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 571/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5738, 訓練了 114 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 572/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5738, 訓練了 119 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 573/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5738, 訓練了 124 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 574/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7880, 訓練了 230 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 575/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7880, 訓練了 235 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 576/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7880, 訓練了 240 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 577/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6975, 訓練了 62 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 578/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6975, 訓練了 67 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 579/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6975, 訓練了 72 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 580/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7033, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 581/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7033, 訓練了 80 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 582/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7033, 訓練了 85 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 583/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2835, 訓練了 120 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 584/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2835, 訓練了 125 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 585/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2835, 訓練了 130 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 586/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.6183, 訓練了 240 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 587/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.6183, 訓練了 245 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 588/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.6183, 訓練了 250 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 589/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.8896, 訓練了 53 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 590/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.8896, 訓練了 58 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 591/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.8896, 訓練了 63 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 592/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5469, 訓練了 72 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 593/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5469, 訓練了 77 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 594/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5469, 訓練了 82 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 595/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1419, 訓練了 116 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 596/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1419, 訓練了 121 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 597/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1419, 訓練了 126 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 598/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4444, 訓練了 236 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 599/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4444, 訓練了 241 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 600/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4444, 訓練了 246 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 601/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7117, 訓練了 53 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 602/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7117, 訓練了 58 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 603/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7117, 訓練了 63 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 604/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6869, 訓練了 72 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 605/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6869, 訓練了 77 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 606/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6869, 訓練了 82 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 607/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4086, 訓練了 115 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 608/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4086, 訓練了 120 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 609/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4086, 訓練了 125 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 610/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7949, 訓練了 230 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 611/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7949, 訓練了 235 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 612/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7949, 訓練了 240 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 613/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3797, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 614/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3797, 訓練了 55 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 615/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3797, 訓練了 60 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 616/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5126, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 617/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5126, 訓練了 78 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 618/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5126, 訓練了 83 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 619/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.5022, 訓練了 119 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 620/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.5022, 訓練了 124 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 621/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.5022, 訓練了 129 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 622/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2361, 訓練了 248 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 623/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2361, 訓練了 253 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 624/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2361, 訓練了 258 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 625/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1279, 訓練了 56 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 626/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1279, 訓練了 61 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 627/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1279, 訓練了 66 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 628/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6104, 訓練了 72 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 629/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6104, 訓練了 77 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 630/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6104, 訓練了 82 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 631/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2703, 訓練了 108 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 632/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2703, 訓練了 113 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 633/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2703, 訓練了 118 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 634/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3929, 訓練了 236 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 635/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3929, 訓練了 241 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 636/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3929, 訓練了 246 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 637/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3650, 訓練了 54 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 638/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3650, 訓練了 59 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 639/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3650, 訓練了 64 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 640/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5422, 訓練了 78 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 641/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5422, 訓練了 83 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 642/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5422, 訓練了 88 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 643/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.4478, 訓練了 125 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 644/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.4478, 訓練了 130 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 645/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.4478, 訓練了 135 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 646/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.8145, 訓練了 230 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 647/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.8145, 訓練了 235 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 648/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.8145, 訓練了 240 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 649/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0923, 訓練了 160 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 650/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0923, 訓練了 165 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 651/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0923, 訓練了 170 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 652/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.9450, 訓練了 286 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 653/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.9450, 訓練了 291 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 654/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.9450, 訓練了 296 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 655/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5001, 訓練了 449 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 656/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5001, 訓練了 454 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 657/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5001, 訓練了 459 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 658/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 46.4885, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 659/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 46.4885, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 660/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 46.4885, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 661/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0713, 訓練了 184 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 662/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0713, 訓練了 189 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 663/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0041, 訓練了 216 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 664/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7426, 訓練了 262 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 665/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7426, 訓練了 267 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 666/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7426, 訓練了 272 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 667/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2086, 訓練了 431 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 668/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2086, 訓練了 436 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 669/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2086, 訓練了 441 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 670/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 69.3650, 訓練了 294 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 671/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 60.1912, 訓練了 414 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 672/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 60.1912, 訓練了 419 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 673/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2064, 訓練了 185 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 674/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2064, 訓練了 190 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 675/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1238, 訓練了 230 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 676/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4123, 訓練了 265 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 677/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4123, 訓練了 270 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 678/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4123, 訓練了 275 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 679/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 13.9667, 訓練了 358 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 680/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4177, 訓練了 435 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 681/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4177, 訓練了 440 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 682/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 69.5274, 訓練了 293 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 683/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 69.5274, 訓練了 298 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 684/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 56.0536, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 685/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8033, 訓練了 167 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 686/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8033, 訓練了 172 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 687/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8033, 訓練了 177 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 688/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2165, 訓練了 271 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 689/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2165, 訓練了 276 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 690/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2165, 訓練了 281 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 691/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.9227, 訓練了 461 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 692/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.9227, 訓練了 466 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 693/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.9227, 訓練了 471 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 694/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 45.8718, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 695/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 45.8718, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 696/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 45.8718, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 697/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5975, 訓練了 168 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 698/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5975, 訓練了 173 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 699/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5975, 訓練了 178 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 700/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.7721, 訓練了 256 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 701/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.7721, 訓練了 261 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 702/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.7721, 訓練了 266 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 703/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0879, 訓練了 447 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 704/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0879, 訓練了 452 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 705/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0879, 訓練了 457 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 706/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 69.3659, 訓練了 294 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 707/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 60.0425, 訓練了 414 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 708/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 60.0425, 訓練了 419 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 709/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8197, 訓練了 185 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 710/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8197, 訓練了 190 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 711/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8197, 訓練了 195 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 712/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4186, 訓練了 268 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 713/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4186, 訓練了 273 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 714/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4186, 訓練了 278 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 715/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0816, 訓練了 422 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 716/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0816, 訓練了 427 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 717/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0816, 訓練了 432 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 718/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 69.5278, 訓練了 293 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 719/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 69.5278, 訓練了 298 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 720/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 56.0562, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 721/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7248, 訓練了 170 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 722/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7248, 訓練了 175 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 723/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7248, 訓練了 180 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 724/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0410, 訓練了 278 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 725/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0410, 訓練了 283 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 726/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0410, 訓練了 288 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 727/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.4567, 訓練了 447 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 728/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3740, 訓練了 471 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 729/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3740, 訓練了 476 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 730/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 46.0609, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 731/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 46.0609, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 732/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 46.0609, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 733/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3814, 訓練了 168 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 734/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3814, 訓練了 173 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 735/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3814, 訓練了 178 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 736/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.9820, 訓練了 269 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 737/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.9820, 訓練了 274 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 738/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.9820, 訓練了 279 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 739/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7430, 訓練了 422 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 740/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7430, 訓練了 427 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 741/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7430, 訓練了 432 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 742/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 69.1638, 訓練了 294 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 743/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 67.5850, 訓練了 333 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 744/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 52.0322, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 745/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.8310, 訓練了 192 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 746/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.8310, 訓練了 197 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 747/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.8310, 訓練了 202 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 748/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9605, 訓練了 272 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 749/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9605, 訓練了 277 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 750/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9605, 訓練了 282 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 751/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.5031, 訓練了 390 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 752/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9283, 訓練了 427 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 753/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9283, 訓練了 432 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 754/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 68.0106, 訓練了 295 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 755/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 53.0758, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 756/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 53.0758, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 757/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7445, 訓練了 95 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 758/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7445, 訓練了 100 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 759/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7445, 訓練了 105 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 760/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4583, 訓練了 139 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 761/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4583, 訓練了 144 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 762/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4583, 訓練了 149 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 763/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9082, 訓練了 236 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 764/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9082, 訓練了 241 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 765/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9082, 訓練了 246 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 766/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.3895, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 767/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.3895, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 768/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.3895, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 769/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.8350, 訓練了 92 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 770/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.8350, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 771/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.8350, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 772/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4302, 訓練了 137 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 773/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4302, 訓練了 142 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 774/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4302, 訓練了 147 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 775/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1967, 訓練了 230 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 776/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1967, 訓練了 235 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 777/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1967, 訓練了 240 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 778/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 13.2559, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 779/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 13.2559, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 780/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 13.2559, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 781/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2518, 訓練了 91 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 782/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2518, 訓練了 96 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 783/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2518, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 784/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9225, 訓練了 138 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 785/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9225, 訓練了 143 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 786/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9225, 訓練了 148 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 787/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4260, 訓練了 229 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 788/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4260, 訓練了 234 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 789/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4260, 訓練了 239 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 790/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 33.8967, 訓練了 358 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 791/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 11.2084, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 792/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 11.2084, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 793/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5036, 訓練了 106 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 794/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5036, 訓練了 111 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 795/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5036, 訓練了 116 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 796/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.3980, 訓練了 132 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 797/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.3980, 訓練了 137 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 798/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.3980, 訓練了 142 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 799/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1987, 訓練了 253 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 800/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1987, 訓練了 258 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 801/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1987, 訓練了 263 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 802/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.2877, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 803/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.2877, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 804/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.2877, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 805/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6319, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 806/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6319, 訓練了 112 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 807/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6319, 訓練了 117 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 808/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1889, 訓練了 138 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 809/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1889, 訓練了 143 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 810/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1889, 訓練了 148 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 811/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1768, 訓練了 218 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 812/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1768, 訓練了 223 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 813/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1768, 訓練了 228 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 814/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 13.0219, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 815/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 13.0219, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 816/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 13.0219, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 817/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4142, 訓練了 110 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 818/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4142, 訓練了 115 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 819/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4142, 訓練了 120 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 820/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8646, 訓練了 138 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 821/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8646, 訓練了 143 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 822/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8646, 訓練了 148 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 823/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.4313, 訓練了 236 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 824/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.4313, 訓練了 241 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 825/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.4313, 訓練了 246 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 826/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 30.9432, 訓練了 383 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 827/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 20.6242, 訓練了 453 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 828/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 20.6242, 訓練了 458 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 829/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3564, 訓練了 86 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 830/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3564, 訓練了 91 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 831/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3564, 訓練了 96 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 832/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0144, 訓練了 135 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 833/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0144, 訓練了 140 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 834/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0144, 訓練了 145 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 835/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3357, 訓練了 243 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 836/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3357, 訓練了 248 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 837/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3357, 訓練了 253 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 838/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0817, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 839/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0817, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 840/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0817, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 841/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0085, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 842/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0085, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 843/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0085, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 844/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0051, 訓練了 141 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 845/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0051, 訓練了 146 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 846/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0051, 訓練了 151 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 847/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5161, 訓練了 217 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 848/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5161, 訓練了 222 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 849/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5161, 訓練了 227 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 850/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 35.4323, 訓練了 357 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 851/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 12.8047, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 852/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 12.8047, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 853/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8341, 訓練了 94 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 854/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2010, 訓練了 122 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 855/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2010, 訓練了 127 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 856/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1887, 訓練了 124 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 857/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1887, 訓練了 129 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 858/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1887, 訓練了 134 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 859/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9787, 訓練了 241 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 860/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9787, 訓練了 246 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 861/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9787, 訓練了 251 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 862/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 51.8530, 訓練了 295 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 863/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 15.9876, 訓練了 459 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 864/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 12.4304, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 865/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.8680, 訓練了 38 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 866/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.8680, 訓練了 43 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 867/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.8680, 訓練了 48 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 868/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1307, 訓練了 58 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 869/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1307, 訓練了 63 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 870/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1307, 訓練了 68 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 871/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7329, 訓練了 92 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 872/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7329, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 873/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7329, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 874/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7082, 訓練了 208 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 875/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7082, 訓練了 213 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 876/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7082, 訓練了 218 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 877/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2513, 訓練了 40 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 878/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2513, 訓練了 45 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 879/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2513, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 880/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4996, 訓練了 57 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 881/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4996, 訓練了 62 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 882/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4996, 訓練了 67 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 883/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9946, 訓練了 99 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 884/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9946, 訓練了 104 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 885/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9946, 訓練了 109 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 886/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.8418, 訓練了 195 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 887/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.8418, 訓練了 200 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 888/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.8418, 訓練了 205 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 889/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7966, 訓練了 46 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 890/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7966, 訓練了 51 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 891/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6357, 訓練了 77 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 892/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2236, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 893/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2236, 訓練了 81 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 894/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2236, 訓練了 86 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 895/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.8543, 訓練了 83 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 896/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.8543, 訓練了 88 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 897/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.8543, 訓練了 93 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 898/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.7143, 訓練了 217 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 899/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.4933, 訓練了 240 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 900/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.1842, 訓練了 325 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 901/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9088, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 902/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9088, 訓練了 55 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 903/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9088, 訓練了 60 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 904/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.0500, 訓練了 56 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 905/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.0500, 訓練了 61 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 906/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.0500, 訓練了 66 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 907/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8435, 訓練了 111 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 908/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8435, 訓練了 116 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 909/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8435, 訓練了 121 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 910/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9451, 訓練了 208 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 911/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9451, 訓練了 213 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 912/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9451, 訓練了 218 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 913/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9244, 訓練了 52 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 914/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9244, 訓練了 57 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 915/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9244, 訓練了 62 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 916/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3443, 訓練了 55 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 917/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3443, 訓練了 60 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 918/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3443, 訓練了 65 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 919/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5205, 訓練了 89 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 920/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5205, 訓練了 94 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 921/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5205, 訓練了 99 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 922/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.4935, 訓練了 195 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 923/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.4935, 訓練了 200 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 924/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.4935, 訓練了 205 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 925/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3652, 訓練了 56 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 926/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3652, 訓練了 61 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 927/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3652, 訓練了 66 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 928/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.4114, 訓練了 56 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 929/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.4114, 訓練了 61 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 930/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.4114, 訓練了 66 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 931/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.6168, 訓練了 93 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 932/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.6168, 訓練了 98 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 933/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.6168, 訓練了 103 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 934/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.9277, 訓練了 231 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 935/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.9277, 訓練了 236 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 936/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.9277, 訓練了 241 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 937/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5883, 訓練了 42 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 938/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5883, 訓練了 47 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 939/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5883, 訓練了 52 epochs\n",
      "  目前最佳 RMSE: 3.3855\n",
      "\n",
      "組合 940/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.2177, 訓練了 57 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 941/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.2177, 訓練了 62 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 942/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.2177, 訓練了 67 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 943/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9423, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 944/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9423, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 945/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9423, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 946/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3939, 訓練了 204 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 947/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3939, 訓練了 209 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 948/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3939, 訓練了 214 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 949/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0829, 訓練了 39 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 950/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0829, 訓練了 44 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 951/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0829, 訓練了 49 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 952/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.6985, 訓練了 58 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 953/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.6985, 訓練了 63 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 954/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.6985, 訓練了 68 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 955/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3077, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 956/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3077, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 957/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3077, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 958/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.4755, 訓練了 184 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 959/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.4755, 訓練了 189 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 960/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.4755, 訓練了 194 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 961/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2344, 訓練了 55 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 962/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2344, 訓練了 60 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 963/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2344, 訓練了 65 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 964/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2118, 訓練了 58 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 965/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2118, 訓練了 63 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 966/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2118, 訓練了 68 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 967/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3081, 訓練了 88 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 968/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3081, 訓練了 93 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 969/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3081, 訓練了 98 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 970/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.6971, 訓練了 247 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 971/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.6971, 訓練了 252 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 972/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.6971, 訓練了 257 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 973/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0308, 訓練了 116 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 974/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0308, 訓練了 121 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 975/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0308, 訓練了 126 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 976/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7345, 訓練了 199 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 977/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7345, 訓練了 204 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 978/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7345, 訓練了 209 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 979/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2612, 訓練了 367 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 980/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2612, 訓練了 372 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 981/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2612, 訓練了 377 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 982/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 24.7572, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 983/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 24.7572, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 984/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 24.7572, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 985/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9151, 訓練了 126 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 986/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9151, 訓練了 131 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 987/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9151, 訓練了 136 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 988/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8669, 訓練了 210 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 989/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8669, 訓練了 215 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 990/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8669, 訓練了 220 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 991/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8813, 訓練了 298 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 992/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8813, 訓練了 303 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 993/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8813, 訓練了 308 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 994/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 25.7307, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 995/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 25.7307, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 996/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 25.7307, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 997/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4832, 訓練了 148 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 998/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4832, 訓練了 153 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 999/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4832, 訓練了 158 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1000/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3781, 訓練了 189 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1001/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3781, 訓練了 194 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1002/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3781, 訓練了 199 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1003/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5010, 訓練了 310 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1004/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5010, 訓練了 315 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1005/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5010, 訓練了 320 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1006/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 68.0048, 訓練了 216 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1007/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 43.1281, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1008/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 43.1281, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1009/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0334, 訓練了 138 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1010/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0334, 訓練了 143 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1011/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0334, 訓練了 148 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1012/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3561, 訓練了 214 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1013/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3561, 訓練了 219 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1014/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3561, 訓練了 224 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1015/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4243, 訓練了 355 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1016/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4243, 訓練了 360 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1017/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4243, 訓練了 365 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1018/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 23.9480, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1019/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 23.9480, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1020/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 23.9480, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1021/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8281, 訓練了 160 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1022/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8281, 訓練了 165 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1023/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8281, 訓練了 170 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1024/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.1645, 訓練了 182 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1025/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.1645, 訓練了 187 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1026/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.1645, 訓練了 192 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1027/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3346, 訓練了 298 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1028/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3346, 訓練了 303 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1029/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3346, 訓練了 308 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1030/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 27.2515, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1031/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 27.2515, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1032/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 27.2515, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1033/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0583, 訓練了 143 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1034/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0583, 訓練了 148 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1035/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0583, 訓練了 153 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1036/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8443, 訓練了 189 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1037/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8443, 訓練了 194 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1038/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8443, 訓練了 199 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1039/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9151, 訓練了 277 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1040/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9151, 訓練了 282 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1041/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9151, 訓練了 287 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1042/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 67.9494, 訓練了 216 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1043/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 43.0857, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1044/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 43.0857, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1045/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2037, 訓練了 122 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1046/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2037, 訓練了 127 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1047/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2037, 訓練了 132 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1048/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9507, 訓練了 196 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1049/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9507, 訓練了 201 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1050/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9507, 訓練了 206 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1051/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5982, 訓練了 382 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1052/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5982, 訓練了 387 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1053/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5982, 訓練了 392 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1054/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 24.3492, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1055/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 24.3492, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1056/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 24.3492, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1057/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5506, 訓練了 145 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1058/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5506, 訓練了 150 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1059/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5506, 訓練了 155 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1060/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6885, 訓練了 190 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1061/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6885, 訓練了 195 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1062/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6885, 訓練了 200 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1063/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7405, 訓練了 316 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1064/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7405, 訓練了 321 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1065/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7405, 訓練了 326 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1066/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 27.3626, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1067/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 27.3626, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1068/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 27.3626, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1069/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1958, 訓練了 133 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1070/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1958, 訓練了 138 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1071/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5312, 訓練了 182 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1072/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0090, 訓練了 189 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1073/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0090, 訓練了 194 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1074/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0090, 訓練了 199 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1075/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9644, 訓練了 309 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1076/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9644, 訓練了 314 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1077/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9644, 訓練了 319 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1078/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 34.0349, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1079/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 34.0349, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1080/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 34.0349, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1081/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1464, 訓練了 74 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1082/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1464, 訓練了 79 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1083/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1464, 訓練了 84 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1084/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9114, 訓練了 100 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1085/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9114, 訓練了 105 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1086/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9114, 訓練了 110 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1087/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3137, 訓練了 195 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1088/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3137, 訓練了 200 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1089/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3137, 訓練了 205 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1090/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0677, 訓練了 396 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1091/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0677, 訓練了 401 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1092/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0677, 訓練了 406 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1093/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8943, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1094/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8943, 訓練了 78 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1095/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8943, 訓練了 83 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1096/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6201, 訓練了 108 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1097/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6201, 訓練了 113 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1098/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6201, 訓練了 118 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1099/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2673, 訓練了 155 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1100/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2673, 訓練了 160 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1101/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2673, 訓練了 165 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1102/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5088, 訓練了 360 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1103/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5088, 訓練了 365 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1104/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5088, 訓練了 370 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1105/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.6235, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1106/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.6235, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1107/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.6235, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1108/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4005, 訓練了 98 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1109/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4005, 訓練了 103 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1110/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4005, 訓練了 108 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1111/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8754, 訓練了 175 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1112/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8754, 訓練了 180 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1113/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8754, 訓練了 185 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1114/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 15.2184, 訓練了 391 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1115/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 15.2184, 訓練了 396 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1116/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 15.2184, 訓練了 401 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1117/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3768, 訓練了 68 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1118/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3768, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1119/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3768, 訓練了 78 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1120/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7777, 訓練了 105 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1121/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7777, 訓練了 110 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1122/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7777, 訓練了 115 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1123/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1389, 訓練了 189 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1124/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1389, 訓練了 194 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1125/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0603, 訓練了 221 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1126/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2575, 訓練了 396 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1127/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2575, 訓練了 401 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1128/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2575, 訓練了 406 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1129/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5679, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1130/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5679, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1131/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5679, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1132/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.7942, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1133/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.7942, 訓練了 106 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1134/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.7942, 訓練了 111 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1135/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1264, 訓練了 154 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1136/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1264, 訓練了 159 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1137/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1264, 訓練了 164 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1138/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5677, 訓練了 359 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1139/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5677, 訓練了 364 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1140/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5677, 訓練了 369 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1141/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2417, 訓練了 67 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1142/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4605, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1143/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4605, 訓練了 106 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1144/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1212, 訓練了 113 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1145/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1212, 訓練了 118 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1146/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1212, 訓練了 123 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1147/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.7094, 訓練了 156 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1148/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.7094, 訓練了 161 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1149/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.7094, 訓練了 166 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1150/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 17.0649, 訓練了 396 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1151/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 17.0649, 訓練了 401 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1152/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 17.0649, 訓練了 406 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1153/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.9991, 訓練了 65 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1154/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.9991, 訓練了 70 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1155/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.9991, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1156/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8686, 訓練了 99 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1157/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8686, 訓練了 104 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1158/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8686, 訓練了 109 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1159/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7512, 訓練了 180 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1160/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7512, 訓練了 185 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1161/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9594, 訓練了 231 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1162/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0638, 訓練了 383 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1163/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0638, 訓練了 388 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1164/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0638, 訓練了 393 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1165/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4006, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1166/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4006, 訓練了 80 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1167/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4006, 訓練了 85 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1168/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8351, 訓練了 100 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1169/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8351, 訓練了 105 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1170/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8351, 訓練了 110 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1171/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3244, 訓練了 156 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1172/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3244, 訓練了 161 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1173/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3244, 訓練了 166 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1174/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2827, 訓練了 363 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1175/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2827, 訓練了 368 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1176/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2827, 訓練了 373 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1177/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3063, 訓練了 69 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1178/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3063, 訓練了 74 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1179/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3063, 訓練了 79 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1180/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6905, 訓練了 104 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1181/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6905, 訓練了 109 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1182/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6905, 訓練了 114 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1183/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7961, 訓練了 155 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1184/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7961, 訓練了 160 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1185/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7961, 訓練了 165 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1186/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 16.8574, 訓練了 389 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1187/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 16.8574, 訓練了 394 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1188/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 16.8574, 訓練了 399 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1189/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1021, 訓練了 44 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1190/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1021, 訓練了 49 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1191/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1021, 訓練了 54 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1192/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7417, 訓練了 49 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1193/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7417, 訓練了 54 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1194/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7417, 訓練了 59 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1195/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3937, 訓練了 83 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1196/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3937, 訓練了 88 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1197/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3937, 訓練了 93 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1198/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2081, 訓練了 150 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1199/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2081, 訓練了 155 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1200/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2081, 訓練了 160 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1201/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.8128, 訓練了 42 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1202/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7623, 訓練了 64 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1203/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7623, 訓練了 69 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1204/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3232, 訓練了 44 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1205/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3232, 訓練了 49 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1206/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3232, 訓練了 54 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1207/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7480, 訓練了 91 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1208/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7480, 訓練了 96 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1209/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7480, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1210/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7802, 訓練了 137 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1211/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7802, 訓練了 142 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1212/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7802, 訓練了 147 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1213/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9695, 訓練了 43 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1214/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9695, 訓練了 48 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1215/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9695, 訓練了 53 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1216/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5729, 訓練了 57 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1217/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5729, 訓練了 62 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1218/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5729, 訓練了 67 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1219/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.1452, 訓練了 69 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1220/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.1452, 訓練了 74 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1221/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.1452, 訓練了 79 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1222/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.4612, 訓練了 164 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1223/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.4612, 訓練了 169 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1224/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.4612, 訓練了 174 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1225/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5603, 訓練了 32 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1226/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5603, 訓練了 37 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1227/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5603, 訓練了 42 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1228/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6892, 訓練了 45 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1229/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6892, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1230/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6892, 訓練了 55 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1231/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0836, 訓練了 90 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1232/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0836, 訓練了 95 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1233/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0836, 訓練了 100 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1234/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6073, 訓練了 151 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1235/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6073, 訓練了 156 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1236/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6073, 訓練了 161 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1237/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6630, 訓練了 44 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1238/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3406, 訓練了 70 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1239/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3406, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1240/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7395, 訓練了 44 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1241/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7395, 訓練了 49 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1242/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7395, 訓練了 54 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1243/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3268, 訓練了 70 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1244/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3268, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1245/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3268, 訓練了 80 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1246/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7529, 訓練了 137 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1247/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7529, 訓練了 142 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1248/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7529, 訓練了 147 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1249/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.1543, 訓練了 33 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1250/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1543, 訓練了 38 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1251/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1543, 訓練了 43 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1252/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6210, 訓練了 44 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1253/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6210, 訓練了 49 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1254/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6210, 訓練了 54 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1255/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3795, 訓練了 65 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1256/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3795, 訓練了 70 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1257/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3795, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1258/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.4577, 訓練了 170 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1259/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.4577, 訓練了 175 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1260/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.4553, 訓練了 204 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1261/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9697, 訓練了 39 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1262/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9697, 訓練了 44 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1263/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9697, 訓練了 49 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1264/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.0525, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1265/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.0525, 訓練了 55 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1266/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.0525, 訓練了 60 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1267/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8807, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1268/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8807, 訓練了 80 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1269/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8807, 訓練了 85 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1270/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3886, 訓練了 143 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1271/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3886, 訓練了 148 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1272/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3886, 訓練了 153 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1273/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1632, 訓練了 33 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1274/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1632, 訓練了 38 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1275/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4319, 訓練了 65 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1276/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4246, 訓練了 45 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1277/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4246, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1278/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4246, 訓練了 55 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1279/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7743, 訓練了 65 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1280/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7743, 訓練了 70 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1281/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7743, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1282/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0396, 訓練了 143 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1283/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0396, 訓練了 148 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1284/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0396, 訓練了 153 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1285/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7654, 訓練了 65 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1286/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7654, 訓練了 70 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1287/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7654, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1288/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.4504, 訓練了 46 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1289/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.4504, 訓練了 51 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1290/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.4504, 訓練了 56 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1291/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1355, 訓練了 71 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1292/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1355, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1293/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1355, 訓練了 81 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1294/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3568, 訓練了 154 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1295/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3568, 訓練了 159 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "組合 1296/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3568, 訓練了 164 epochs\n",
      "  目前最佳 RMSE: 3.2177\n",
      "\n",
      "網格搜索完成!\n",
      "總耗時: 7269.02 秒\n",
      "\n",
      "最佳參數組合:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "最佳測試 RMSE: 3.2177\n",
      "\n",
      "使用最佳參數建立最終模型...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "最終模型評估結果:\n",
      "測試集 MSE: 10.3536\n",
      "測試集 RMSE: 3.2177 天\n",
      "R^2 分數: 0.6621\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 設置隨機種子，確保結果可重現\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(50)  # 固定隨機種子\n",
    "\n",
    "# MLP 模型定義\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size=600, hidden_sizes=[256, 128, 64], output_size=1, dropout_rate=0.3):\n",
    "        super(MLPModel, self).__init__()\n",
    "        \n",
    "        # 第一個隱藏層\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_sizes[0])\n",
    "        \n",
    "        # 第二個隱藏層\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_sizes[1])\n",
    "        \n",
    "        # 第三個隱藏層\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_sizes[2])\n",
    "        \n",
    "        # 輸出層\n",
    "        self.fc_out = nn.Linear(hidden_sizes[2], output_size)\n",
    "        \n",
    "        # Dropout 層\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# 訓練和評估模型的函數\n",
    "def train_and_evaluate(model, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, \n",
    "                      optimizer, criterion, num_epochs=500, batch_size=8, patience=20, min_delta=0.001):\n",
    "    \n",
    "    # 準備 DataLoader\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 早停相關變數\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    wait = 0\n",
    "    stopped_epoch = 0\n",
    "    \n",
    "    # 記錄訓練過程\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    # 訓練循環\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # 計算平均訓練損失\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        # 計算測試損失\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test_tensor)\n",
    "            test_loss = criterion(test_outputs, y_test_tensor).item()\n",
    "            test_losses.append(test_loss)\n",
    "        \n",
    "        # 早停判斷\n",
    "        if test_loss < best_loss - min_delta:\n",
    "            best_loss = test_loss\n",
    "            wait = 0\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                stopped_epoch = epoch + 1\n",
    "                break\n",
    "    \n",
    "    # 如果完成所有 epoch\n",
    "    if stopped_epoch == 0:\n",
    "        stopped_epoch = num_epochs\n",
    "    \n",
    "    # 載入最佳模型\n",
    "    if best_model is not None:\n",
    "        model.load_state_dict(best_model)\n",
    "    \n",
    "    # 最終評估\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_predictions = model(X_test_tensor)\n",
    "        final_test_loss = criterion(test_predictions, y_test_tensor).item()\n",
    "        final_test_rmse = np.sqrt(final_test_loss)\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'final_test_loss': final_test_loss,\n",
    "        'final_test_rmse': final_test_rmse,\n",
    "        'epochs_trained': stopped_epoch,\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "        'best_epoch': stopped_epoch - wait if wait < patience else stopped_epoch\n",
    "    }\n",
    "\n",
    "# 網格搜索函數\n",
    "def grid_search(X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, param_grid, verbose=True):\n",
    "    # 生成所有參數組合\n",
    "    param_combinations = list(itertools.product(*param_grid.values()))\n",
    "    param_keys = list(param_grid.keys())\n",
    "    \n",
    "    # 最佳結果追蹤\n",
    "    best_rmse = float('inf')\n",
    "    best_params = None\n",
    "    best_result = None\n",
    "    all_results = []\n",
    "    \n",
    "    # 總組合數\n",
    "    total_combinations = len(param_combinations)\n",
    "    \n",
    "    print(f\"開始網格搜索 - 總共 {total_combinations} 種參數組合\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 逐一嘗試每種參數組合\n",
    "    for i, combination in enumerate(param_combinations):\n",
    "        # 構建當前參數字典\n",
    "        current_params = {param_keys[j]: combination[j] for j in range(len(param_keys))}\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n組合 {i+1}/{total_combinations}:\")\n",
    "            for k, v in current_params.items():\n",
    "                print(f\"  {k}: {v}\")\n",
    "        \n",
    "        # 設置隨機種子確保公平比較\n",
    "        set_seed(50)\n",
    "        \n",
    "        # 初始化模型和優化器\n",
    "        hidden_sizes = current_params.get('hidden_sizes', [256, 128, 64])\n",
    "        dropout_rate = current_params.get('dropout_rate', 0.3)\n",
    "        \n",
    "        model = MLPModel(\n",
    "            input_size=X_train_tensor.shape[1], \n",
    "            hidden_sizes=hidden_sizes, \n",
    "            output_size=1, \n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "        \n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(), \n",
    "            lr=current_params.get('learning_rate', 0.001),\n",
    "            weight_decay=current_params.get('weight_decay', 1e-5)\n",
    "        )\n",
    "        \n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # 訓練和評估\n",
    "        result = train_and_evaluate(\n",
    "            model, \n",
    "            X_train_tensor, y_train_tensor, \n",
    "            X_test_tensor, y_test_tensor,\n",
    "            optimizer, \n",
    "            criterion,\n",
    "            num_epochs=current_params.get('num_epochs', 500),\n",
    "            batch_size=current_params.get('batch_size', 8),\n",
    "            patience=current_params.get('patience', 20)\n",
    "        )\n",
    "        \n",
    "        # 儲存結果\n",
    "        result_entry = {\n",
    "            'params': current_params,\n",
    "            'test_rmse': result['final_test_rmse'],\n",
    "            'epochs_trained': result['epochs_trained'],\n",
    "            'best_epoch': result['best_epoch']\n",
    "        }\n",
    "        all_results.append(result_entry)\n",
    "        \n",
    "        # 更新最佳結果\n",
    "        if result['final_test_rmse'] < best_rmse:\n",
    "            best_rmse = result['final_test_rmse']\n",
    "            best_params = current_params\n",
    "            best_result = result\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  訓練完成: RMSE = {result['final_test_rmse']:.4f}, 訓練了 {result['epochs_trained']} epochs\")\n",
    "            print(f\"  目前最佳 RMSE: {best_rmse:.4f}\")\n",
    "    \n",
    "    # 總耗時\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(\"\\n網格搜索完成!\")\n",
    "    print(f\"總耗時: {total_time:.2f} 秒\")\n",
    "    print(\"\\n最佳參數組合:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(f\"最佳測試 RMSE: {best_rmse:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'best_params': best_params,\n",
    "        'best_result': best_result,\n",
    "        'all_results': all_results\n",
    "    }\n",
    "\n",
    "# 使用方式 (假設您已經準備好了資料)\n",
    "# 這裡先確保 X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor 已經準備好\n",
    "\n",
    "# 定義網格搜索的參數範圍\n",
    "param_grid = {\n",
    "    'hidden_sizes': [\n",
    "        [64, 32, 16],\n",
    "        [128, 64, 32],\n",
    "        [256, 128, 64],\n",
    "        [512, 256, 128]\n",
    "    ],\n",
    "    'learning_rate': [0.0005, 0.001, 0.003],\n",
    "    'weight_decay': [1e-6, 1e-5, 1e-4],\n",
    "    'dropout_rate': [0.2, 0.3, 0.4],\n",
    "    'batch_size': [4, 8, 16, 32],\n",
    "    'patience': [15, 20, 25]\n",
    "}\n",
    "\n",
    "# 執行網格搜索\n",
    "grid_results = grid_search(X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, param_grid)\n",
    "\n",
    "# 使用最佳參數建立最終模型\n",
    "best_params = grid_results['best_params']\n",
    "print(\"\\n使用最佳參數建立最終模型...\")\n",
    "\n",
    "# 設置隨機種子\n",
    "set_seed(50)\n",
    "\n",
    "# 初始化最終模型\n",
    "final_model = MLPModel(\n",
    "    input_size=X_train_tensor.shape[1], \n",
    "    hidden_sizes=best_params['hidden_sizes'], \n",
    "    output_size=1, \n",
    "    dropout_rate=best_params['dropout_rate']\n",
    ")\n",
    "\n",
    "final_optimizer = optim.Adam(\n",
    "    final_model.parameters(), \n",
    "    lr=best_params['learning_rate'],\n",
    "    weight_decay=best_params['weight_decay']\n",
    ")\n",
    "\n",
    "final_criterion = nn.MSELoss()\n",
    "\n",
    "# 訓練最終模型\n",
    "final_result = train_and_evaluate(\n",
    "    final_model, \n",
    "    X_train_tensor, y_train_tensor, \n",
    "    X_test_tensor, y_test_tensor,\n",
    "    final_optimizer, \n",
    "    final_criterion,\n",
    "    num_epochs=500,  # 可以設置為更大的值\n",
    "    batch_size=best_params['batch_size'],\n",
    "    patience=best_params['patience']\n",
    ")\n",
    "\n",
    "# 繪製最終模型的損失曲線\n",
    "plt.rcParams['font.family'] = 'Heiti TC'  # 設置中文字體\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(final_result['train_losses']) + 1), final_result['train_losses'], label='訓練損失', color='blue')\n",
    "plt.plot(range(1, len(final_result['test_losses']) + 1), final_result['test_losses'], label='測試損失', color='red')\n",
    "plt.axvline(x=final_result['best_epoch'], color='green', linestyle='--', label=f'最佳模型 (epoch {final_result[\"best_epoch\"]})')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('損失 (MSE)')\n",
    "plt.title('最終模型訓練過程')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('final_model_loss_curve_feature5.png')\n",
    "plt.show()\n",
    "\n",
    "# 評估最終模型\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    # 測試集評估\n",
    "    test_predictions = final_model(X_test_tensor)\n",
    "    test_mse = final_criterion(test_predictions, y_test_tensor).item()\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    \n",
    "    # 計算 R^2 分數\n",
    "    y_test_mean = torch.mean(y_test_tensor)\n",
    "    ss_tot = torch.sum((y_test_tensor - y_test_mean) ** 2)\n",
    "    ss_res = torch.sum((y_test_tensor - test_predictions) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    print(\"\\n最終模型評估結果:\")\n",
    "    print(f'測試集 MSE: {test_mse:.4f}')\n",
    "    print(f'測試集 RMSE: {test_rmse:.4f} 天')\n",
    "    print(f'R^2 分數: {r2.item():.4f}')\n",
    "    \n",
    "    # 繪製實際值與預測值的比較圖\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # 轉換為 numpy 數組以便繪圖\n",
    "    y_test_np = y_test_tensor.cpu().numpy().flatten()\n",
    "    test_pred_np = test_predictions.cpu().numpy().flatten()\n",
    "    \n",
    "    # 繪製散點圖\n",
    "    plt.scatter(y_test_np, test_pred_np, color='blue', label='預測 vs 實際')\n",
    "    \n",
    "    # 繪製理想線 (y=x)\n",
    "    min_val = min(y_test_np.min(), test_pred_np.min())\n",
    "    max_val = max(y_test_np.max(), test_pred_np.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='理想線 (y=x)')\n",
    "    \n",
    "    plt.xlabel('實際開花日 (天)')\n",
    "    plt.ylabel('預測開花日 (天)')\n",
    "    plt.title('最終模型: 實際開花日 vs 預測開花日')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('final_model_predictions_feature5.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcd79585-2d6f-431d-aa9c-1a60697bbbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 繪製實際值與預測值的比較圖\n",
    "plt.figure(figsize=(10, 10))\n",
    "    \n",
    "# 轉換為 numpy 數組以便繪圖\n",
    "y_test_np = y_test_tensor.cpu().numpy().flatten()\n",
    "test_pred_np = test_predictions.cpu().numpy().flatten()\n",
    "    \n",
    "# 繪製散點圖\n",
    "plt.scatter(y_test_np, test_pred_np, color='lightpink', edgecolor='black', label='預測 vs 實際')\n",
    "    \n",
    " # 繪製理想線 (y=x)\n",
    "min_val = min(y_test_np.min(), test_pred_np.min())\n",
    "max_val = max(y_test_np.max(), test_pred_np.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='理想線 (y=x)')\n",
    "    \n",
    "plt.xlabel('實際開花所需日數')\n",
    "plt.ylabel('預測開花所需日數')\n",
    "plt.title('預測 vs 實際')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('final_model_predictions_feature5.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5dc0d48-b62f-45a9-a087-02cb56f3decc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試集 MSE: 10.3536\n"
     ]
    }
   ],
   "source": [
    "test_mse = final_criterion(test_predictions, y_test_tensor).item()\n",
    "print(f'測試集 MSE: {test_mse:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Data_Analysis]",
   "language": "python",
   "name": "conda-env-Data_Analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
