{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd4165c7-d2d6-48fe-8fb7-4e540ed713fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b67d56aa-5464-483a-954d-c7634c178128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>年</th>\n",
       "      <th>月</th>\n",
       "      <th>日</th>\n",
       "      <th>當地氣壓</th>\n",
       "      <th>海平面氣壓</th>\n",
       "      <th>最大降水量</th>\n",
       "      <th>一小時降水量</th>\n",
       "      <th>10分鐘降水量</th>\n",
       "      <th>平均氣溫</th>\n",
       "      <th>最高氣溫</th>\n",
       "      <th>最低氣溫</th>\n",
       "      <th>平均濕度</th>\n",
       "      <th>最小濕度</th>\n",
       "      <th>日照時間</th>\n",
       "      <th>開花日</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1011.7</td>\n",
       "      <td>1012.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>41.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1020.2</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>51.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1021.3</td>\n",
       "      <td>1022.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1004.6</td>\n",
       "      <td>1005.3</td>\n",
       "      <td>20.2</td>\n",
       "      <td>13.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1016.3</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23371</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>1006.9</td>\n",
       "      <td>1009.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>12.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>51.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23372</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>1008.1</td>\n",
       "      <td>1011.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23373</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>1013.4</td>\n",
       "      <td>1016.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23374</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>1017.1</td>\n",
       "      <td>1020.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>53.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23375</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>1003.4</td>\n",
       "      <td>1006.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>55.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23376 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          年   月   日    當地氣壓   海平面氣壓  最大降水量  一小時降水量  10分鐘降水量  平均氣溫  最高氣溫  最低氣溫  \\\n",
       "0      1961   1   1  1011.7  1012.4    0.0     0.0      0.0   2.1   7.9  -3.9   \n",
       "1      1961   1   2  1020.2  1021.0    0.0     0.0      0.0   1.5   9.2  -3.3   \n",
       "2      1961   1   3  1021.3  1022.1    0.1     0.8      0.0   2.5   7.3  -2.4   \n",
       "3      1961   1   4  1004.6  1005.3   20.2    13.9      3.2   4.7  11.5   0.6   \n",
       "4      1961   1   5  1016.3  1017.0    0.0     0.0      0.0   3.8   7.7   1.4   \n",
       "...     ...  ..  ..     ...     ...    ...     ...      ...   ...   ...   ...   \n",
       "23371  2024  12  27  1006.9  1009.9    0.0     0.0      0.0   7.4  12.7   3.8   \n",
       "23372  2024  12  28  1008.1  1011.1    0.0     0.0      0.0   5.4  11.5   1.4   \n",
       "23373  2024  12  29  1013.4  1016.4    0.0     0.0      0.0   6.0  12.3   0.5   \n",
       "23374  2024  12  30  1017.1  1020.1    0.0     0.0      0.0   6.2  10.3   3.5   \n",
       "23375  2024  12  31  1003.4  1006.4    0.0     0.0      0.0   8.0  14.6   2.8   \n",
       "\n",
       "       平均濕度  最小濕度  日照時間  開花日  \n",
       "0      41.0  15.0   8.6    0  \n",
       "1      51.0  26.0   8.7    0  \n",
       "2      58.0  37.0   5.4    0  \n",
       "3      60.0  38.0   1.0    0  \n",
       "4      33.0  19.0   8.3    0  \n",
       "...     ...   ...   ...  ...  \n",
       "23371  51.0  38.0   6.1    0  \n",
       "23372  59.0  36.0   7.5    0  \n",
       "23373  54.0  31.0   8.9    0  \n",
       "23374  53.0  32.0   5.0    0  \n",
       "23375  55.0  37.0   7.6    0  \n",
       "\n",
       "[23376 rows x 15 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 讀資料\n",
    "df = pd.read_csv('Dataset/weather_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8080dd-d8c6-4419-95b0-9c1c2145b412",
   "metadata": {},
   "source": [
    "### 將年, 月, 日欄位重新命名為 year, month, day ，合併成 date 並轉為 datetime格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58e4b0d-1fb1-47fb-ad98-b084f7a79ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新命名 年 月 日 的欄位\n",
    "df = df.rename(columns={'年': 'year', '月': 'month', '日': 'day'})\n",
    "\n",
    "# 合併為 datetime 欄位\n",
    "df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "\n",
    "# 排序\n",
    "df = df.sort_values(['year', 'month', 'day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c59bc6-3ded-4815-8686-9ee7cbdcc30e",
   "metadata": {},
   "source": [
    "### 選定訓練時需要的特徵值，並只取每年前120日的氣象資料當作模型的 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4ffa14-d7cd-44e8-a891-3087ff86fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 特徵挑選與目標\n",
    "feature_cols = ['當地氣壓', '海平面氣壓', '平均氣溫', '最高氣溫', '最低氣溫', '最大降水量', '一小時降水量', '10分鐘降水量',  '平均濕度', '最小濕度', '日照時間']\n",
    "yearly_sequences = []\n",
    "\n",
    "for year, group in df.groupby('year'):\n",
    "    # 只取該年按日期排序後的前120筆\n",
    "    sub = group.sort_values('date').iloc[:120]\n",
    "    # 取 feature_cols 對應的欄位\n",
    "    if len(sub) == 120:  # 避免資料天數不足\n",
    "        yearly_sequences.append(sub[feature_cols].to_numpy())\n",
    "    else:\n",
    "        print(f'⚠️ {year} 年資料不足120天，已略過')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc10855-177b-4fa8-9354-678412c5cd72",
   "metadata": {},
   "source": [
    "### 將每年開花所需的日數當作模型的 y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f0c634b-019e-4264-932e-4bb61e14b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = np.stack(yearly_sequences)  # shape=(年數, 120, 特徵數)\n",
    "y = []\n",
    "for year, group in df.groupby('year'):\n",
    "    # 排序後的資料\n",
    "    group_sorted = group.sort_values('date')\n",
    "    # 找到開花日=1的那一行\n",
    "    bloom_rows = group_sorted[group_sorted['開花日'] == 1]\n",
    "    if len(bloom_rows) > 0:\n",
    "        # 計算開花日是該年的第幾天 (0-based)\n",
    "        first_date = group_sorted['date'].iloc[0]\n",
    "        bloom_date = bloom_rows['date'].iloc[0]\n",
    "        days_diff = (bloom_date - first_date).days\n",
    "        y.append(days_diff)\n",
    "    else:\n",
    "        print(f\"警告: {year}年沒有開花日記錄\")\n",
    "        # 跳過這一年的資料\n",
    "# y 已經是一個 list，長度等於 yearly_sequences\n",
    "y_np = np.array(y)   # shape=(年數, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a922c05-1ac4-4131-ae38-d8abc9d4f881",
   "metadata": {},
   "source": [
    "### 將 X 標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a93914-9d41-4c07-a0a3-5a52fe006d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假設 X_np.shape = (年數, 120, 6)\n",
    "X_flat = X_np.reshape((X_np.shape[0], -1))\n",
    "\n",
    "# 對每個特徵單獨標準化\n",
    "X_scaled = np.zeros_like(X_np)\n",
    "for i in range(X_np.shape[2]):  # 遍歷6個特徵\n",
    "    feature_data = X_np[:, :, i]  # (年數, 120)\n",
    "    scaler = StandardScaler()\n",
    "    # 將所有年份的該特徵數據平攤用於擬合scaler\n",
    "    scaler.fit(feature_data.reshape(-1, 1))\n",
    "    # 對每年的該特徵進行轉換\n",
    "    for j in range(X_np.shape[0]):  # 遍歷每一年\n",
    "        X_scaled[j, :, i] = scaler.transform(X_np[j, :, i].reshape(-1, 1)).flatten()\n",
    "\n",
    "# 然後再平攤用於模型輸入\n",
    "X_flat_scaled = X_scaled.reshape((X_scaled.shape[0], -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220a2dd7-36b2-45e6-a054-97f9bac46ea2",
   "metadata": {},
   "source": [
    "### 將 X, y 以 8:2 年代前後順序做切分訓練集與測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90048689-896e-4d65-b192-e939ee1f5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時間順序分割 (最後20%作為測試集)\n",
    "split_index = int(0.8 * len(X_flat_scaled))\n",
    "X_train, X_test = X_flat_scaled[:split_index], X_flat_scaled[split_index:]\n",
    "y_train, y_test = y_np[:split_index], y_np[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfb7fb6f-f625-48ec-aeb7-275f0f625c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轉換為張量\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dde6776-c913-4f01-bfa7-c89f8281d3d7",
   "metadata": {},
   "source": [
    "### 設定random seed（50）\n",
    "### 建立MLP模型：3 of Fully Connected Layers、Loss：MSE、Adam Optimizer、early stop\n",
    "### 設定網格搜索：hidden state, learning rate, weight Decay, Dropout Rate, Batch Size, Patience\n",
    "### 使用 R^2 評估模型\n",
    "### Loss 數據視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7547bba5-233d-44fb-bdba-119bd4993def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始網格搜索 - 總共 1296 種參數組合\n",
      "\n",
      "組合 1/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.1983, 訓練了 310 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 2/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1983, 訓練了 315 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 3/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1983, 訓練了 320 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 4/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.0061, 訓練了 490 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 5/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.0061, 訓練了 495 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 6/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.0061, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 7/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 61.1474, 訓練了 340 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 8/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 43.8435, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 9/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 43.8435, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 10/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 70.5672, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 11/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 70.5672, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 12/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 70.5672, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 13/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8717, 訓練了 346 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 14/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8717, 訓練了 351 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 15/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8717, 訓練了 356 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 16/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 56.3677, 訓練了 219 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 17/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 15.1620, 訓練了 450 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 18/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.8463, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 19/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 57.6296, 訓練了 340 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 20/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 49.8021, 訓練了 415 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 21/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 37.7689, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 22/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 74.8930, 訓練了 345 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 23/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 74.8930, 訓練了 350 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 24/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 71.9421, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 4.1983\n",
      "\n",
      "組合 25/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.7491, 訓練了 372 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 26/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.7491, 訓練了 377 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 27/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.7491, 訓練了 382 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 28/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5367, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 29/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5367, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 30/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5367, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 31/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 71.3839, 訓練了 219 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 32/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 71.3839, 訓練了 224 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 33/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 39.7706, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 34/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 78.7633, 訓練了 16 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 35/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 78.7633, 訓練了 21 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 36/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 78.7633, 訓練了 26 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 37/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0765, 訓練了 343 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 38/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0765, 訓練了 348 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 39/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0765, 訓練了 353 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 40/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7827, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 41/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7827, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 42/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7827, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 43/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 73.8146, 訓練了 178 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 44/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 53.6788, 訓練了 415 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 45/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 42.7812, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 46/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 70.0744, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 47/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 70.0744, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 48/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 70.0744, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 49/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9271, 訓練了 324 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 50/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9271, 訓練了 329 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 51/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8970, 訓練了 355 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 52/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 47.6941, 訓練了 272 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 53/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.7461, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 54/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.7461, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 55/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 71.2393, 訓練了 229 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 56/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 57.4459, 訓練了 380 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 57/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 42.2781, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 58/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 74.8863, 訓練了 345 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 59/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 74.8863, 訓練了 350 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 60/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 71.9487, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 61/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3176, 訓練了 340 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 62/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8689, 訓練了 378 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 63/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7892, 訓練了 406 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 64/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 10.1574, 訓練了 489 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 65/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.8091, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 66/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.8091, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 67/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 54.9880, 訓練了 375 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 68/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 50.1067, 訓練了 417 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 69/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 39.6126, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 70/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 78.7630, 訓練了 16 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 71/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 78.7630, 訓練了 21 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 72/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 78.7630, 訓練了 26 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 73/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0204, 訓練了 330 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 74/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0204, 訓練了 335 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 75/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0204, 訓練了 340 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 76/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1590, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 77/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1590, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 78/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1590, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 79/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 70.6498, 訓練了 232 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 80/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 43.0660, 訓練了 495 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 81/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 41.8924, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 82/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 70.1506, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 83/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 70.1506, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 84/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 70.1506, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 85/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.6527, 訓練了 316 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 86/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.6527, 訓練了 321 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 87/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.6527, 訓練了 326 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 88/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 17.7978, 訓練了 414 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 89/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2841, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 90/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2841, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 91/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 67.2672, 訓練了 275 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 92/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 39.4544, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 93/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 39.4544, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 94/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 74.9024, 訓練了 345 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 95/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 72.5893, 訓練了 464 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 96/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 71.9724, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 97/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8396, 訓練了 357 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 98/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8396, 訓練了 362 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 99/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8396, 訓練了 367 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 100/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.1994, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 101/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.1994, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 102/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.1994, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 103/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 59.4743, 訓練了 344 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 104/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 51.3201, 訓練了 417 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 105/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 39.6503, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 106/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 78.7629, 訓練了 16 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 107/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 78.7629, 訓練了 21 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 108/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 72.3928, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 109/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6148, 訓練了 185 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 110/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6148, 訓練了 190 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 111/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6148, 訓練了 195 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 112/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.7132, 訓練了 261 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 113/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.7132, 訓練了 266 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 114/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.7132, 訓練了 271 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 115/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 11.0626, 訓練了 375 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 116/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 11.0626, 訓練了 380 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 117/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5275, 訓練了 443 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 118/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 46.8282, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 119/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 46.8282, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 120/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 46.8282, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 121/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7501, 訓練了 198 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 122/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7501, 訓練了 203 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 123/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7501, 訓練了 208 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 124/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1748, 訓練了 274 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 125/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1748, 訓練了 279 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 126/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1748, 訓練了 284 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 127/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.2252, 訓練了 411 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 128/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4965, 訓練了 463 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 129/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2776, 訓練了 491 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 130/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 48.5843, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 131/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 48.5843, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 132/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 48.5843, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 133/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8397, 訓練了 182 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 134/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8397, 訓練了 187 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 135/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8397, 訓練了 192 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 136/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0099, 訓練了 255 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 137/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9546, 訓練了 278 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 138/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9546, 訓練了 283 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 139/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 22.5708, 訓練了 340 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 140/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4330, 訓練了 495 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 141/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4330, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 142/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 72.7924, 訓練了 254 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 143/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 48.0915, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 144/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 48.0915, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 145/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9109, 訓練了 165 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 146/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9109, 訓練了 170 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 147/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9109, 訓練了 175 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 148/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4737, 訓練了 262 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 149/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4737, 訓練了 267 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 150/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4737, 訓練了 272 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 151/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 59.0787, 訓練了 179 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 152/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6350, 訓練了 473 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 153/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6350, 訓練了 478 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 154/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 47.0087, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 155/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 47.0087, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 156/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 47.0087, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 157/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5783, 訓練了 162 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 158/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5783, 訓練了 167 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 159/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2111, 訓練了 214 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 160/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6774, 訓練了 271 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 161/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4432, 訓練了 299 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 162/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4432, 訓練了 304 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 163/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 20.1099, 訓練了 339 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 164/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.7745, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 165/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.7745, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 166/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 48.2803, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 167/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 48.2803, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 168/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 48.2803, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 169/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1037, 訓練了 172 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 170/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1037, 訓練了 177 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 171/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1037, 訓練了 182 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 172/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0775, 訓練了 263 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 173/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0775, 訓練了 268 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 174/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0775, 訓練了 273 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 175/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 12.3655, 訓練了 370 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 176/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 12.3655, 訓練了 375 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 177/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 12.3655, 訓練了 380 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 178/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 72.8002, 訓練了 254 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 179/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 48.1205, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 180/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 48.1205, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 181/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.8409, 訓練了 165 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 182/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.8409, 訓練了 170 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 183/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.8409, 訓練了 175 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 184/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.0283, 訓練了 252 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 185/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.0283, 訓練了 257 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 186/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.0283, 訓練了 262 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 187/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.3189, 訓練了 416 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 188/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.3189, 訓練了 421 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 189/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.3189, 訓練了 426 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 190/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 46.5338, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 191/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 46.5338, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 192/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 46.5338, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 193/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.4673, 訓練了 156 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 194/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.4673, 訓練了 161 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 195/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.4673, 訓練了 166 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 196/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5680, 訓練了 271 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 197/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5680, 訓練了 276 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 198/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5680, 訓練了 281 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 199/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 40.7865, 訓練了 262 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 200/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 40.7865, 訓練了 267 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 201/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3037, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 202/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 47.1121, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 203/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 47.1121, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 204/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 47.1121, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 205/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3630, 訓練了 185 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 206/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3630, 訓練了 190 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 207/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2380, 訓練了 226 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 208/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.8106, 訓練了 269 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 209/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.8106, 訓練了 274 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 210/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.8106, 訓練了 279 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 211/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7876, 訓練了 453 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 212/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7876, 訓練了 458 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 213/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7876, 訓練了 463 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 214/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 75.5305, 訓練了 179 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 215/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 49.1301, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 216/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 49.1301, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 217/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9821, 訓練了 60 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 218/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9821, 訓練了 65 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 219/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9821, 訓練了 70 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 220/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5434, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 221/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5434, 訓練了 106 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 222/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5434, 訓練了 111 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 223/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6768, 訓練了 157 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 224/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6768, 訓練了 162 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 225/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6768, 訓練了 167 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 226/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3007, 訓練了 383 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 227/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3007, 訓練了 388 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 228/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3007, 訓練了 393 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 229/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9174, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 230/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9174, 訓練了 78 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 231/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9174, 訓練了 83 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 232/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6409, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 233/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6409, 訓練了 112 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 234/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6409, 訓練了 117 epochs\n",
      "  目前最佳 RMSE: 3.7491\n",
      "\n",
      "組合 235/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.6513, 訓練了 156 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 236/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.6513, 訓練了 161 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 237/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.6513, 訓練了 166 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 238/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.2040, 訓練了 312 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 239/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.2040, 訓練了 317 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 240/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.2040, 訓練了 322 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 241/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9327, 訓練了 74 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 242/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9327, 訓練了 79 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 243/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9327, 訓練了 84 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 244/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5724, 訓練了 106 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 245/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5724, 訓練了 111 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 246/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5724, 訓練了 116 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 247/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0188, 訓練了 159 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 248/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0188, 訓練了 164 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 249/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0188, 訓練了 169 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 250/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2424, 訓練了 316 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 251/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2424, 訓練了 321 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 252/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2424, 訓練了 326 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 253/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0247, 訓練了 64 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 254/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0247, 訓練了 69 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 255/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0247, 訓練了 74 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 256/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7197, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 257/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7197, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 258/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7197, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 259/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1962, 訓練了 153 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 260/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1962, 訓練了 158 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 261/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1962, 訓練了 163 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 262/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6419, 訓練了 383 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 263/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6419, 訓練了 388 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 264/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6419, 訓練了 393 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 265/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4975, 訓練了 65 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 266/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4975, 訓練了 70 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 267/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4975, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 268/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6657, 訓練了 93 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 269/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6657, 訓練了 98 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 270/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6657, 訓練了 103 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 271/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.8138, 訓練了 163 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 272/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.8138, 訓練了 168 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 273/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.8138, 訓練了 173 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 274/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.1851, 訓練了 312 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 275/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.1851, 訓練了 317 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 276/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.1851, 訓練了 322 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 277/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.1938, 訓練了 69 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 278/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1938, 訓練了 74 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 279/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1938, 訓練了 79 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 280/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.1440, 訓練了 104 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 281/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1440, 訓練了 109 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 282/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1440, 訓練了 114 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 283/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3723, 訓練了 185 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 284/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3723, 訓練了 190 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 285/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3723, 訓練了 195 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 286/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2830, 訓練了 316 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 287/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2830, 訓練了 321 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 288/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2830, 訓練了 326 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 289/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1061, 訓練了 60 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 290/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1061, 訓練了 65 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 291/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1061, 訓練了 70 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 292/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3858, 訓練了 100 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 293/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3858, 訓練了 105 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 294/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3858, 訓練了 110 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 295/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3398, 訓練了 150 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 296/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3398, 訓練了 155 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 297/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3398, 訓練了 160 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 298/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4780, 訓練了 353 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 299/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.8955, 訓練了 388 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 300/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.8955, 訓練了 393 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 301/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1931, 訓練了 64 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 302/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1931, 訓練了 69 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 303/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1931, 訓練了 74 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 304/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.8795, 訓練了 94 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 305/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.8795, 訓練了 99 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 306/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.8795, 訓練了 104 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 307/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0970, 訓練了 164 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 308/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0970, 訓練了 169 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 309/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0970, 訓練了 174 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 310/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0601, 訓練了 316 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 311/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0601, 訓練了 321 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 312/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0601, 訓練了 326 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 313/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2170, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 314/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2170, 訓練了 81 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 315/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2170, 訓練了 86 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 316/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4878, 訓練了 109 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 317/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4878, 訓練了 114 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 318/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4878, 訓練了 119 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 319/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9816, 訓練了 172 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 320/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9816, 訓練了 177 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 321/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9816, 訓練了 182 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 322/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1856, 訓練了 313 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 323/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1856, 訓練了 318 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 324/1296:\n",
      "  hidden_sizes: [64, 32, 16]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1856, 訓練了 323 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 325/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3160, 訓練了 224 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 326/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3160, 訓練了 229 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 327/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3160, 訓練了 234 epochs\n",
      "  目前最佳 RMSE: 3.6513\n",
      "\n",
      "組合 328/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.3375, 訓練了 363 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 329/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.3375, 訓練了 368 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 330/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.3375, 訓練了 373 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 331/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 13.0250, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 332/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 13.0250, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 333/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 13.0250, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 334/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 70.3598, 訓練了 375 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 335/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 62.6384, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 336/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 62.6384, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 337/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0317, 訓練了 231 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 338/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0317, 訓練了 236 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 339/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0317, 訓練了 241 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 340/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.7743, 訓練了 336 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 341/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5425, 訓練了 366 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 342/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5425, 訓練了 371 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 343/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 12.8592, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 344/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 12.8592, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 345/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 12.8592, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 346/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 73.8936, 訓練了 313 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 347/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 72.8572, 訓練了 370 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 348/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 72.8572, 訓練了 375 epochs\n",
      "  目前最佳 RMSE: 3.3375\n",
      "\n",
      "組合 349/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.1823, 訓練了 281 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 350/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.1823, 訓練了 286 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 351/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.1823, 訓練了 291 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 352/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6518, 訓練了 363 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 353/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6518, 訓練了 368 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 354/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6518, 訓練了 373 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 355/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 34.0589, 訓練了 376 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 356/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 12.7354, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 357/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 12.7354, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 358/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 75.6928, 訓練了 238 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 359/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 75.6928, 訓練了 243 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 360/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 75.6928, 訓練了 248 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 361/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8684, 訓練了 246 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 362/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6934, 訓練了 283 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 363/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6934, 訓練了 288 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 364/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0774, 訓練了 332 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 365/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0774, 訓練了 337 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 366/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0774, 訓練了 342 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 367/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 12.5593, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 368/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 12.5593, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 369/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 12.5593, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 370/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 70.6376, 訓練了 376 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 371/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 62.9400, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 372/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 62.9400, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 373/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0985, 訓練了 228 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 374/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0985, 訓練了 233 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 375/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0985, 訓練了 238 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 376/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6608, 訓練了 339 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 377/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6608, 訓練了 344 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 378/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6608, 訓練了 349 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 379/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 12.9126, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 380/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 12.9126, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 381/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 12.9126, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 382/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 75.7003, 訓練了 248 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 383/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 72.3837, 訓練了 381 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 384/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 68.1762, 訓練了 497 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 385/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5982, 訓練了 236 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 386/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5982, 訓練了 241 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 387/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5723, 訓練了 267 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 388/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1067, 訓練了 371 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 389/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.7170, 訓練了 406 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 390/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.7170, 訓練了 411 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 391/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 13.5625, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 392/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 13.5625, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 393/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 13.5625, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 394/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 75.8822, 訓練了 238 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 395/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 73.9294, 訓練了 343 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 396/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 73.9294, 訓練了 348 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 397/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0634, 訓練了 259 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 398/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0634, 訓練了 264 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 399/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0634, 訓練了 269 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 400/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1167, 訓練了 341 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 401/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1167, 訓練了 346 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 402/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1167, 訓練了 351 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 403/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 15.7455, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 404/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 15.7455, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 405/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 15.7455, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 406/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 62.5272, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 407/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 62.5272, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 408/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 62.5272, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 409/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6710, 訓練了 223 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 410/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6710, 訓練了 228 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 411/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6710, 訓練了 233 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 412/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7159, 訓練了 365 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 413/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7159, 訓練了 370 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 414/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7159, 訓練了 375 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 415/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 12.4753, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 416/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 12.4753, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 417/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 12.4753, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 418/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 73.7221, 訓練了 313 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 419/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 72.1749, 訓練了 381 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 420/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 68.3322, 訓練了 497 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 421/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7801, 訓練了 228 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 422/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7801, 訓練了 233 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 423/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7801, 訓練了 238 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 424/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2241, 訓練了 381 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 425/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.9946, 訓練了 410 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 426/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.9946, 訓練了 415 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 427/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 15.4299, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 428/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 15.4299, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 429/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 15.4299, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 430/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 75.8573, 訓練了 238 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 431/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 73.7520, 訓練了 343 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 432/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 73.7520, 訓練了 348 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 433/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6441, 訓練了 123 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 434/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6441, 訓練了 128 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 435/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6441, 訓練了 133 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 436/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0893, 訓練了 185 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 437/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0893, 訓練了 190 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 438/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0893, 訓練了 195 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 439/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.2562, 訓練了 323 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 440/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.2562, 訓練了 328 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 441/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.2562, 訓練了 333 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 442/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 28.5886, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 443/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 28.5886, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 444/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 28.5886, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 445/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4789, 訓練了 121 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 446/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4789, 訓練了 126 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 447/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4789, 訓練了 131 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 448/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6600, 訓練了 175 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 449/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6600, 訓練了 180 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 450/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6600, 訓練了 185 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 451/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6977, 訓練了 319 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 452/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6977, 訓練了 324 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 453/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6977, 訓練了 329 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 454/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 49.1293, 訓練了 430 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 455/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 36.3262, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 456/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 36.3262, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 457/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2950, 訓練了 136 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 458/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2950, 訓練了 141 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 459/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2950, 訓練了 146 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 460/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2954, 訓練了 190 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 461/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2954, 訓練了 195 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 462/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2954, 訓練了 200 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 463/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9757, 訓練了 304 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 464/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9757, 訓練了 309 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 465/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9757, 訓練了 314 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 466/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 55.9354, 訓練了 338 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 467/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 37.1302, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 468/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 37.1302, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 469/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3225, 訓練了 115 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 470/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2483, 訓練了 136 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 471/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2483, 訓練了 141 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 472/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.2425, 訓練了 184 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 473/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.2425, 訓練了 189 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 474/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.2425, 訓練了 194 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 475/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6522, 訓練了 329 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 476/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6522, 訓練了 334 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 477/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6522, 訓練了 339 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 478/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 26.2752, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 479/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 26.2752, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 480/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 26.2752, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 481/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7245, 訓練了 115 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 482/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7245, 訓練了 120 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 483/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7245, 訓練了 125 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 484/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7615, 訓練了 194 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 485/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7615, 訓練了 199 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 486/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7615, 訓練了 204 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 487/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8380, 訓練了 313 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 488/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8380, 訓練了 318 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 489/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8380, 訓練了 323 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 490/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 37.5062, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 491/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 37.5062, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 492/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 37.5062, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 493/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1960, 訓練了 140 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 494/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1960, 訓練了 145 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 495/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1960, 訓練了 150 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 496/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1823, 訓練了 181 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 497/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1823, 訓練了 186 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 498/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1823, 訓練了 191 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 499/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7872, 訓練了 297 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 500/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7872, 訓練了 302 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 501/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7872, 訓練了 307 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 502/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 55.9549, 訓練了 338 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 503/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 37.1332, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 504/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 37.1332, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 505/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3650, 訓練了 142 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 506/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3650, 訓練了 147 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 507/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3650, 訓練了 152 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 508/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.1252, 訓練了 174 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 509/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.1252, 訓練了 179 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 510/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.1252, 訓練了 184 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 511/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8632, 訓練了 313 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 512/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8632, 訓練了 318 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 513/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8632, 訓練了 323 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 514/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 25.9154, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 515/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 25.9154, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 516/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 25.9154, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 517/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3000, 訓練了 131 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 518/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3000, 訓練了 136 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 519/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3000, 訓練了 141 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 520/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1933, 訓練了 187 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 521/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1933, 訓練了 192 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 522/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1933, 訓練了 197 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 523/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9187, 訓練了 291 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 524/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9187, 訓練了 296 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 525/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9187, 訓練了 301 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 526/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 49.9178, 訓練了 421 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 527/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 33.8438, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 528/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 33.8438, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 529/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0713, 訓練了 136 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 530/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0713, 訓練了 141 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 531/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0713, 訓練了 146 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 532/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.9678, 訓練了 209 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 533/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.9678, 訓練了 214 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 534/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.9678, 訓練了 219 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 535/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5235, 訓練了 314 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 536/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5235, 訓練了 319 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 537/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5235, 訓練了 324 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 538/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 50.9530, 訓練了 372 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 539/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 37.2444, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 540/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 37.2444, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 541/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4222, 訓練了 57 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 542/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4222, 訓練了 62 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 543/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4222, 訓練了 67 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 544/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3534, 訓練了 68 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 545/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3534, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 546/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3534, 訓練了 78 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 547/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5084, 訓練了 120 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 548/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5084, 訓練了 125 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 549/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5084, 訓練了 130 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 550/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3072, 訓練了 267 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 551/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3072, 訓練了 272 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 552/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3072, 訓練了 277 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 553/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8852, 訓練了 59 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 554/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8852, 訓練了 64 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 555/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4603, 訓練了 117 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 556/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3669, 訓練了 77 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 557/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3669, 訓練了 82 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 558/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3669, 訓練了 87 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 559/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.7256, 訓練了 120 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 560/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.7256, 訓練了 125 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 561/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.7256, 訓練了 130 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 562/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.6447, 訓練了 281 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 563/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.6447, 訓練了 286 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 564/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.6447, 訓練了 291 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 565/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2502, 訓練了 79 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 566/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2502, 訓練了 84 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 567/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2502, 訓練了 89 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 568/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2495, 訓練了 72 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 569/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2495, 訓練了 77 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 570/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2495, 訓練了 82 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 571/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9914, 訓練了 121 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 572/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9914, 訓練了 126 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 573/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9914, 訓練了 131 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 574/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 9.9007, 訓練了 229 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 575/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9590, 訓練了 333 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 576/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9590, 訓練了 338 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 577/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4975, 訓練了 58 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 578/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4975, 訓練了 63 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 579/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4975, 訓練了 68 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 580/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6317, 訓練了 71 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 581/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6317, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 582/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6317, 訓練了 81 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 583/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.1060, 訓練了 129 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 584/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.1060, 訓練了 134 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 585/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.1060, 訓練了 139 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 586/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3537, 訓練了 267 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 587/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3537, 訓練了 272 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 588/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3537, 訓練了 277 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 589/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1699, 訓練了 48 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 590/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1699, 訓練了 53 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 591/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1699, 訓練了 58 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 592/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1085, 訓練了 82 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 593/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1085, 訓練了 87 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 594/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1085, 訓練了 92 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 595/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.7721, 訓練了 142 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 596/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.7721, 訓練了 147 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 597/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.7721, 訓練了 152 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 598/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.4130, 訓練了 281 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 599/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.4130, 訓練了 286 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 600/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.4130, 訓練了 291 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 601/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1366, 訓練了 58 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 602/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1366, 訓練了 63 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 603/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1366, 訓練了 68 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 604/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1126, 訓練了 71 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 605/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1126, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 606/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1126, 訓練了 81 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 607/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4410, 訓練了 119 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 608/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4410, 訓練了 124 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 609/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4410, 訓練了 129 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 610/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 10.0030, 訓練了 229 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 611/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9827, 訓練了 311 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 612/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9827, 訓練了 316 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 613/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9823, 訓練了 56 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 614/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9823, 訓練了 61 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 615/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6359, 訓練了 90 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 616/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6984, 訓練了 70 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 617/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6984, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 618/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6984, 訓練了 80 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 619/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1013, 訓練了 119 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 620/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1013, 訓練了 124 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 621/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1013, 訓練了 129 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 622/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1882, 訓練了 244 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 623/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1882, 訓練了 249 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 624/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1882, 訓練了 254 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 625/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4923, 訓練了 91 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 626/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4923, 訓練了 96 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 627/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4923, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 628/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1257, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 629/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1257, 訓練了 78 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 630/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1257, 訓練了 83 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 631/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.8036, 訓練了 123 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 632/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.8036, 訓練了 128 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 633/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4431, 訓練了 158 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 634/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7149, 訓練了 300 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 635/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7149, 訓練了 305 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 636/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7149, 訓練了 310 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 637/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8280, 訓練了 54 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 638/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1665, 訓練了 78 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 639/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1665, 訓練了 83 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 640/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1537, 訓練了 71 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 641/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1537, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 642/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1537, 訓練了 81 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 643/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9752, 訓練了 133 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 644/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9752, 訓練了 138 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 645/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9752, 訓練了 143 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 646/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9127, 訓練了 277 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 647/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9127, 訓練了 282 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 648/1296:\n",
      "  hidden_sizes: [128, 64, 32]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9127, 訓練了 287 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 649/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1376, 訓練了 178 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 650/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1376, 訓練了 183 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 651/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1376, 訓練了 188 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 652/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3807, 訓練了 256 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 653/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9035, 訓練了 281 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 654/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9035, 訓練了 286 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 655/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6879, 訓練了 481 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 656/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6879, 訓練了 486 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 657/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6879, 訓練了 491 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 658/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 53.8345, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 659/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 53.8345, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 660/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 53.8345, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 661/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9380, 訓練了 197 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 662/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9380, 訓練了 202 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 663/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9380, 訓練了 207 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 664/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6671, 訓練了 252 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 665/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6671, 訓練了 257 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 666/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6671, 訓練了 262 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 667/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.4380, 訓練了 397 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 668/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.4380, 訓練了 402 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 669/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.4380, 訓練了 407 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 670/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 70.3568, 訓練了 283 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 671/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 59.1932, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 672/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 59.1932, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 673/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.3537, 訓練了 198 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 674/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.3537, 訓練了 203 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 675/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.3537, 訓練了 208 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 676/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6370, 訓練了 266 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 677/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6370, 訓練了 271 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 678/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6370, 訓練了 276 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 679/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2495, 訓練了 418 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 680/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2495, 訓練了 423 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 681/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2495, 訓練了 428 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 682/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 74.6550, 訓練了 207 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 683/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 74.6550, 訓練了 212 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 684/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 62.5902, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 685/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4836, 訓練了 160 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 686/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4836, 訓練了 165 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 687/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4836, 訓練了 170 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 688/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2388, 訓練了 251 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 689/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2388, 訓練了 256 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 690/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2388, 訓練了 261 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 691/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2079, 訓練了 459 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 692/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2079, 訓練了 464 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 693/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2079, 訓練了 469 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 694/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 53.8725, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 695/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 53.8725, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 696/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 53.8725, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 697/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0273, 訓練了 184 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 698/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0273, 訓練了 189 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 699/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5142, 訓練了 257 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 700/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.8428, 訓練了 243 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 701/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.8428, 訓練了 248 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 702/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.8428, 訓練了 253 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 703/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1916, 訓練了 416 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 704/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1916, 訓練了 421 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 705/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1916, 訓練了 426 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 706/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 69.4089, 訓練了 283 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 707/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 58.2531, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 708/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 58.2531, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 709/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4583, 訓練了 215 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 710/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4583, 訓練了 220 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 711/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4583, 訓練了 225 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 712/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1998, 訓練了 268 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 713/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1998, 訓練了 273 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 714/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1998, 訓練了 278 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 715/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 47.0210, 訓練了 231 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 716/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.0199, 訓練了 411 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 717/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1635, 訓練了 449 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 718/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 77.1524, 訓練了 126 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 719/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 77.1524, 訓練了 131 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 720/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 72.1490, 訓練了 283 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 721/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4029, 訓練了 172 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 722/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4029, 訓練了 177 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 723/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4029, 訓練了 182 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 724/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.4796, 訓練了 234 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 725/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3694, 訓練了 257 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 726/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3694, 訓練了 262 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 727/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6785, 訓練了 454 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 728/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6785, 訓練了 459 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 729/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6785, 訓練了 464 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 730/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 53.6674, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 731/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 53.6674, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 732/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 53.6674, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 733/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3061, 訓練了 205 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 734/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3061, 訓練了 210 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 735/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.8786, 訓練了 239 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 736/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4966, 訓練了 252 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 737/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4966, 訓練了 257 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 738/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4966, 訓練了 262 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 739/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2571, 訓練了 480 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 740/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2571, 訓練了 485 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 741/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2571, 訓練了 490 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 742/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 73.9472, 訓練了 207 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 743/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 73.9472, 訓練了 212 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 744/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 67.1109, 訓練了 396 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 745/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5684, 訓練了 188 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 746/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5684, 訓練了 193 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 747/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5684, 訓練了 198 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 748/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5190, 訓練了 256 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 749/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5190, 訓練了 261 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 750/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5190, 訓練了 266 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 751/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.3169, 訓練了 414 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 752/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.9587, 訓練了 445 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 753/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.9587, 訓練了 450 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 754/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 74.9111, 訓練了 206 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 755/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 74.9111, 訓練了 211 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 756/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 74.9111, 訓練了 216 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 757/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1526, 訓練了 87 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 758/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1526, 訓練了 92 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 759/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1526, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 760/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4135, 訓練了 134 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 761/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4135, 訓練了 139 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 762/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4135, 訓練了 144 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 763/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0373, 訓練了 235 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 764/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0373, 訓練了 240 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 765/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0373, 訓練了 245 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 766/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 9.0976, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 767/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 9.0976, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 768/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 9.0976, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 769/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0403, 訓練了 88 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 770/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0403, 訓練了 93 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 771/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0403, 訓練了 98 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 772/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.4070, 訓練了 138 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 773/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.4070, 訓練了 143 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 774/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.4070, 訓練了 148 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 775/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2649, 訓練了 223 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 776/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2649, 訓練了 228 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 777/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2649, 訓練了 233 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 778/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 64.4901, 訓練了 202 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 779/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 18.1729, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 780/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 18.1729, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 781/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4618, 訓練了 111 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 782/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4618, 訓練了 116 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 783/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4618, 訓練了 121 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 784/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3364, 訓練了 137 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 785/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3364, 訓練了 142 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 786/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3364, 訓練了 147 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 787/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7588, 訓練了 237 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 788/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7588, 訓練了 242 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 789/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7588, 訓練了 247 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 790/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 34.5717, 訓練了 457 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 791/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 34.5717, 訓練了 462 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 792/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 34.5717, 訓練了 467 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 793/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1338, 訓練了 91 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 794/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1338, 訓練了 96 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 795/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1338, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 796/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6059, 訓練了 135 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 797/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6059, 訓練了 140 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 798/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6059, 訓練了 145 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 799/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6327, 訓練了 237 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 800/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6327, 訓練了 242 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 801/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6327, 訓練了 247 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 802/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 11.2528, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 803/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 11.2528, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 804/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 11.2528, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 805/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0866, 訓練了 100 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 806/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0866, 訓練了 105 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 807/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0866, 訓練了 110 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 808/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2348, 訓練了 138 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 809/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2348, 訓練了 143 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 810/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2348, 訓練了 148 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 811/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0619, 訓練了 225 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 812/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0619, 訓練了 230 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 813/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0619, 訓練了 235 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 814/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 33.6305, 訓練了 408 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 815/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 19.3623, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 816/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 19.3623, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 817/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5480, 訓練了 106 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 818/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5480, 訓練了 111 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 819/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5480, 訓練了 116 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 820/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1694, 訓練了 140 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 821/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1694, 訓練了 145 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 822/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1694, 訓練了 150 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 823/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3330, 訓練了 231 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 824/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3330, 訓練了 236 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 825/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3330, 訓練了 241 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 826/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 73.8246, 訓練了 118 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 827/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 22.1728, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 828/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 22.1728, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 829/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3419, 訓練了 91 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 830/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3419, 訓練了 96 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 831/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3419, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 832/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5561, 訓練了 147 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 833/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5561, 訓練了 152 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 834/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5561, 訓練了 157 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 835/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3416, 訓練了 236 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 836/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3416, 訓練了 241 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 837/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3416, 訓練了 246 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 838/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 9.5082, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 839/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 9.5082, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 840/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 9.5082, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 841/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3749, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 842/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3749, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 843/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3749, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 844/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.1016, 訓練了 133 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 845/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.1016, 訓練了 138 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 846/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.1016, 訓練了 143 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 847/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7155, 訓練了 213 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 848/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7155, 訓練了 218 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 849/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7155, 訓練了 223 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 850/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 22.0817, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 851/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 22.0817, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 852/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 22.0817, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 853/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.1513, 訓練了 108 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 854/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1513, 訓練了 113 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 855/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1513, 訓練了 118 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 856/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6581, 訓練了 140 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 857/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6581, 訓練了 145 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 858/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6581, 訓練了 150 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 859/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6745, 訓練了 226 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 860/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6745, 訓練了 231 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 861/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6745, 訓練了 236 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 862/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 73.8273, 訓練了 118 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 863/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 25.3950, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 864/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 25.3950, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 865/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5550, 訓練了 38 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 866/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5550, 訓練了 43 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 867/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5550, 訓練了 48 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 868/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2442, 訓練了 57 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 869/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2442, 訓練了 62 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 870/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2442, 訓練了 67 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 871/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2738, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 872/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2738, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 873/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2738, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 874/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.6395, 訓練了 190 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 875/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.6395, 訓練了 195 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 876/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.6395, 訓練了 200 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 877/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7401, 訓練了 38 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 878/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7401, 訓練了 43 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 879/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7401, 訓練了 48 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 880/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4741, 訓練了 62 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 881/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4741, 訓練了 67 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 882/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4741, 訓練了 72 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 883/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9370, 訓練了 96 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 884/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9370, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 885/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9370, 訓練了 106 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 886/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3327, 訓練了 181 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 887/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3327, 訓練了 186 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 888/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3327, 訓練了 191 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 889/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5922, 訓練了 42 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 890/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5922, 訓練了 47 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 891/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5922, 訓練了 52 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 892/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7500, 訓練了 56 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 893/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7500, 訓練了 61 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 894/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7500, 訓練了 66 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 895/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0914, 訓練了 87 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 896/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0914, 訓練了 92 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 897/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0914, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 898/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.7025, 訓練了 196 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 899/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.6848, 訓練了 220 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 900/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.6848, 訓練了 225 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 901/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1749, 訓練了 61 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 902/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1749, 訓練了 66 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 903/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1749, 訓練了 71 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 904/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6037, 訓練了 64 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 905/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6037, 訓練了 69 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 906/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6037, 訓練了 74 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 907/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.8880, 訓練了 89 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 908/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.8880, 訓練了 94 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 909/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.8880, 訓練了 99 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 910/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5882, 訓練了 190 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 911/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5882, 訓練了 195 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 912/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5882, 訓練了 200 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 913/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0448, 訓練了 43 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 914/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0448, 訓練了 48 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 915/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0448, 訓練了 53 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 916/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2522, 訓練了 55 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 917/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2522, 訓練了 60 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 918/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2522, 訓練了 65 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 919/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1107, 訓練了 109 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 920/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1107, 訓練了 114 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 921/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1107, 訓練了 119 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 922/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5860, 訓練了 181 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 923/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5860, 訓練了 186 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 924/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5860, 訓練了 191 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 925/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.6724, 訓練了 47 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 926/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.6724, 訓練了 52 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 927/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.6724, 訓練了 57 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 928/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2250, 訓練了 52 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 929/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2250, 訓練了 57 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 930/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2250, 訓練了 62 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 931/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3087, 訓練了 108 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 932/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3087, 訓練了 113 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 933/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3087, 訓練了 118 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 934/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.6878, 訓練了 196 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 935/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.6725, 訓練了 220 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 936/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.6725, 訓練了 225 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 937/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6377, 訓練了 53 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 938/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6377, 訓練了 58 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 939/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6377, 訓練了 63 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 940/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7821, 訓練了 55 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 941/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7821, 訓練了 60 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 942/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7821, 訓練了 65 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 943/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9788, 訓練了 98 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 944/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7886, 訓練了 121 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 945/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7886, 訓練了 126 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 946/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9977, 訓練了 189 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 947/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9977, 訓練了 194 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 948/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9977, 訓練了 199 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 949/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3612, 訓練了 40 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 950/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3612, 訓練了 45 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 951/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3612, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 952/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2190, 訓練了 64 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 953/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2190, 訓練了 69 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 954/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2190, 訓練了 74 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 955/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.0089, 訓練了 105 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 956/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.0089, 訓練了 110 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 957/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.0089, 訓練了 115 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 958/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5312, 訓練了 197 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 959/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5312, 訓練了 202 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 960/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5312, 訓練了 207 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 961/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7461, 訓練了 45 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 962/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7461, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 963/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7461, 訓練了 55 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 964/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.4967, 訓練了 57 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 965/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.4967, 訓練了 62 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 966/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.4967, 訓練了 67 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 967/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9231, 訓練了 94 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 968/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9231, 訓練了 99 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 969/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9231, 訓練了 104 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 970/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.7597, 訓練了 216 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 971/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.5380, 訓練了 243 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 972/1296:\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.0636, 訓練了 279 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 973/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6303, 訓練了 125 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 974/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6303, 訓練了 130 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 975/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6303, 訓練了 135 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 976/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.1951, 訓練了 205 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 977/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.1951, 訓練了 210 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 978/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.1951, 訓練了 215 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 979/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3530, 訓練了 329 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 980/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3530, 訓練了 334 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 981/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3530, 訓練了 339 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 982/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 36.2160, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 983/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 36.2160, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 984/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 36.2160, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 985/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0879, 訓練了 115 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 986/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0879, 訓練了 120 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 987/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0879, 訓練了 125 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 988/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3865, 訓練了 184 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 989/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3865, 訓練了 189 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 990/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3865, 訓練了 194 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 991/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9435, 訓練了 300 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 992/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9435, 訓練了 305 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 993/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9435, 訓練了 310 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 994/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 39.8282, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 995/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 39.8282, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 996/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 39.8282, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 997/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7661, 訓練了 130 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 998/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7661, 訓練了 135 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 999/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7661, 訓練了 140 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1000/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9283, 訓練了 187 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1001/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9283, 訓練了 192 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1002/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9283, 訓練了 197 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1003/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.0062, 訓練了 296 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1004/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.0062, 訓練了 301 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1005/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.0062, 訓練了 306 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1006/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 58.8213, 訓練了 376 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1007/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 48.4686, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1008/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 48.4686, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1009/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8167, 訓練了 118 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1010/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8167, 訓練了 123 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1011/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8167, 訓練了 128 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1012/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9145, 訓練了 186 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1013/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9145, 訓練了 191 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1014/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9145, 訓練了 196 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1015/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 10.1144, 訓練了 304 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1016/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4765, 訓練了 394 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1017/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4339, 訓練了 422 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1018/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 35.8512, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1019/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 35.8512, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1020/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 35.8512, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1021/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.3121, 訓練了 121 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1022/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.3121, 訓練了 126 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1023/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.3121, 訓練了 131 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1024/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2786, 訓練了 183 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1025/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2786, 訓練了 188 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1026/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.2786, 訓練了 193 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1027/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.8364, 訓練了 299 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1028/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.8364, 訓練了 304 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1029/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.8364, 訓練了 309 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1030/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 40.3966, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1031/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 40.3966, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1032/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 40.3966, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1033/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6181, 訓練了 164 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1034/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6181, 訓練了 169 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1035/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6181, 訓練了 174 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1036/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.8302, 訓練了 187 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1037/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.8302, 訓練了 192 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1038/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.8302, 訓練了 197 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1039/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.1031, 訓練了 276 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1040/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.1031, 訓練了 281 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1041/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.1031, 訓練了 286 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1042/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 73.2102, 訓練了 161 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1043/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 50.2362, 訓練了 437 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1044/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 50.2362, 訓練了 442 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1045/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.1246, 訓練了 123 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1046/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1246, 訓練了 128 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1047/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1246, 訓練了 133 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1048/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0089, 訓練了 178 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1049/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0089, 訓練了 183 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1050/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0089, 訓練了 188 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1051/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.6908, 訓練了 342 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1052/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.6908, 訓練了 347 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1053/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.6908, 訓練了 352 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1054/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 35.4175, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1055/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 35.4175, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1056/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 35.4175, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1057/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9659, 訓練了 125 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1058/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6105, 訓練了 146 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1059/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6105, 訓練了 151 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1060/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8464, 訓練了 176 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1061/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8464, 訓練了 181 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1062/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8464, 訓練了 186 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1063/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.2210, 訓練了 277 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1064/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1993, 訓練了 301 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1065/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1993, 訓練了 306 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1066/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 42.2491, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1067/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 42.2491, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1068/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 42.2491, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1069/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.1196, 訓練了 178 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1070/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1196, 訓練了 183 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1071/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.1196, 訓練了 188 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1072/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.8350, 訓練了 187 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1073/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.8350, 訓練了 192 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1074/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.8350, 訓練了 197 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1075/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4244, 訓練了 299 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1076/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4244, 訓練了 304 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1077/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4244, 訓練了 309 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1078/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 59.1962, 訓練了 376 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1079/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 50.0131, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1080/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.0005\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 50.0131, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1081/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5179, 訓練了 71 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1082/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5179, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1083/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5179, 訓練了 81 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1084/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1599, 訓練了 117 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1085/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1599, 訓練了 122 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1086/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1599, 訓練了 127 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1087/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.9583, 訓練了 202 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1088/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.9583, 訓練了 207 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1089/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.9583, 訓練了 212 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1090/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.8133, 訓練了 441 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1091/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.8133, 訓練了 446 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1092/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.8133, 訓練了 451 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1093/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3454, 訓練了 65 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1094/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3454, 訓練了 70 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1095/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3454, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1096/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.1601, 訓練了 106 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1097/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.1601, 訓練了 111 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1098/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.1601, 訓練了 116 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1099/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4319, 訓練了 178 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1100/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4319, 訓練了 183 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1101/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4319, 訓練了 188 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1102/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.5110, 訓練了 414 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1103/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.5110, 訓練了 419 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1104/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.5110, 訓練了 424 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1105/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5541, 訓練了 78 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1106/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5541, 訓練了 83 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1107/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5541, 訓練了 88 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1108/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9805, 訓練了 98 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1109/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9805, 訓練了 103 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1110/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9805, 訓練了 108 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1111/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3137, 訓練了 146 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1112/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3137, 訓練了 151 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1113/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3137, 訓練了 156 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1114/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 39.2332, 訓練了 320 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1115/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 23.4136, 訓練了 422 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1116/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 21.0707, 訓練了 482 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1117/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3009, 訓練了 64 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1118/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3009, 訓練了 69 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1119/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3009, 訓練了 74 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1120/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.4543, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1121/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.4543, 訓練了 112 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1122/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4543, 訓練了 117 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1123/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9594, 訓練了 178 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1124/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9594, 訓練了 183 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1125/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9594, 訓練了 188 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1126/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.6979, 訓練了 443 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1127/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.3530, 訓練了 475 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1128/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.3530, 訓練了 480 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1129/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4534, 訓練了 74 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1130/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4534, 訓練了 79 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1131/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.4908, 訓練了 108 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1132/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7261, 訓練了 105 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1133/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7261, 訓練了 110 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1134/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7261, 訓練了 115 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1135/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9935, 訓練了 163 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1136/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9935, 訓練了 168 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1137/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9935, 訓練了 173 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1138/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 9.0869, 訓練了 407 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1139/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.3794, 訓練了 442 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1140/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.3794, 訓練了 447 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1141/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.1011, 訓練了 83 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1142/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.1011, 訓練了 88 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1143/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.8874, 訓練了 115 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1144/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8132, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1145/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8132, 訓練了 106 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1146/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8132, 訓練了 111 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1147/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7741, 訓練了 155 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1148/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7741, 訓練了 160 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1149/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7741, 訓練了 165 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1150/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 23.8626, 訓練了 419 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1151/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 23.6113, 訓練了 442 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1152/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 21.9794, 訓練了 485 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1153/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2676, 訓練了 68 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1154/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2676, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1155/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2676, 訓練了 78 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1156/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.5381, 訓練了 120 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1157/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5381, 訓練了 125 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1158/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5381, 訓練了 130 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1159/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9723, 訓練了 189 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1160/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9723, 訓練了 194 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1161/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9723, 訓練了 199 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1162/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.0885, 訓練了 426 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1163/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.0885, 訓練了 431 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1164/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.0885, 訓練了 436 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1165/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5474, 訓練了 68 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1166/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5474, 訓練了 73 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1167/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5474, 訓練了 78 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1168/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.8317, 訓練了 97 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1169/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.8317, 訓練了 102 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1170/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.8317, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1171/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9161, 訓練了 162 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1172/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9161, 訓練了 167 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1173/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9161, 訓練了 172 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1174/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.8676, 訓練了 402 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1175/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.8676, 訓練了 407 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1176/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.8676, 訓練了 412 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1177/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2437, 訓練了 72 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1178/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2437, 訓練了 77 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1179/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.8106, 訓練了 107 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1180/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9211, 訓練了 96 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1181/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9211, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1182/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9211, 訓練了 106 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1183/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.6655, 訓練了 163 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1184/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.6655, 訓練了 168 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1185/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.6655, 訓練了 173 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1186/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 14.6024, 訓練了 415 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1187/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 14.6024, 訓練了 420 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1188/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 12.7609, 訓練了 500 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1189/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.1685, 訓練了 34 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1190/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.1685, 訓練了 39 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1191/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.1685, 訓練了 44 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1192/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9374, 訓練了 45 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1193/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9374, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1194/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9374, 訓練了 55 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1195/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.3033, 訓練了 89 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1196/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.2510, 訓練了 121 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1197/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.2510, 訓練了 126 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1198/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.3870, 訓練了 152 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1199/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.3870, 訓練了 157 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1200/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.3870, 訓練了 162 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1201/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7958, 訓練了 44 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1202/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7958, 訓練了 49 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1203/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.7958, 訓練了 54 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1204/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5672, 訓練了 45 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1205/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5672, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1206/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5672, 訓練了 55 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1207/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6586, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1208/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6586, 訓練了 81 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1209/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6586, 訓練了 86 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1210/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9654, 訓練了 139 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1211/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.9654, 訓練了 144 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1212/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.9654, 訓練了 149 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1213/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7029, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1214/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.5914, 訓練了 71 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1215/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.5914, 訓練了 76 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1216/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.7246, 訓練了 45 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1217/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7246, 訓練了 50 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1218/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7246, 訓練了 55 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1219/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.3190, 訓練了 77 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1220/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.3190, 訓練了 82 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1221/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.3190, 訓練了 87 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1222/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 7.9622, 訓練了 137 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1223/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 7.9622, 訓練了 142 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1224/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-06\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 7.9622, 訓練了 147 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1225/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.9421, 訓練了 33 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1226/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.7337, 訓練了 58 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1227/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.7337, 訓練了 63 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1228/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9011, 訓練了 46 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1229/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9011, 訓練了 51 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1230/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9011, 訓練了 56 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1231/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.9679, 訓練了 79 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1232/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.9679, 訓練了 84 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1233/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.9679, 訓練了 89 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1234/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.0115, 訓練了 173 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1235/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.0115, 訓練了 178 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1236/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.0115, 訓練了 183 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1237/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.2621, 訓練了 42 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1238/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.2621, 訓練了 47 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1239/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.8090, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1240/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.2901, 訓練了 47 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1241/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.2901, 訓練了 52 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1242/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.2901, 訓練了 57 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1243/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8660, 訓練了 83 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1244/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8660, 訓練了 88 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1245/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8660, 訓練了 93 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1246/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.5351, 訓練了 140 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1247/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.5351, 訓練了 145 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1248/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.5351, 訓練了 150 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1249/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.4131, 訓練了 39 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1250/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.4131, 訓練了 44 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1251/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.4131, 訓練了 49 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1252/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6643, 訓練了 47 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1253/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6643, 訓練了 52 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1254/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6643, 訓練了 57 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1255/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5903, 訓練了 69 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1256/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5903, 訓練了 74 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1257/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5903, 訓練了 79 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1258/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 6.4742, 訓練了 134 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1259/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 6.4742, 訓練了 139 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1260/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 1e-05\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 6.4742, 訓練了 144 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1261/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.7782, 訓練了 30 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1262/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.7782, 訓練了 35 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1263/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9397, 訓練了 62 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1264/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0342, 訓練了 44 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1265/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0342, 訓練了 49 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1266/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0342, 訓練了 54 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1267/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9166, 訓練了 96 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1268/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9166, 訓練了 101 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1269/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9166, 訓練了 106 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1270/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6028, 訓練了 155 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1271/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6028, 訓練了 160 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1272/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.2\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6028, 訓練了 165 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1273/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.0273, 訓練了 46 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1274/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.0273, 訓練了 51 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1275/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.0273, 訓練了 56 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1276/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.9190, 訓練了 51 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1277/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.9190, 訓練了 56 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1278/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.9190, 訓練了 61 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1279/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 4.8484, 訓練了 67 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1280/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 4.8484, 訓練了 72 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1281/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 4.8484, 訓練了 77 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1282/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5020, 訓練了 143 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1283/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5020, 訓練了 148 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1284/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5020, 訓練了 153 epochs\n",
      "  目前最佳 RMSE: 3.1823\n",
      "\n",
      "組合 1285/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 3.1796, 訓練了 37 epochs\n",
      "  目前最佳 RMSE: 3.1796\n",
      "\n",
      "組合 1286/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 3.1796, 訓練了 42 epochs\n",
      "  目前最佳 RMSE: 3.1796\n",
      "\n",
      "組合 1287/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 3.1796, 訓練了 47 epochs\n",
      "  目前最佳 RMSE: 3.1796\n",
      "\n",
      "組合 1288/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.6619, 訓練了 70 epochs\n",
      "  目前最佳 RMSE: 3.1796\n",
      "\n",
      "組合 1289/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.6619, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 3.1796\n",
      "\n",
      "組合 1290/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 8\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.6619, 訓練了 80 epochs\n",
      "  目前最佳 RMSE: 3.1796\n",
      "\n",
      "組合 1291/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 5.5856, 訓練了 75 epochs\n",
      "  目前最佳 RMSE: 3.1796\n",
      "\n",
      "組合 1292/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 5.5856, 訓練了 80 epochs\n",
      "  目前最佳 RMSE: 3.1796\n",
      "\n",
      "組合 1293/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 16\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 5.5856, 訓練了 85 epochs\n",
      "  目前最佳 RMSE: 3.1796\n",
      "\n",
      "組合 1294/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 15\n",
      "  訓練完成: RMSE = 8.4915, 訓練了 138 epochs\n",
      "  目前最佳 RMSE: 3.1796\n",
      "\n",
      "組合 1295/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 20\n",
      "  訓練完成: RMSE = 8.4915, 訓練了 143 epochs\n",
      "  目前最佳 RMSE: 3.1796\n",
      "\n",
      "組合 1296/1296:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "  patience: 25\n",
      "  訓練完成: RMSE = 8.4915, 訓練了 148 epochs\n",
      "  目前最佳 RMSE: 3.1796\n",
      "\n",
      "網格搜索完成!\n",
      "總耗時: 7831.44 秒\n",
      "\n",
      "最佳參數組合:\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  learning_rate: 0.003\n",
      "  weight_decay: 0.0001\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 4\n",
      "  patience: 15\n",
      "最佳測試 RMSE: 3.1796\n",
      "\n",
      "使用最佳參數建立最終模型...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "最終模型評估結果:\n",
      "測試集 MSE: 10.1102\n",
      "測試集 RMSE: 3.1796 天\n",
      "R^2 分數: 0.6700\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 設置隨機種子，確保結果可重現\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(50)  # 固定隨機種子\n",
    "\n",
    "# MLP 模型定義\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size=1320, hidden_sizes=[256, 128, 64], output_size=1, dropout_rate=0.3):\n",
    "        super(MLPModel, self).__init__()\n",
    "        \n",
    "        # 第一個隱藏層\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_sizes[0])\n",
    "        \n",
    "        # 第二個隱藏層\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_sizes[1])\n",
    "        \n",
    "        # 第三個隱藏層\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_sizes[2])\n",
    "        \n",
    "        # 輸出層\n",
    "        self.fc_out = nn.Linear(hidden_sizes[2], output_size)\n",
    "        \n",
    "        # Dropout 層\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# 訓練和評估模型的函數\n",
    "def train_and_evaluate(model, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, \n",
    "                      optimizer, criterion, num_epochs=500, batch_size=8, patience=20, min_delta=0.001):\n",
    "    \n",
    "    # 準備 DataLoader\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 早停相關變數\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    wait = 0\n",
    "    stopped_epoch = 0\n",
    "    \n",
    "    # 記錄訓練過程\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    # 訓練循環\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # 計算平均訓練損失\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        # 計算測試損失\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test_tensor)\n",
    "            test_loss = criterion(test_outputs, y_test_tensor).item()\n",
    "            test_losses.append(test_loss)\n",
    "        \n",
    "        # 早停判斷\n",
    "        if test_loss < best_loss - min_delta:\n",
    "            best_loss = test_loss\n",
    "            wait = 0\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                stopped_epoch = epoch + 1\n",
    "                break\n",
    "    \n",
    "    # 如果完成所有 epoch\n",
    "    if stopped_epoch == 0:\n",
    "        stopped_epoch = num_epochs\n",
    "    \n",
    "    # 載入最佳模型\n",
    "    if best_model is not None:\n",
    "        model.load_state_dict(best_model)\n",
    "    \n",
    "    # 最終評估\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_predictions = model(X_test_tensor)\n",
    "        final_test_loss = criterion(test_predictions, y_test_tensor).item()\n",
    "        final_test_rmse = np.sqrt(final_test_loss)\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'final_test_loss': final_test_loss,\n",
    "        'final_test_rmse': final_test_rmse,\n",
    "        'epochs_trained': stopped_epoch,\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "        'best_epoch': stopped_epoch - wait if wait < patience else stopped_epoch\n",
    "    }\n",
    "\n",
    "# 網格搜索函數\n",
    "def grid_search(X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, param_grid, verbose=True):\n",
    "    # 生成所有參數組合\n",
    "    param_combinations = list(itertools.product(*param_grid.values()))\n",
    "    param_keys = list(param_grid.keys())\n",
    "    \n",
    "    # 最佳結果追蹤\n",
    "    best_rmse = float('inf')\n",
    "    best_params = None\n",
    "    best_result = None\n",
    "    all_results = []\n",
    "    \n",
    "    # 總組合數\n",
    "    total_combinations = len(param_combinations)\n",
    "    \n",
    "    print(f\"開始網格搜索 - 總共 {total_combinations} 種參數組合\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 逐一嘗試每種參數組合\n",
    "    for i, combination in enumerate(param_combinations):\n",
    "        # 構建當前參數字典\n",
    "        current_params = {param_keys[j]: combination[j] for j in range(len(param_keys))}\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n組合 {i+1}/{total_combinations}:\")\n",
    "            for k, v in current_params.items():\n",
    "                print(f\"  {k}: {v}\")\n",
    "        \n",
    "        # 設置隨機種子確保公平比較\n",
    "        set_seed(50)\n",
    "        \n",
    "        # 初始化模型和優化器\n",
    "        hidden_sizes = current_params.get('hidden_sizes', [256, 128, 64])\n",
    "        dropout_rate = current_params.get('dropout_rate', 0.3)\n",
    "        \n",
    "        model = MLPModel(\n",
    "            input_size=X_train_tensor.shape[1], \n",
    "            hidden_sizes=hidden_sizes, \n",
    "            output_size=1, \n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "        \n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(), \n",
    "            lr=current_params.get('learning_rate', 0.001),\n",
    "            weight_decay=current_params.get('weight_decay', 1e-5)\n",
    "        )\n",
    "        \n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # 訓練和評估\n",
    "        result = train_and_evaluate(\n",
    "            model, \n",
    "            X_train_tensor, y_train_tensor, \n",
    "            X_test_tensor, y_test_tensor,\n",
    "            optimizer, \n",
    "            criterion,\n",
    "            num_epochs=current_params.get('num_epochs', 500),\n",
    "            batch_size=current_params.get('batch_size', 8),\n",
    "            patience=current_params.get('patience', 20)\n",
    "        )\n",
    "        \n",
    "        # 儲存結果\n",
    "        result_entry = {\n",
    "            'params': current_params,\n",
    "            'test_rmse': result['final_test_rmse'],\n",
    "            'epochs_trained': result['epochs_trained'],\n",
    "            'best_epoch': result['best_epoch']\n",
    "        }\n",
    "        all_results.append(result_entry)\n",
    "        \n",
    "        # 更新最佳結果\n",
    "        if result['final_test_rmse'] < best_rmse:\n",
    "            best_rmse = result['final_test_rmse']\n",
    "            best_params = current_params\n",
    "            best_result = result\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  訓練完成: RMSE = {result['final_test_rmse']:.4f}, 訓練了 {result['epochs_trained']} epochs\")\n",
    "            print(f\"  目前最佳 RMSE: {best_rmse:.4f}\")\n",
    "    \n",
    "    # 總耗時\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(\"\\n網格搜索完成!\")\n",
    "    print(f\"總耗時: {total_time:.2f} 秒\")\n",
    "    print(\"\\n最佳參數組合:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(f\"最佳測試 RMSE: {best_rmse:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'best_params': best_params,\n",
    "        'best_result': best_result,\n",
    "        'all_results': all_results\n",
    "    }\n",
    "\n",
    "# 使用方式 (假設您已經準備好了資料)\n",
    "# 這裡先確保 X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor 已經準備好\n",
    "\n",
    "# 定義網格搜索的參數範圍\n",
    "param_grid = {\n",
    "    'hidden_sizes': [\n",
    "        [64, 32, 16],\n",
    "        [128, 64, 32],\n",
    "        [256, 128, 64],\n",
    "        [512, 256, 128]\n",
    "    ],\n",
    "    'learning_rate': [0.0005, 0.001, 0.003],\n",
    "    'weight_decay': [1e-6, 1e-5, 1e-4],\n",
    "    'dropout_rate': [0.2, 0.3, 0.4],\n",
    "    'batch_size': [4, 8, 16, 32],\n",
    "    'patience': [15, 20, 25]\n",
    "}\n",
    "\n",
    "# 執行網格搜索\n",
    "grid_results = grid_search(X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, param_grid)\n",
    "\n",
    "# 使用最佳參數建立最終模型\n",
    "best_params = grid_results['best_params']\n",
    "print(\"\\n使用最佳參數建立最終模型...\")\n",
    "\n",
    "# 設置隨機種子\n",
    "set_seed(50)\n",
    "\n",
    "# 初始化最終模型\n",
    "final_model = MLPModel(\n",
    "    input_size=X_train_tensor.shape[1], \n",
    "    hidden_sizes=best_params['hidden_sizes'], \n",
    "    output_size=1, \n",
    "    dropout_rate=best_params['dropout_rate']\n",
    ")\n",
    "\n",
    "final_optimizer = optim.Adam(\n",
    "    final_model.parameters(), \n",
    "    lr=best_params['learning_rate'],\n",
    "    weight_decay=best_params['weight_decay']\n",
    ")\n",
    "\n",
    "final_criterion = nn.MSELoss()\n",
    "\n",
    "# 訓練最終模型\n",
    "final_result = train_and_evaluate(\n",
    "    final_model, \n",
    "    X_train_tensor, y_train_tensor, \n",
    "    X_test_tensor, y_test_tensor,\n",
    "    final_optimizer, \n",
    "    final_criterion,\n",
    "    num_epochs=500,  # 可以設置為更大的值\n",
    "    batch_size=best_params['batch_size'],\n",
    "    patience=best_params['patience']\n",
    ")\n",
    "\n",
    "# 繪製最終模型的損失曲線\n",
    "plt.rcParams['font.family'] = 'Heiti TC'  # 設置中文字體\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(final_result['train_losses']) + 1), final_result['train_losses'], label='訓練損失', color='blue')\n",
    "plt.plot(range(1, len(final_result['test_losses']) + 1), final_result['test_losses'], label='測試損失', color='red')\n",
    "plt.axvline(x=final_result['best_epoch'], color='green', linestyle='--', label=f'最佳模型 (epoch {final_result[\"best_epoch\"]})')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('損失 (MSE)')\n",
    "plt.title('最終模型訓練過程')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('final_model_loss_curve_feature11.png')\n",
    "plt.show()\n",
    "\n",
    "# 評估最終模型\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    # 測試集評估\n",
    "    test_predictions = final_model(X_test_tensor)\n",
    "    test_mse = final_criterion(test_predictions, y_test_tensor).item()\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    \n",
    "    # 計算 R^2 分數\n",
    "    y_test_mean = torch.mean(y_test_tensor)\n",
    "    ss_tot = torch.sum((y_test_tensor - y_test_mean) ** 2)\n",
    "    ss_res = torch.sum((y_test_tensor - test_predictions) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    print(\"\\n最終模型評估結果:\")\n",
    "    print(f'測試集 MSE: {test_mse:.4f}')\n",
    "    print(f'測試集 RMSE: {test_rmse:.4f} 天')\n",
    "    print(f'R^2 分數: {r2.item():.4f}')\n",
    "    \n",
    "    # 繪製實際值與預測值的比較圖\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # 轉換為 numpy 數組以便繪圖\n",
    "    y_test_np = y_test_tensor.cpu().numpy().flatten()\n",
    "    test_pred_np = test_predictions.cpu().numpy().flatten()\n",
    "    \n",
    "    # 繪製散點圖\n",
    "    plt.scatter(y_test_np, test_pred_np, color='blue', label='預測 vs 實際')\n",
    "    \n",
    "    # 繪製理想線 (y=x)\n",
    "    min_val = min(y_test_np.min(), test_pred_np.min())\n",
    "    max_val = max(y_test_np.max(), test_pred_np.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='理想線 (y=x)')\n",
    "    \n",
    "    plt.xlabel('實際開花日 (天)')\n",
    "    plt.ylabel('預測開花日 (天)')\n",
    "    plt.title('最終模型: 實際開花日 vs 預測開花日')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('final_model_predictions_feature11.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcd79585-2d6f-431d-aa9c-1a60697bbbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAANXCAYAAADQKQWKAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAwSRJREFUeJzs3XmcjeX/x/HXmTO7fTd2xk62yj7ZJdswTWRJSimUylDWLAllKVqk+kVCkQZlySA0aiKRjJDsMfZlhtnPOb8/ztdhmqEZ5sx9Zub9fDzmYe773HOfzz1XE++5rvtzm2w2mw0RERERERHJEDejCxAREREREcmOFKZERERERETugsKUiIiIiIjIXVCYEhERERERuQsKUyIiIiIiIndBYUpEREREROQuKEyJiIiIiIjcBYUpERERERGRu6AwJSIiTnXq1Cni4uK48Yz4xMREzp07x8mTJzlx4gSXLl3iypUrjo9Lly5x4sQJzp49e9fvefbsWS5cuJBZl3DXTpw4Qd26dfn222/v6uvPnj3L/PnzOXPmTCZXJiIimcFku/G3m4iIiBOUKVOGU6dOpdhXr149OnfuzOTJk2/7da+99hrTpk0D4PLly2zdupVu3bpx8eJFli1bRr58+QCwWCx4enrSq1cvx9f27duXQ4cOsX37didcUdp69uyJr68v7u7umM1mzGYzJpOJefPmUbduXRo3bozVasVisZCcnExcXBxjxoyhVq1aAAwcOBA3N/vvOG02G4MGDWLfvn089dRT/P7779SsWZN//vmHa9euOd7T09OTSpUqZdk1iohISgpTIiLiVLt37yZPnjz4+vpy/PhxWrRowY8//kj58uW5fv06efLkoW/fvhQqVIh58+aRnJzM1atXyZMnD2XLlgVgxowZjBgxgueee47hw4dTpUoVGjZsiI+PD8ePH6dChQps3ryZ3bt3U65cOV599VXOnj3L6tWrs+w6TSYTb7zxBmXKlMHLywuTyZTmcYmJibi7u9OnTx82b95My5YtAfD19eXRRx/FZDLx1Vdfce7cOfr378+qVaswm83YbDa6devGqlWrcHd3JykpiSFDhjBnzpwsu0YREUnJ3egCREQkZ6tXrx6dOnXi/vvv5+zZs/Tp04emTZuSkJBA0aJF8fLyYt++fUyePJlixYqRnJyMj48PBQsWdJxj+PDhFC1alGeffZaaNWsCsHjxYipXrszkyZPZsmULAA888AAff/zxbYMMwIEDB6hRowbfffcdnTt3TvHaF198wYABAzhx4gQlSpTgtddeY8GCBZjNZoYPH05ISMhtz1ugQAE6dOhAkyZNcHNzw93dHZPJRHx8vCNcWSwW4uPj2bdvX6qvd3NzY8CAAURERNCqVSsuX77M2rVrWb16NZUqVaJhw4Z06dIFb29vFi1aRIUKFQgODs7ASIiISGbTzJSIiDjdxx9/zKBBgwA4evQo5cqVY/369XTo0AGz2YzFYsHDwwObzUZycjIdOnRg3bp1qc5z4MABChYsiJ+fHyNHjqRIkSJs2rSJpKQkNm7ciLe3NwsWLGDjxo2cOXPmtjNTbdu2xcvLizVr1qTY37RpU8qWLcvSpUtZsGABzz33HCNGjODEiRMsXryYH374gRYtWqQ635w5c0hKSsLb25uQkBDGjh1LhQoVsFqtPPnkk8yYMYMSJUo4tseNG4e3tzdJSUmMHz8egLx587J69WpGjhxJ//792bRpE56eniQmJrJz507q1q3L7Nmzadu2LZ988glDhw5lz549dwyOIiLiXGpAISIiTjdw4EDmzJmD1Wplz549gH1ZW/78+Tlz5gznz5/n9OnTREVFMXToULy8vFJ8/aeffsqFCxeoXr26Y9/evXvZuXNnqvux0mPIkCF8//33HDt2zLFvz549REREMHjwYAB27NhBp06dmDx5MgsXLuTgwYNpBqlb3fj9ZEJCAvHx8cTHxwP2pX3x8fEkJiY6jvX29nbcI3XD2bNn2blzJ56envz000888sgjTJ06lfPnzzNkyBDKly9PyZIlGTRoEFOnTlWQEhExmJb5iYiI0xw/fpyxY8dSqFAh3NzcqFq1Kps2bWL16tWUL18ek8lE0aJFU3yNj49Piu1z584xcuRIRo8ezbx582jSpAkA7777bqplfunVtWtXSpcuzbx585g6dSoAc+fOpVatWo7AVKtWLb766it27NhBw4YNqVy58m3PN3ToUMfnISEhzJ49G7PZjJubG15eXsyYMQOwN8sAePzxxx3LFW9ls9moUKEC/fv3p3fv3gwZMoRnnnmGTp060a5dOwCmTZtG27ZtMZvNGbpmERHJfApTIiLiNImJifz5558UKlSII0eOcPXqVf744w82b97M559/ztWrV3F3T/lXkdVqpWvXro7t4sWLc+jQIZ566imWLFniCFOrVq2iRIkSjpmujDCbzTz33HPMmTOHiRMnkpCQwOLFix3dAwGeeeYZvv/+e5o2bcqgQYN48803yZ8//x3Pu2bNGl599VVHR79/s1qtJCUlsWnTpjTDVMmSJencuTPvv/8+/fv3JzY2lhIlSnDkyBHc3Nxwc3PDYrHQq1cvOnfuzBNPPMHEiRMpV65chr8HIiJy7xSmRETEaapUqcJvv/0G2JtI7Ny5kz59+nD48GEqVapEgQIF+Oeff1J8zfjx4zl8+HCKfYUKFWLFihXEx8dz9epVAJYtW+bo5ufv75/h2p555hkmTZrEN998w+XLlwHo16+f43UvLy++++47Fi5cyIgRIwgPDyciIiLVzNmt9uzZw6JFixgwYECar7u5ubFp0yZ8fX158cUX0zymX79+dOnShT179hAaGsrGjRupUaMG+fPnx2QyERMTg6enJ0ePHmX//v2ULl06w9cuIiKZQ2FKRESy1OOPP079+vWJjY3l6tWrjudF3SowMDDVvq+++opr167RpUsXIO1ufhlRokQJHn30UT788EOuXLlC375906ylX79+BAQEUL16db788kuefvrp257Tzc2Nc+fO8dVXX932mDNnzlCvXr3bvl6jRg1Onz5Nv379qFKlCmXKlMHNzY3Y2FgAR6CaOnUqHh4eWu4nImIghSkREclSefLkoUGDBoSHh1OgQAGuXLmS4vWRI0eyf//+VF+3du1azp8/T8eOHYGUy/xuNH6wWq0ZqmXIkCE0b94cgCVLlqR47Y8//qBy5cr4+vpSqlQpvLy8Ujww93ZKly7NCy+8cNvXv/766zt+/Y1Zsjx58nDs2DEqVaqEm5sbJpMJq9XqWOpXokQJzpw585/1iIiI8yhMiYiIIa5du8bVq1fT7EjXvn37FNsWi4Xvv/+e119/naSkJGrWrMlXX32Fm5sbycnJ+Pv7Y7PZSEpKIjk5Od01NGvWjLp165IvXz7uu+++FK/16dMHgL59+xIWFkZiYiIdOnS4iytNv/nz57N69WqqVatGnTp1GDFiBBMnTqREiRKMHDmSLVu28Msvv3D48OFUjTtERCTrKUyJiIghmjZtyo4dO5g+fTrjxo2jcOHCjBs3jt69e6e6ByosLIwLFy7QunVrKlSoQEhICOfPn2fgwIFMmzaNV155BZPJ5JihysiyvyFDhpA3b95U+7/++mteeOEFJk6cSPny5fn666+pWrXqHc8VGxvLsWPHGD9+fJoh0WazERMTwwMPPJDmaw888AClS5d2PBz4iSeeIDExkZ9++slx3C+//EKrVq34+uuvUz10WEREspaeMyUiIk4VHR3Nli1b2LdvX4qAsXPnTnr27MmuXbs4efIknp6e/PPPP3Tt2pVVq1Zx6zPlP/30U0qVKkWtWrWIjIzkpZdeIjY2FpvNxrZt22jdujUXLlxwHJ+R59E/++yz9OrVK9X+6tWrs3HjRmJjY9m/f7/jXq07GT9+PFu2bKFHjx6UK1eOzZs3c+bMGf7++2+KFClC1apVeeWVVxg/fnyqGbSEhATuu+8+pkyZgs1mIzAwkMOHD7N48eIUz91q3LgxEyZMoHv37nz++efpvk4REcl8ClMiIuJUefPm5dFHH2XDhg20adOG3bt306pVK9q3b88jjzzCnj176NixI8WKFSMsLIyZM2cyfPhwRo8eDcD58+fZtGkTLVq0YN++fbRv3562bdsyYcIEChcuzOrVq7l+/TqTJ09m586ddOnShRUrVuDt7Z1l17hq1SqaNGlCwYIFCQoKIi4ujrFjx1KsWDHH9+DHH39k9OjRxMfH079/f4oWLcr69esBiI+PdzyDCuzNNQ4dOsTmzZupUqUKixYt4ueff3aEqtdee43nn3+elStXZmhZo4iIZC6TLSO/vhMREbkLu3fvpnz58hQuXBiLxcKcOXNo3bo1devWTfP4sLAwGjVqRIECBQC4cOECR48epVSpUkyZMoVp06al6Lz3999/U7FiRa5cuUKVKlWoUqUKb7zxRqp7r5wlMTGR+fPn06hRI+rWrZvmEr9bWa1W1qxZQ4cOHfDw8ODMmTP4+fmxefNmWrZs6TjGzc3+O8+hQ4fy2WefMXv2bEfb9eTkZMxm83++l4iIOI/ClIiIiIu7evUqvr6+eHh4GF2KiIjcQmFKRERERETkLuieKRERERERkbugMCUiIiIiInIXFKZERERERETugsKUiIiIiIjIXXA3ugBXYLVaOX36NPny5VOLWRERERGRXMxmsxETE0OpUqUcj6i4HYUp4PTp05QtW9boMkRERERExEWcPHmSMmXK3PEYhSlwPPjx5MmT5M+f3+BqMldSUhJhYWG0b99ezycxkMbBNWgcXIPGwXgaA9egcXANGgfX4ErjEB0dTdmyZVM8HP52FKbAsbQvf/78OTJM+fr6kj9/fsP/w8zNNA6uQePgGjQOxtMYuAaNg2vQOLgGVxyH9Nz+owYUIiIiIiIid0FhSkRERERE5C4oTImIiIiIiNwF3TOVTjabjeTkZCwWi9GlZEhSUhLu7u7Ex8dnu9qNZjabcXd3V7t8EREREUmTwlQ6JCYmEhUVRWxsrNGlZJjNZqNkyZKcPHlSoeAu+Pr64ufnh6enp9GliIiIiIiLUZj6D1arlaNHj2I2mylVqhSenp7ZKpRYrVauXbtG3rx5//OhY3KTzWYjMTGR8+fPc/ToUapUqaLvn4iIiIikoDD1HxITE7FarZQtWxZfX1+jy8kwq9VKYmIi3t7eCgMZ5OPjg4eHB8ePH3d8D0VEREREbtC/rtNJQSR30riLiIiIyO3oX4oiIiIiIiJ3QWFKRERERETkLihM5VBWq5WLFy862qEnJydz4cIFzpw5w9WrV4mLiyM+Pp74+HhiYmI4efJkmueJj493fG6z2bDZbI7t2NhYkpOTnXsh/7Jr1y4OHjyYoa85depUtuzEKCIiIiKuTQ0ocqhLly5RqlQp8ubNi8lkIjo6mk6dOhEdHc3u3buxWCzExcVRuHBhLBYLycnJXLlyBYD/+7//4+eff2bu3Ln07NmTLVu24OPjw9WrV3n33XcZOHAgJpOJwYMHU7BgQd59912nXMOuXbu4cOEC7u7ujnuXJk+ejLe3N8OHDwdw1F6jRg3KlSvH999/T7du3ShYsCAXL15k06ZNfP311xw5coQ1a9Zw5coVx3VarVbKlCmjtuciIiIiclcUpnKoIkWKOGafoqOjqV27NpMnT6ZWrVqYTCbeffddNm3axHfffQeQYsapW7duvP/++wQGBpI3b15mz55N//796du3L15eXowdO5Y6derg5eVFwYIFnXYNs2bNIjo6mjp16jj2NW7cGICNGzc69q1YsYIRI0bQv39/3N3dady4MaGhodSsWZOmTZvSr18/EhMTyZ8/P82bN2fXrl0UK1aMQ4cOcenSJYUpEREREbkrClNZyGKxEB4eTlRUFH5+fgQEBGA2m53yXiaTiUOHDtG1a1f69u3Lww8/TO3atYmNjcXHx4d9+/bxwAMPABAXFwfYW4GDPYht2LCBVatWsWHDBqKiojhw4ADR0dEAXLx4kf3799/2eVsrV65k6NChjudz3dCuXTvatGnDyJEjefnll5k/fz5ly5Zl7ty5BAQEpDpP2bJlady4Mf369aNKlSoAnDt3jjx58pAnTx5iY2MpX748AQEBjtpv2Lp1K126dCEsLIwyZcrw9ttvM3r0aHr16kWxYsV4/PHH+fjjj7Nlu3sRERERcQ26ZyqLhIaGUtnfn1atWtG7d29atWpFZX9/QkNDnfae/v7+tG7dmvHjx9O3b18ARo8eTdGiRdm0aRMLFy7E39+fQoUKER4e7vi6rVu3UqBAAQYMGADA/PnzeeaZZ/jll1/S9b5du3bF3d2dlStXOvb9+eef/PTTTzz77LNs3LiRdevWsX79evr27cumTZtSnePnn38mOTmZnTt3kpCQQFBQEMHBwRQrVoz777+f4OBgmjVrxqFDhyhcuDARERGOsAewZcsWHnnkEUaPHs1rr73Giy++yNmzZ+nRowe//fYbH3zwAS+88MLdfFtFRERERADNTGWJ0NBQgoOD6dywCV++9Bq1y1ck8vhRpixdRHBwMMuXLycoKChT3/PYsWNs376d9u3bs3PnTnbs2EF0dDSxsbGMGjXKcc8RQPPmzR33JCUlJfHCCy9gMplYvHgxYA9gN5b5pYebmxsvvvgic+bM4dFHHwVgzpw59OnThyJFijiW3NWvX9+xbO/fChYsSNWqVfHx8cHNzY1KlSoBkDdvXooVK0aFChWIjY0lT548VK9endjYWNzdb/7nvGfPHqpXr07//v354IMPKF26NN26dcPLy4s2bdoQERFBmzZtMv6NFRERERH5H4UpJ7NYLIQMG0bnhk1YOe5NR2hpXL0WK8e9Sbc3xjA8JITAwMBMXfJ39uxZVq9ejdVq5Y8//qBmzZpMmzaNQYMGMXPmTBYsWOA49ujRo47PPTw82LVrFyNHjnTcRzV//ny2bdvGL7/8Qtu2bdP1/k8//TTjx4/njz/+oFy5cixatIiIiAgAHn74YT766CPq1avHO++8Q4cOHVJ9fc2aNalZsyYA7733HjNmzMBsNmMymYiIiHDMXN1YBvhvw4cPZ/To0fz++++Eh4ezf/9+du7cyR9//MH58+e5du0aL7/8MsOHD6dMmTLp/r6KiIiIiNygMOVk4eHhHDt+nC9fes0RpG5wc3NjVI8+NA0ZQnh4OC1btsy0923UqBGNGjXiyJEjrFq1ik6dOnHs2DG8vLwICQlJNTN1Kw8PD55//nnHfUr33XcfLVu25K+//kr3+xcoUID+/fszZ84cqlevTsOGDbnvvvsAMJvNfPvtt3z11Vc8+eSTjB8/nsGDB6d5noULF2KxWKhatWqq75/FYmHz5s0cOnTIUesNnTt3ZsiQITzzzDPkzZuXTZs28ffff+Pu7k5CQgLVqlWjX79+nDlzRmFKRERERO6KwpSTRUVFAVC7fMU0X69dvlKK45ylQ4cO1KlTh88//5xp06bx0UcfOV47depUquNfeuklx9LDChUq8MADD1CkSBEgZee/Oxk6dCj16tWjcOHCzJkzJ9Xrjz/+OGazmTFjxtw2TFmtVk6ePEnevHnTfP3EiRO3bYSRP39++vfvz8SJE2ncuLGja5/NZiMuLo4RI0Y4mnCIiIiIiGSUwpST+fn5ARB5/CiNq9dK9Xrk8SMpjnOWfPnyUaNGDWw2GyNHjrzjzFRcXBxbtmzhvffe47fffmPBggV88cUXJCUl4enpSWJiouNhwHdSuXJlWrVqxb59++jatatj/3vvvcf+/fvp378/X331leN+qNspX748wcHBab62d+/eVPsSExOpUqUKefLkoWHDhgwbNoyWLVuye/du+vfvz969e9mzZw8NGjT4z2sQEREREbkddfNzsoCAACqUL8+UpYuwWq0pXrNarUxdtpiKFSqk2RrcGZKTk5k8eTLFihWjRIkSFC1alL1795KUlOQ4ZsWKFZQsWRJ/f38GDBhAnTp1+Prrr2nVqhXdunVj/vz5vPHGG+l6v5deeokhQ4akWKLXsWNH9u/fT4sWLThz5gwffPDBHc/h7u5O3rx50/z496xUcnIynp6efP755+zYsYOff/6Z3r17s3XrVscxe/bsoVu3bmzYsCFd1yAiIiIikhbNTDmZ2Wxm5qxZBAcH0+2NMYzq0Yfa5SsRefwIU5ctZvWOCJYvX+605039O8BNnjyZS5cuUalSJYYOHUq3bt0YOXIkDz/8sOOYOXPm0L59e6KioujTpw+DBg2iUqVKnD9/nu7du7Ny5UqioqI4d+7cf86otW3bNlXTCn9/fzZv3pyu+n18fIiPj3csE7yxVO/s2bMUKVKEsmXLpghqiYmJADRt2pRvv/2Wfv36sXz5cu6//37WrVuHm5sbjRs3ZsWKFbRt25Zt27ZRv379dNUiIiIiInIrzUxlgaCgIJYvX87eM6doGjKE/MGP0DRkCJFnTzulLfoN69ato1evXhQsWJCkpCSWLFlCnTp1iI6O5plnnqFAgQKEhIQwYMAAnnnmGRISEkhKSqJLly507NiRadOm0ahRI15++WXc3d1ZsGABDRo0wGazOQLJvxs/ZJbExET27NmDu7s7jRs35p9//qF58+ZERETw008/0axZMy5fvkyZMmVYv369476vq1evOs7RtWtXDh48SLt27Th//jxPPPEE7du3B6BJkybs379fQUpERERE7ppmprJIUFAQgYGBhIeHExUVhZ+fHwEBAU6bkQJ7F74nn3yShx56iDNnzrBq1SpmzpyZ4v6lzp0788svv7BgwQK8vLwAGDNmDGAPI7feG+Xr68vUqVMB2LBhAyVKlKBkyZJOqd1kMvHGG2/g7e1NmzZtmDBhAsWLFwfss32LFi3CZrOxfft2FixYQKlSpShdujRPPPEETzzxhOM8JUqUAKBatWpcvnyZAgUKOF4rV66cU2oXERERkdxBYSoLmc3mTG1//l/KlCnD4MGDiY6OJn/+/CxduvS2x40dOzbN124X9urWrZtpdabFw8OD5cuX3/EYk8lE48aNb/vg33+7NUiJiIiIiNwrLfMTERERERG5C4aGqZMnTxIUFEShQoXw9/fnvffec7y2du1aatWqhbe3Nw0bNmTHjh23PU9ycjIjRoygaNGi5M+fnwEDBnDt2rWsuAQREREREcmlDAtTCQkJdOjQAU9PT77//nsmT57MpEmTmD9/Pn/++SdBQUH06dOHX375hZYtW/Lwww+n+XBZgAkTJrB06VK++OIL1qxZwx9//MFTTz2VxVckIiIiIiK5iWH3TP30009cunSJL774Ag8PDxo1akRMTAwff/wxv/zyC126dGH06NEA1KtXj19//ZXZs2fz9ttvpzhPYmIic+bM4csvv+SRRx4BYNmyZVSuXJk///yTmjVrZvm1iYiIiIhIzmfYzNS1a9fw8fHBw8PDsa9AgQKcPXuW8PBwHn300RTH9+3bN82HrP7+++9YrVY6dOjg2FexYkWaNm2qh7KKiIiIiIjTGBammjRpwsWLF5kwYQLXr19n3759TJgwgebNm3PixAkqV66c4vjKlStz5MiRVOc5ceIEFSpUSNV17nbHi4iIiIiIZAbDlvkVK1aMJUuW8OSTTzJx4kTA3ob7q6++YvHixfj6+qY4vlChQly/fj3VeeLi4lIde+P46OjoNN87ISGBhIQEx/aN45KSkkhKSkpxbFJSEjabDavVitVqzdhFugCbzeb4M7vUn5ycTOnSpXnnnXfo3bu3095n+vTpLFiwgH379t32GKvVis1mIykp6Z6eCXbjv6t///clWUvj4Bo0DsbTGLgGjYNr0Di4Blcah4zUYOhzpjp16sTZs2fZt28fbdq0oW/fvtStWxcfHx/i4+NTHHvlypU0Q1Nax944Pm/evGm+79SpUx0B7lZhYWGp3sPd3Z2SJUty7do1EhMTM3J5LiUmJobExERMJlOKpZUAFouF5ORkx0N7b0hKSsLd3R2TyYTNZsNkMqV43Wq14uaWcnIzPj4eb2/vFPuuXLmCu7v7bcfj3zZt2kRSUhJt27a9bSDODN27d2fMmDFERERQq1atNI9JTEwkLi6OH3/8keTk5Ht+Ty09dQ0aB9egcTCexsA1aBxcg8bBIFYr3PLvSVcYh9jY2HQfa/hDe81mM59++in58uVj8uTJAJQrV44jR47QoEEDx3GHDx+mUqVKqb6+XLlyHDt2LNU/7A8fPkz37t3TfM9Ro0YxbNgwx3Z0dDRly5alffv25M+fP8Wx8fHxnDx5krx586YKCa4sOTmZv/76i1KlSpGYmIjFYuHbb7/lxRdfpECBAo6ZOW9vb2JiYhg7dixjxoxJcY6KFSuyfPly7r//fvr378/XX3+Np6cnJpOJ5ORkChcuzLFjx1J8zaxZs9i1axcrV650jMfixYtZvXo1a9asSVftERERtG7dmuLFi9/7N+IO8ufPT4MGDdi+fTtNmjRJ85j4+Hh8fHx46KGH7mn8k5KS2LBhA+3atUsVZiXraBxcg8bBeBoD16BxcA0aB+OYfvgB88iRJH/7LUlFirjMOGTkl/mGh6kdO3bw4Ycfsn79evLkyQPAQw89xLfffktwcLDjuKVLl9K2bdtUX1+vXj0AtmzZQuvWrQE4deoU27Zt44MPPkjzPb28vFLNwgB4eHikOWtjMplwc3NLNQvjymJjY7nvvvscS9NsNhtPP/00zZs3Z8uWLYwdO5bk5GSmTZtG//798fX1dVzflClTMJlMxMfHs3TpUo4fP06+fPmYO3cu/fv3B+DYsWN06NAhxfckISGBTz/9lG+//RZ3d3e2bt1Knz59uH79OmazmUqVKmGz2ahcuTKbNm26be3bt2/nsccey5Lvd8uWLYmIiEgRrm/l5ubmmM3LjB/szDqP3BuNg2vQOBhPY+AaNA6uQeOQxTZuhG7dID4ej+nTYeZMwDXGISPvb2g6SE5OZuDAgTz55JO0adPGsf/FF1/k66+/ZubMmfz++++MGzeOiIgIXn75ZcD+QF8/Pz92796Np6cnQ4cOZeDAgYSFhfHTTz/Ro0cPunXrRu3atQ26MuMVLFiQ5ORkpk6dSo8ePUhMTKRLly63Pf7W+4FsNhsHDhzg3LlzjnuGTCYTw4cPp0KFClSoUIHmzZunOsf//d//0bVrV6pUqcIbb7xBcnIylStX5vLly1y4cIFjx47x+eefp3nv260OHjzoWHb3wQcf0KxZs1THtGzZkpkzZ9K/f39MJlOaHwsWLOD999+nVKlSjt8wLFu2jAIFCnD69GkAateuzV9//fXf31ARERERyRxhYdClC8THQ+fOMH260RXdNUNnpq5du0b9+vWZ+b8kekOtWrX45ptvGD58OGPGjKFOnTqEhYVRpkwZwB7C4uLiHA0VJkyYQHx8PL169SIpKYng4GBmz57t/Au4Uygwm+HWZWF3OtbNDXx8/vvY/83cpdetAenG7EpERARlypRxhItFixZx+fJlxwwfwJgxY+jduzeenp488MADFCtWDIAZM2akmpm64dSpU7z77rssWLCAUaNGceTIEVq2bMmvv/6aItRev36dEiVK3LbmuLg4zp8/71jS+cQTTzBy5Ej27NlD3bp1AThw4ADbt2/nm2++ITExkZEjR6Z5Lj8/P/Lly8fChQt5/fXXmTx5MsOGDePNN9+kVKlSgL3r4/Hjx9P7LRURERGRe7F+PQQGQkKCPVB9/TV4eYELNJ64G4aGqYIFCzJ//vw0X+vYsSMdO3ZM87WuXbty5coVx7a7uzszZsxgxowZzijz9u7UUKFjR7j1HqHixeF2N7O1aAFbttzcrlABLlxIfdz/OvOlh8Vi4YcffuD48eOcP3+eTZs2cfXqVZo0aZLmMj/bLef+6aefOHDgAFWqVMHX15cnn3yStm3bMnbsWMf3OCkpKUVDioULF+Lh4cGzzz5LdHQ0u3fv5q+//uLBBx9kyy3XtmXLFl577bXb1h0TEwPY/9sA+31Nffr04YMPPuDjjz8GYN68eTz22GMUKVIEsIemO/n4449p3Lgxx44do1SpUgwePNjxWoECBRzvKSIiIiJO9P339qV9CQn2QLVsGXh6Gl3VPck+NwFJhtyYqVuyZAkRERH06tWLU6dO3fb4Gw0pTp48Sc+ePZk9ezY2m4169eoRFhaGj48PkydPJjIyksjISNavX5/i60eNGsWvv/6Ku7s7S5cuxcvLi6SkJE6dOkXNmjXx9fWlQoUKPPfcc46gdKc6br2nbdCgQSxevJgrV64QHx/PwoULef755wEYMGAA7u7uaX4sXLgQsN9X98wzz7Bq1Sref//9FPdieXt7Y7VaXaINp4iIiEiOZbHA8OH2INWtW44IUuACDSiytWvXbv/av59JdO7c7Y/9d6OFf3XIuxt58uThwoULTJ8+nd27d7No0SKWL19OREQExYsXd7R8XLBgAfHx8QwdOhSAMmXKsHTpUpo1a8a1a9eIj4+nevXqXL9+neeff56hQ4c6uvn9e7newIEDGTx4sKOpyKJFizh06BAAjRs3ZsqUKTRv3pywsLDb1n0jRN36/LC6detSr149FixYQOHChSlTpgxNmzYFYNKkSbzyyitpnuvGslCLxcJPP/2Eu7s7mzZtomHDho5jYmNjMZvNht/oKCIiIpKjmc32manp02HGDMgh//ZSmLoXGbmHyVnHZkBQUBBdunTBx8cnxTK/xMRExzI/k8nkaPiwadMmLly4QHR0ND179iRv3ry89957gL1Jxa1tIydMmMDy5cv5888/qVy5Mj/88AMtWrTg0KFDeHp6UrRoURYvXswnn3zC9u3bqVq1KlWrVk1VY4ECBTCZTFy8eNGxjA9g8ODBTJw4kaJFizpmpQBKly5N6dKl73jds2fPJjo6mm+++YbHH3+cnj17Ou7JunTpEgUKFLjL76iIiIiI3NG5c/bbXQDKlIGs6GuQhbTMLxeIjo7m7bff5scff8TX15e8efPyzjvvMGfOHHx9ffHy8uLLL790HP/7778zcOBAKleuTFBQEH/88Qc1atTgk08+YdeuXQCMHDmSCRMmOL7mueee4+TJk6xfv5533nmHsWPH8sMPPzBq1CgCAwNxd3dn5cqVmM1mDh48mGaQAvvMVPHixTl69GiK/cHBwVy5coW9e/fSt2/fdF/7yZMnGT9+PO+99x5du3alW7duDBo0yPH60aNHKVeuXLrPJyIiIiLp9N13ULGifUlfDqUwlUNdvnyZVatWsWbNGtasWcOsWbOoXbs2MTExXLt2jVdeeYWhQ4cSGxvL9evXeeyxxxxfu2vXLk6ePAngCF/ly5dn9OjRWCwWrly5wvPPP8+CBQtY9r8fjn/++Yc+ffowfPhwVq9ezdtvv82lS5eYNWsWISEhALzxxhv88MMP/Pnnn3esvXbt2vz+++8p9nl5edGiRQt69+5Nvnz50v19ePHFF2nXrp2jmck777zDjh07WLx4MQC7d+/mvvvuS/f5RERERCQdvv0WHn3U3oBt5Uqjq3Eahakc6u+//6Zbt26cPXuWefPm8ddff5EnTx7HfUi38vLywmKxOJowrFy5kjp16gD2Tok3mkKMHTuWUqVK0axZM86fP8/UqVP56quvAPuzocqWLUuBAgWIjo5m0qRJPPbYY/Tv398x81OzZk2mT59O69atWbBgwW1rb9asGT/++GOKfTExMXz//fcpZpXSY+XKlYSGhjq2S5QoweXLl+nTpw8A4eHhjvuvRERERCQTrFwJwcH2duc9e8L/moLlRLpnKoeqXr06U6dOZdiwYcTGxjJ//nyGDRsG2DvYubm5YbPZmD17NvHx8YA9WDRv3pyHH36YRo0aAdChQweaNWuG2WwmOTkZT09PAgICqFOnDg888AADBw4E4Oeff6Zq1ao8+OCDmM1mxowZQ4ECBRg1ahRff/01J06cwN3dnT59+mCz2di6davjmVX/FhgYyFtvvcXVq1cd9zMtWrSIWrVqpXge1r06evQoe/bsuePDjEVEREQkA1asgB49IDkZHn8cvvgC3HNu5Mi5V5bL5cuXj5EjRzoebPzss88ycOBAfH19UzwfCsBqtXLt2jW8//eQ4SFDhjhee/fdd5k5cyZJSUl4eHikeBDwraZPn05iYiKFChXCarXy4osvEhQUhIeHB++++y5ly5Z1zHb17duX3r1737b2Bg0aOALeDfPmzePll1/O8PfhTipWrIjFYsnUc4qIiIjkWqGh9pmo5GTo1cs+I5WDgxQoTOUavr6+KZ6vdCs3Nzfy589/2681m823DVE35MmThzz/60Lo5uZGz549Ha/99NNPab5nRvz7HioRERERcTE//mgPUr17w+ef5/ggBQpTIiIiIiKSGd55Bxo0gD59Uj9zNYdSA4p0uvEcJsldNO4iIiIid/Djj5CYaP/cZIJ+/XJNkAKFqf/k8b+nM8fGxhpciRjhxrh75JCndIuIiIhkmqVLoXVre8OJG4Eql9Eyv/9gNpspWLAg586dA0izgYMrs1qtJCYmEh8fn+H7lHIzm81GbGws586do2DBgv95z5iIiIhIrvLll9C3L1itULhwrpqNupXCVDqULFkSwBGoshObzUZcXBw+Pj7ZKgS6ioIFCzrGX0RERESAJUvgiSfsQerpp+GTTyCX/tJeYSodTCYTfn5+FC9e3PFg2+wiKSmJH3/8kYceekhL1TLoTq3gRURERHKlxYvt90VZrfDMMzBvXq4NUqAwlSHpaRHuam48bNfb21thSkRERETu3q1B6tln4aOPcnWQAoUpERERERFJj7Jlwdvbfq/U3Lm5PkiBwpSIiIiIiKTHQw/Bb79B1aoKUv+j74KIiIiIiKRt0SL444+b29WrK0jdQt8JERERERFJ7bPP7PdItWkD//xjdDUuSWFKRERERERS+vRTGDAAbDbo1QtKlza6IpekMCUiIiIiIjd9/LG9Wx/ASy/B7Nmg55WmSWFKRERERETs5s2D556zf/7yy/DOOwpSd6AwJSIiIiIisGIFPP+8/fNXXoFZsxSk/oNao4uIiIiICLRtC82aQePGMH26glQ6KEyJiIiIiAjkywcbN4KXl4JUOmmZn4iIiIhIbjVnDkyZcnPb21tBKgM0MyUiIiIikhu9+6793iiApk2hZUsjq8mWNDMlIiIiIpLbvPPOzSA1ahS0aGFsPdmUwpSIiIiISG4yaxYMG2b/fMwYePNNLe27SwpTIiIiIiK5xYwZEBJi/3zcOHjjDQWpe6AwJSIiIiKSG+zaBSNG2D9//XWYOFFB6h6pAYWIiIiISG7QoIG96cTlyzBhgtHV5AgKUyIiIiIiOVlCgv3ZUQAvvWRsLTmMlvmJiIiIiORUU6ZAs2b22SjJdApTIiIiIiI50Ztv2rv1/fYbrFhhdDU5ksKUiIiIiEhO88YbMHas/fMpU+Dpp42tJ4dSmBIRERERyUkmTrR36wOYOtX+UF5xCjWgEBERERHJKSZMsIcpgLfegldfNbScnE5hSkREREQkJ7h4ET7+2P759OkwfLix9eQCClMiIiIiIjlBkSKwZQts2gSDBhldTa6gMCUiIiIikl3ZbHDoEFStat+uWvXm5+J0akAhIiIiIpId2Wz21ud16sD69UZXkyspTImIiIiIZDc2m71L39SpkJBgn52SLKdlfiIiIiIi2YnNBiNHwttv27ffew9eeMHYmnIphSkRERERkezCZrO3O58xw779/vswZIixNeViClMiIiIiItmBzWZvdz5rln37gw9g8GBja8rlFKZERERERLIDqxXOnLF/PncuPP+8sfWIwpSIiIiISLZgNsPnn8NTT0HbtkZXI6ibn4iIiIiI67LZYMkSsFjs2+7uClIuRGFKRERERMQV2WwwdCj06QMDB9q3xaVomZ+IiIiIiKux2eztzj/8EEwmaNbM/qe4FIUpERERERFXYrXag9TcufYA9X//Z79PSlyOwpSIiIiIiKuwWu3PjfroI3uQ+uwz6N/f6KrkNhSmRERERERcxUsv3QxSCxZAv35GVyR3oAYUIiIiIiKu4uGHwdsbFi5UkMoGNDMlIiIiIuIqOneGI0fAz8/oSiQdNDMlIiIiImIUqxVGjrQHqBsUpLINhSkRERERESNYLDBgALz1lv1BvPHxRlckGaRlfiIiIiIiWc1igaeftt8bZTbD1Kn2e6UkW1GYEhERERHJShaL/blRX3xhD1JLlkCPHkZXJXdBYUpEREREJKtYLPbnRi1aZA9SX34Jjz1mdFVylxSmRERERESyyqRJ9iDl7g5ffQWPPmp0RXIP1IBCRERERCSrDB0KDzwAS5cqSOUAmpkSEREREXEmmw1MJvvnRYrAL7/Yl/hJtqeZKRERERERZ0lOhl69YN68m/sUpHIMhSkREREREWdISoLeve1L+oYOhZMnja5IMpmW+YmIiIiIZLakJPuM1DffgKen/c+yZY2uSjKZwpSIiIiISGZKSoLHH4fQUHuQCg2FTp2MrkqcQGFKRERERCSzJCbag9SKFfYgtWIFdOxodFXiJApTIiIiIiKZJTTUHqC8vGDlSujQweiKxIkUpkREREREMkvPnvDXX9CoETz8sNHViJMpTImIiIiI3IuEBHsL9Dx57M+Tev11oyuSLKLW6CIiIiIidyshAR59FDp3huvXja5GspjClIiIiIjI3YiPh6AgWLMGtm+HyEijK5IspmV+IiIiIiIZdSNIrVsHPj6werX9PinJVRSmREREREQyIj4eunWD9evtQWrNGmjVyuiqxABa5iciIiIikl5xcRAYaA9Svr6wdq2CVC6mmSkRERERkfQ6dgx+/fVmkGrRwuiKxEAKUyIiIiIi6VWjBmzcCNeuwUMPGV2NGExhSkRERETkTmJj7Q/irVfPvt2ggaHliOvQPVMiIiIiIrdz/br9GVIBAfDzz0ZXIy5GYUpEREREJC03gtTmzfZtm83YesTlaJmfiIiIiMi/Xb8OnTrB1q2QLx98/z00bWp0VeJiFKZERERERG517Zo9SP34oz1IrV8PTZoYXZW4IEOX+Z09e5bevXtTuHBhypYty6RJk7BarUyYMAGTyZTqo379+thuM726cOHCVMdHRkZm8RWJiIiISLZ27Rp07GgPUvnzQ1iYgpTclqEzU4GBgZQrV45169YRExNDSEgInp6evPDCCzz++OOO42JjY2nRogXjx4/HZDKlea7IyEj69OnD2LFjHfsqVark9GsQERERkRzEw8M+G1WggD1INWxodEXiwgwLUxcvXmT79u2sWrWKEiVKADB69GjeeustRo4cSdGiRR3Hzpgxg8qVKxMYGHjb80VGRtK+fXuqV6/u9NpFREREJIfy8oJvvoHDh6FWLaOrERdn2DK/QoUKUb16dSZPnszVq1c5efIkc+fOpXDhwimOi42NZfr06bz++uu3nZUCe5iqVq2as8sWERERkRzGPTYWtw8+uNmtz9tbQUrSxbCZKTc3N5YuXcqDDz7I+++/D0CxYsUICwtLcdzcuXMpVaoU3bp1u+25oqOjOXnyJE899RRJSUk89NBDvPfee5QpU8aZlyAiIiIi2d3VqzSZOBHzwYNw6RJMmmR0RZKNGBamYmJi6NmzJ+3btyckJIRLly4xZcoUzp075zgmLi6O6dOnM3fu3DvOSp0/f5433niD5s2bYzKZmD59Oh07dmTXrl24u6e+xISEBBISEhzb0dHRACQlJZGUlJSJV2m8G9eT064ru9E4uAaNg2vQOBhPY+AaNA4u4OpV3Dp2pPDBg9gKFSK5c2fQeBjClX4eMlKDyXa79nhONnv2bD755BN+//13R+D5888/adq0KSdOnCB//vzMmjWLhQsXsnv37juGqX+Li4ujXLlyLFu2jFatWqV6fcKECUycODHV/iVLluDr63v3FyUiIiIi2YL7tWs0nTiRQocOkZgvHz9PnMhVNS8T7LcZ9e7dm6tXr5I/f/47HmvYzNTBgwdp1apVipmjmjVr4u7uzp49e3jggQd4++23+fDDDzMUpAB8fHwoX748p06dSvP1UaNGMWzYMMd2dHQ0ZcuWpX379v/5DctukpKS2LBhA+3atcPDw8PocnItjYNr0Di4Bo2D8TQGrkHjYKArVzB37IjboUPYChfmp7FjafTccxoHA7nSz8ONVWvpYViY8vf357vvvkux7/Dhw1y8eJEyZcrw0UcfUaJECbp3737H8xw/fpzmzZvzyy+/ULp0aQCioqL4888/qVGjRppf4+XlhZeXV6r9Hh4ehg+es+Tka8tONA6uQePgGjQOxtMYuAaNQxazWKBLF9i5E4oUIfn774k+dUrj4CJcYRwy8v6GdfPr378/+/btY/DgwWzfvp3Vq1fTtWtXAgMDKVmyJG+//fZtO/itXbsWPz8/du/eTfny5alUqRI9e/bkxx9/JCwsjE6dOtGiRQvuv/9+A65MRERERFyW2QwvvAAlSsAPP0DdukZXJNmYYWGqSJEihIWFsW/fPlq0aMHgwYNp27YtX3zxBWfOnKFly5YEBQWl+bXJycnExcVhtVoBWLZsGaVLl6Zr16707NmTunXr8uWXX2bl5YiIiIhIdtG3Lxw6BHXqGF2JZHOGLfMDqF+/Plu3bk21P1++fHcMQ127duXKlSuO7RIlSrB06VJnlCgiIiIi2d3FizBkCLzzDvj52ffly2dsTZIjGBqmRERERESc6uJFaNsWfv8dzpyBzZshg83NRG7HsGV+IiIiIiJOdeECtGljD1IlSsCHHypISabSzJSIiIiI5Dw3gtQff0DJkvYZqerVja5KchjNTImIiIhIznL+PLRurSAlTqcwJSIiIiI5y8CBsHevvdnEli0KUuI0WuYnIiIiIjnLe+/BpUvwySdQtarR1UgOpjAlIiIiItlfcjK4/++ftmXK2Gek1GxCnEzL/EREREQkeztzBurXh1ufO6ogJVlAYUpEREREsq+oKGjVCiIjYeRIiI83uiLJRbTMT0RERESyp9On7UHqr7+gbFnYuBG8vY2uSnIRzUyJiIiISPZza5AqV85+j5S/v9FVSS6jMCUiIiIi2cupU9CypT1IlS9vD1KVKhldleRCWuYnIiIiItnLggVw6NDNIFWhgsEFSW6lMCUiIiIi2cvo0fZW6P372wOViEEUpkRERETE9UVFQZEi4Olpb3s+frzRFYnonikRERERcXHHj0OzZtCjByQmGl2NiINmpkRERETEdR0/bm82ceyYfUbq4kXw8zO6KhFAM1MiIiIi4qqOHbsZpPz9YetWBSlxKQpTIiIiIuJ6jh69GaQqV7YHqTJljK5KJAWFKRERERFxLUeO2IPU8eNQpYq9/Xnp0kZXJZKKwpSIiIiIuJaoKPu9UVWrKkiJS1MDChERERFxLc2awfr1UKmS7pESl6YwJSIiIiLG+/tviI2FOnXs282aGVuPSDpomZ+IiIiIGOvvv+33SLVpA5GRRlcjkm4KUyIiIiJinEOHoEULOHUKiheHYsWMrkgk3RSmRERERMQYf/1lD1KnT0OtWvDDD1CihNFViaSbwpSIiIiIZL2DB+1L+6KioHZtBSnJltSAQkRERESy1o17pM6cgfvug02btLxPsiWFKRERERHJWiVKgL+//R6pjRsVpCTb0jI/EREREcla+fLBunWakRIALBYL27ZtA2Dbtm1YLBaDK0o/hSkRERERcb59++Cdd25u58sHRYsaV4+4hNDQUCr7+9OpUycAOnXqRGV/f0JDQw2uLH0UpkRERETEuSIjoVUrGDYM/u//jK5GXERoaCjBwcHcV7I0G6fMAmDjlFncV7I0wcHB2SJQKUyJiIiIiPPs3QutW8P589CgAXTvbnRF4gIsFgshw4bRuWETVo57kwer1gDgwao1WDnuTTo3bMLwkBCXX/KnMCUiIiIizvHHHzeD1P3325tNFC5sdFXiAsLDwzl2/Dije/bFzS1lJHFzc2NUjz4cPXaM8PBwgypMH4UpEREREcl8e/bYg9SFC/DAA/YgVaiQ0VWJi4iKigKgdvmKab5eu3ylFMe5KoUpEREREclcly5BmzZw8SI8+CBs2AAFCxpdlbgQPz8/ACKPH03z9cjjR1Ic56oUpkREREQkcxUuDOPHQ6NGClKSpoCAACqUL8+UpYuwWq0pXrNarUxdtpiKFSoQEBBgUIXpozAlIiIiIpnvxRchPBwKFDC6EnFBZrOZmbNmsXpHBN3eGMOOg38CsOPgn3R7Ywyrd0QwY+ZMzGazwZXemcKUiIiIiNy7336Ddu3g8uWb+zw8jKtHXF5QUBDLly9n75lTtBsTAkC7MSFEnj3N8uXLCQoKMrjC/6YwJSIiIiL35tdfoW1be5OJ0aONrkaykaCgIP4+fJg1a9YAsGbNGg79/Xe2CFKgMCUiIiIi92LHDvuM1JUr0KwZvP220RVJNmM2m2nevDkAzZs3d/mlfbdSmBIRERGRu7N9uz1IXb0KzZvDunWQL5/RVYlkGYUpEREREcm4X36B9u0hOhoCAhSkJFdSmBIRERGRjLFY4Omn7UGqRQtYuxby5jW6KpEspzAlIiIiIhljNsPKldCrF6xZoyAluZbClIiIiIikz7VrNz+vWhWWLIE8eYyrR8RgClMiIiIi8t+2bYOKFWH9eqMrEXEZClMiIiIicmfh4dChA1y4AO+/Dzab0RWJuASFKRERERG5vR9/hEcegevX7Q/mXbYMTCajqxJxCQpTIiIiIpK2rVtvBql27eDbb8HHx+iqRFyGwpSIiIiIpLZ5M3TsCLGx8PDDsGqVgpTIvyhMiYiIiEhqS5bYg1SHDvY26ApSIqm4G12AiIiIiLiguXOhenUYMgS8vY2uRsQlaWZKREREROz++AMsFvvn7u4QEqIgJXIHClMiIiIiAhs2QKNGMGDAzUAlInekMCUiIiKS261fD126QHw8XLqkMCWSTgpTIiIiIrnZ999DYCAkJNj/XL4cPD2NrkokW1CYEhEREcmt1q2Dbt3sQapbN/sDeRWkRNJNYUpEREQkN1q79maQ6t4dli5VkBLJIIUpERERkdzIagWbDR59VEFK5C4pTImISJaxWCxs27YNgG3btmHRTe4ixuncGcLD4csvwcPD6GpEsiWFKRERyRKhoaFU9venU6dOAHTq1InK/v6EhoYaXJlILrJ2LRw+fHO7USMFKZF7oDAlIiJOFxoaSnBwMPeVLM3GKbMA2DhlFveVLE1wcLAClUhWWLXKfo9Uy5Zw6pTR1YjkCApTIiLiVBaLhZBhw+jcsAkrx73Jg1VrAPBg1RqsHPcmnRs2YXhIiJb8iTjTihUQHAxJSdC8OZQoYXRFIjmCwpSIiDhVeHg4x44fZ3TPvri5pfxrx83NjVE9+nD02DHCw8MNqlAkhwsNhR49IDkZevWCL74Ad3ejqxLJERSmRETEqaKiogCoXb5imq/XLl8pxXEikom++eZmkOrTBxYuVJASyUQKUyIi4lR+fn4ARB4/mubrkcePpDhORDLJ999Dz55gsUDfvvD55wpSIplMYUpERJwqICCACuXLM2XpIqxWa4rXrFYrU5ctpmKFCgQEBBhUoUgO9eCDULs2PPEELFgAZrPRFYnkOPr1hIiIOJXZbGbmrFkEBwfT7Y0xvNazL1QqxY6Df/LW0kWs3hHB8uXLMesfeiKZq0gR2LIF8uVTkBJxEs1MiYiI0wUFBbF8+XL2njlFuzEhALQbE0Lk2dMsX76coKAggysUySGWLIGPPrq5XbCggpSIE2lmSkREskRQUBCBgYH8+OOPREdHs2bNGh566CHNSIlklsWLoV8/sFqhWjVo1croikRyPM1MiYhIljGbzTRv3hyA5s2bK0iJZJZFi24GqWeegRYtjK5IJFdQmBIRERHJzr744maQevZZmDcP3PRPPJGsoJ80ERERkezq88/hySfBZoOBA+33SylIiWQZ/bSJiIiIZEd79sBTT9mD1HPPwdy5ClIiWUwNKERERESyo7p14fXX4dw5eP99BSkRAyhMiYiIiGQnVuvN4DR+vP1Pk8m4ekRyMf0KQ0RERCS7+PRTaNcOrl+3b5tMClIiBlKYEhEREckOPv7Y3q3vhx/sjSdExHAKUyIiIiKubt48e5MJgJdfhkGDDC1HROwUpkRERERc2dy58Pzz9s9feQVmzdLSPhEXoTAlIiIi4qo++AAGD7Z/HhICM2cqSIm4EIUpEREREVd06dLNbn3Dh8P06QpSIi5GrdFFREREXFHhwrBhA3z3HYwbpyAl4oIUpkRERERcyZkzULKk/fP69e0fIuKStMxPRERExFW88w5UrQo//2x0JSKSDoaGqbNnz9K7d28KFy5M2bJlmTRpElarFYDk5GS8vLwwmUyOj+HDh6d5nmvXrvH000+TP39+ihYtyogRI0hOTs7KSxERERG5N7NmwbBhEBMDmzYZXY2IpIOhy/wCAwMpV64c69atIyYmhpCQEDw9PRk5ciR//fUX7u7u7Nmzx3F8kSJF0jzP888/z969e/nuu+9ISEhg0P+evTB9+vQsuQ4RERGRezJzpr3JBNjvjxo71th6RCRdDAtTFy9eZPv27axatYoSJUoAMHr0aN566y1GjhxJZGQkVapUoXr16nc8z+nTp/nyyy/5448/qFWrFgCfffYZ7du3Z8yYMRQsWNDZlyIiIiJy19xmzoRRo+wb48fDhAmG1iMi6WfYMr9ChQpRvXp1Jk+ezNWrVzl58iRz586lcOHCAERGRlKtWrX/PM+2bduoUqWKI0gBPPTQQ5QoUYKtW7c6rX4RERGRe1U5NBTzjSA1YYKClEg2Y9jMlJubG0uXLuXBBx/k/fffB6BYsWKEhYUB9jD1ww8/ULBgQcqXL8+kSZMIDAxMdZ4TJ05QuXLlFPtMJhP+/v4cOXIkzfdOSEggISHBsR0dHQ1AUlISSUlJmXJ9ruLG9eS068puNA6uQePgGjQOxtMYuIak+HiK7NsHgOX117GOHg0akyynnwfX4ErjkJEaDAtTMTEx9OzZk/bt2xMSEsKlS5eYMmUK586dA6BBgwb069ePUqVKsWXLFnr06MHWrVtp3LhxivPExcXh6+ub6vyFChXi+vXrab731KlTmThxYqr9YWFhaZ4rJ9iwYYPRJQgaB1ehcXANGgfjaQyM5/baa/j98gunGjSAtWuNLidX08+Da3CFcYiNjU33sYaFqc8++wyz2cyKFStwd7eXUb16dZo2bcqJEycYe8uNlw0bNuTEiRPMnTs3VZjy8fEhPj4+1fmvXLly22A0atQohg0b5tiOjo6mbNmytG/fnvz582fG5bmMpKQkNmzYQLt27fDw8DC6nFxL4+AaNA6uQeNgPI2BsUwbN2Jr04ak5GQ2bNhAzTfeoK7GwTD6eXANrjQON1atpYdhYergwYO0atXKEaQAatas6ejgFxAQkOL46tWrs3LlylTnKVeuXJrL+Q4fPkylSpXSfG8vLy+8vLxS7ffw8DB88JwlJ19bdqJxcA0aB9egcTCexsAAb7wBr78Or7wC06YBGgdXoXFwDa4wDhl5f8MaUPj7+7N3794U+w4fPszFixd59913effdd1O8tmnTJmrUqJHqPM2bN+fAgQMcPnzYse+XX34hKiqKFi1aOKV2ERERkQybONEepACKFweTydh6ROSeGRam+vfvz759+xg8eDDbt29n9erVdO3alcDAQDp16sTrr7/OwoUL+fXXX3nppZdYv369Y2nexx9/TLly5Th9+jSlSpXi8ccf5/HHHyc8PJyNGzfSv39/XnzxRQoVKmTU5YmIiIjcdGunvmnTYORII6sRkUxi2DK/IkWKEBYWxssvv0yLFi0oXrw43bt3Z/LkyeTLl4+rV6/y+uuvc+bMGerXr09YWBgVK1YE7Gsq4+PjsVqtAHz00Ue8+OKLdOrUCU9PT/r378/UqVONujQRERERO5vNHqImTbJvv/02jBhhaEkiknkMC1MA9evXv+2zoF555RVeeeWVNF8bMmQIQ4YMcWznzZuX+fPnM3/+fKfUKSIiInJXbg1SM2ZASIih5YhI5jJsmZ+IiIhIjlelCri5waxZClIiOZChM1MiIiIiOVrfvvDAA1C9utGViIgTaGZKREREJLPYbDBzJpw+fXOfgpRIjqUwJSIiIpIZbDZ47TUYPhxat4a4OKMrEhEn0zI/ERERkXtls8Grr9qbTAC8+CL4+Bhbk4g4ncKUiIiIyL2w2eyzUbNm2bc/+AAGDza2JhHJEgpTIiIiInfLZoNhw+Ddd+3bH34IgwYZWpKIZB2FKREREZG7NW3azSD10Ufw3HOGliMiWUsNKERERETuVr9+9mdJzZunICWSC2lmSkRERORulS4Nf/wB3t5GVyIiBtDMlIiIiEh62Wzw0kuwdOnNfQpSIrmWwpSIiIhIelitMGQIzJkDTzwBx48bXZGIGEzL/ERERET+y40g9dFHYDLBJ59A+fJGVyUiBlOYEhEREbkTq9Xe7vzjj+1B6vPP7TNTIpLrKUyJiIiI3I7VCs8/b5+JcnOzB6m+fY2uSkRchMKUiIiIyO0sW3YzSC1cCH36GF2RiLgQhSkRERGR2+nZEyIioFEj6N3b6GpExMUoTImIiIjcymKxf3h62u+Rmj3b6IpExEWpNbqIiIjIDRYLPP00PPYYJCYaXY2IuDjNTImIiIiAPUg99RR88QWYzfDLL/DQQ0ZXJSIuTGFKRERExGKBJ5+ExYvtQeqrrxSkROQ/aZmfiIiI5G7JydCvnz1IubvD0qUQHGx0VSKSDWhmSkRERHKvG0Hqyy/tQWrZMuje3eiqRCSbUJgSERGR3OvgQfj2W3uQ+vpr6NbN6IpEJBtRmBIREZHcq1YtWLsWrlyBrl2NrkZEshmFKREREcldkpLgxAnw97dvq9GEiNwlNaAQERGR3CMpCXr1gkaN4I8/jK5GRLI5hSkRERHJHZKS4PHH4ZtvICYG/vnH6IpEJJtTmBIREZGcLzERevaE0FDw9IQVK6BjR6OrEpFsTvdMiYiISM6WmAg9esCqVeDlBStXQocORlclIjmAwpSIiIjkXImJ8Nhj9vbnXl72QPXww0ZXJSI5hJb5iYiISM6VmAiXLoG3tz1QKUiJSCbSzJSIiIjkXHnz2p8jFRkJTZoYXY2I5DCamRIREZGcJT4evvrq5na+fApSIuIUClMiIiKSc8THQ1CQ/VlSb71ldDUiksNpmZ+IiIjkDPHx0L07fP89+PjAgw8aXZGI5HAKUyIiIpL9xcVBt24QFga+vrBmDbRsaXRVIpLDKUyJiIhI9hYXB4GBsGGDPUitXQstWhhdlYjkArpnSkRERLIvi+VmkMqTB9atU5ASkSyjMCUiIiLZl9kMXbrYW6CvWwcPPWR0RSKSiyhMiYiISPb24otw6BAEBBhdiYjkMgpTIiIikr1cv24PUJcu3dxXsqRx9YhIrqUGFCIiIpJ9XL8OnTrB1q2wbx9s2gQmk9FViUgupZkpERERyR6uXYOOHe1BKn9+mDJFQUpEDKWZKREREXF9N4JUeLg9SIWFQaNGRlclIrmcZqZERETEtcXEwCOP2INUgQL2NugKUiLiAjQzJSIiIq7tmWdg27abQerBB42uSEQE0MyUiIiIuLrJk6FWLdi4UUFKRFyKZqZERETE9dhsN5tLVKkCf/wBbvodsIi4Fv1fSURERFzL1avQqhV8//3NfQpSIuKCNDMlIiIiruPKFXj4YdixAw4dgr//Bh8fo6sSEUmTwpSIiIi4hsuXoX172LkTihSBtWsVpETEpSlMiYiIiPEuX4Z27eC336BoUdi0CerUMboqEZE7UpgSERERY126ZA9Su3bZg9QPP8B99xldlYjIf9LdnCIiImKsOXPsQapYMdi8WUFKRLINzUyJiIiIscaNg4sX4bnnoHZto6sREUk3hSkRERHJeleuQL58YDbbP957z+iKREQyTMv8REREJGtduAAtWsDTT4PFYnQ1IiJ3TTNTIiIiknXOn4c2bWDvXjh7Fk6fhrJlja5KROSuaGZKREREssa5c9C6tT1IlSwJW7YoSIlItqaZKREREXG+G0Fq3z7w87N37atWzeiqRETuiWamRERExLnOnoVWrexBqlQp+4yUgpSI5ACamRIRERHnioyEQ4duBqkqVYyuSEQkUyhMiYiIiHO1aQOrVkHlygpSIpKjKEyJiIhI5ouKgthY8Pe3bz/yiLH1iIg4ge6ZEhERkcwVFWW/R6plSzh82OhqREScRmFKREREMs/p0/YQdfAguLmByWR0RSIiTqMwJSIiIpnj1Cl7kPrrLyhf3t5solIlo6sSEXEa3TMlIiIi9+6ff+xL+/7++2aQqlDB6KpERJxKM1MiIiJyb/75xz4j9fff9gClICUiuYTClIiIiNwbHx/ImxcqVlSQEpFcRcv8RERE5N4UKQIbN0JcHJQta3Q1IiJZRjNTIiIiknHHj8PChTe3ixZVkBKRXEczUyIiIpIxx47Zm00cO2Zvff7EE0ZXJCJiCIUpERERSb9jx+zNJo4fhypVoHVroysSETGMlvmJiIhI+hw9Ci1a3AxSmzdD6dJGVyUiYhiFKREREflvR47Yg9SJE1C1qr1rn4KUiORyClMiIiJyZ5cv25f2nTwJ1arZg1SpUkZXJSJiOIUpERERubNCheDpp6F6dfvSPj8/oysSEXEJClMiIiLy3yZMgF9/VZASEbmFwpSIiIikdugQ9OoF16/f3Jc3r3H1iIi4ILVGFxERkZQOHrQ/RyoqCgoUgI8+MroiERGXpJkpERERuenWIFW7NkyaZHRFIiIuS2FKRERE7A4csHfti4qC++6DH36A4sWNrkpExGVpmZ+IiIjA/v32GamzZ6FOHdi0CYoWNboqkWzFYrEQHh5OVFQUfn5+BAQEYDabjS5LnMjQmamzZ8/Su3dvChcuTNmyZZk0aRJWqxWA8PBwHnjgAXx9falXrx6rV6++47kWLlyIyWRK8REZGZkVlyEiIpK9Wa0QHGwPUnXrKkiJ3IXQ0FAq+/vTqlUrevfuTatWrajs709oaKjRpYkTGRqmAgMDSU5OZt26dcyfP59vvvmGt99+mxMnTvDII4/QoUMHtm7dyhNPPEFwcDARERG3PVdkZCR9+vRh//79jo+qVatm4dWIiIhkU25usHgxtGmjICVyF0JDQwkODua+kqWJmPUhMd+sI2LWh9xXsjTBwcEKVDmYYcv8Ll68yPbt21m1ahUlSpQAYPTo0bz11ltcvHiRNm3aMHnyZAAefPBBTpw4wYcffkiTJk3SPF9kZCTt27enevXqWXYNIiIi2VpSEnh42D+vVw82bjS0HJHsyGKxEDJsGJ0bNmHluDdxc7PPVTSuXouV496k2xtjGB4SQmBgoJb85UCGzUwVKlSI6tWrM3nyZK5evcrJkyeZO3cuhQsXxt3dnd69e6c4vmrVqpw+ffq254uMjKRatWrOLltERCRHyHfsGO733Qc//2x0KSLZWnh4OMeOH2d0z76OIHWDm5sbo3r04eixY4SHhxtUoTiTYTNTbm5uLF26lAcffJD3338fgGLFihEWFka9evVSHb969WoeeOCBNM8VHR3NyZMneeqpp0hKSuKhhx7ivffeo0yZMmken5CQQEJCQoqvB0hKSiIpKeker8y13LienHZd2Y3GwTVoHFyDxsF4ybt20WzcOEwxMVjHjMGyfj2YTEaXlevoZ8E13Os4REVF4ePjQ/XyFUiy2VK9Xr18RXx8fIiKitJY34Er/TxkpAaTzZbGqGeBmJgYGjZsSOXKlQkJCeHSpUtMmTKFKVOm0L59+xTHfvLJJ7z66qvs27ePUqVKpTrX4cOH+fLLL2nevDkmk4np06dz4sQJdu3ahbt76rw4YcIEJk6cmGr/kiVL8PX1zbyLFBERcTH5jx6l6euv4xUTw+XKlfl5wgSS8+Y1uiwREZcRGxtL7969uXr1Kvnz57/jsYaFqdmzZ/PJJ5/w+++/OwLPn3/+SdOmTTlx4oSj8M2bN9OhQweWLFnCo48+mq5zx8XFUa5cOZYtW0arVq1SvZ7WzFTZsmW5cOHCf37DspukpCQ2bNhAu3bt8LixLl6ynMbBNWgcXIPGwUC//457hw6YLl3icpUqeG3ZgkexYkZXlWvpZ8E13Os4WCwW6tWtS60SpVjy6usplvpZrVZ6vz2JP89Fsfv333XP1B240s9DdHQ0RYsWTVeYMmyZ38GDB2nVqlWKmaOaNWvi7u7Onj17CAgI4M8//yQoKIgxY8akO0gB+Pj4UL58eU6dOpXm615eXnh5eaXa7+HhYfjgOUtOvrbsROPgGjQOrkHjkMV27YKHH4bLl7E2bMjPL71E+2LFNAYuQD8LruFux8HDw4MpU6cSHBzMY4ljGdWjD7XLVyLy+BGmLlvM6h0RLF++HG9vbydUnfO4ws9DRt7fsAYU/v7+7N27N8W+w4cPc/HiRcqUKcOZM2fo2LEjgYGBvP7667c9z/HjxylbtmyK4BQVFcWff/5JjRo1nFa/iIhItvLOO3D5MjRujGXNGpLz5DG6IpEcIygoiOXLl7P3zCmahgwhf/AjNA0ZQuTZ0yxfvpygoCCjSxQnMSxM9e/fn3379jF48GC2b9/O6tWr6dq1K4GBgZQoUYIuXbrg6+tLSEgIBw4c4MCBAxw6dAiAtWvX4ufnx+7duylfvjyVKlWiZ8+e/Pjjj4SFhdGpUydatGjB/fffb9TliYiIuJZPP4XXXoP166FAAaOrEclxgoKC+PvwYTZv3sySJUvYvHkzh/7+W0EqhzNsmV+RIkUICwvj5ZdfpkWLFhQvXpzu3bszadIkevXqxc6dOwGoU6eO42sKFCjAlStXSE5OJi4uDqvVCsCyZcsYOnQoXbt2xWQy0a1bN9555x1DrktERMRlHD8O5crZO/V5ecG0afb9LtAtSyQnMpvNtGzZ0ugyJAvdVZhKSEjgjz/+4MEHH0zzdavVyunTp2/bmvyG+vXrs3Xr1lT7V61adcev69q1K1euXHFslyhRgqVLl/534SIiIrnFr79Cu3bw1FMwa5Zan4uIOMFdLfOzWCx069bttq+/9957tGjRIkXHPBEREckiO3ZA27Zw9Srs3Anx8UZXJCKSI93VzJSvry9RUVEUKVKEkiVLUr16dR566CF69OjBkSNHGDduHNOnT0+zY56IiIg40fbt0L49REdDQACsXQs+PkZXJSKSI2VoZmrp0qXE/++3W6VLl+bs2bNs2bKFF154gZ07d1KpUiUefvhh3nzzTZ577jmnFCwiIiK3ERFhX9oXHQ0PPWQPUnogr4iI02RoZurVV19lwIAB1KpVi9jYWD799FN+/fVXDhw4wJkzZ3j11Ve5evUq//d//0evXr0oWrSos+oWERGRW/38M3ToADEx0LIlrF4Nan8uIuJUGQpTx48fJykpiU8//ZSPPvqI119/ndKlS7N69WpKly7tOG7SpEk8/PDD/Pzzz1rqJyIikhWOH4fr16FVK/juOwUpEZEskKFlflarldmzZ/Prr79SpEgR3nrrLRo2bMjKlSuJjIzk0UcfBWDUqFG4u7vz22+/OaVoERER+ZdevWDNGs1IiYhkoQzNTLm5ufH+++/TokULTCYTP/74I7t27SIuLo48efIQHh7OpEmT8Pf3p2bNmjRt2tRZdYuIiEhEBJQvD6VK2bc7dDC2HhGRXCZDM1OXLl3Cz8+PRx99lGbNmlGwYEHy5MlDt27dMJlMlCxZkitXrvD000/Tp08fZ9UsIiIiP/5obzbRqhWcOWN0NSIiuVK6Z6YsFgvFixfHZDLRq1cvLBYLAMnJyTzxxBP0798fDw8Pxo4dy5w5c7h+/brTihYREcnVtm6Fjh0hNhYqVIACBYyuSEQkV0r3zJTZbCYmJoYHHniAJUuWMGLECAYNGkTDhg1ZuHAh27dv5/Dhw4wePZqePXsyZcoUZ9YtIiKSO23ZcjNIPfwwrFyp50iJiBgkQ8v8fHx8iIqKYsWKFURERHD58mWuXbvG6tWrGTx4MIULF+bIkSOMHTuWo0ePcurUKWfVLSIikvv88MPNINWhg4KUiIjBMtSAwmq18sILLxAZGYnNZqNLly40bNiQ69ev06BBA2JjYwkLCwPg+eefx2w2O6VoERGRXOfHH6FzZ4iLsweqb74Bb2+jqxIRydUy3M1v+PDhHDhwgCtXrtC4ceMUr+/atcvx+aRJkzKnQhEREQF/fyhdGqpVswcpPcdRRMRwGQpTN1SvXj3N/aVutGYVERGRzFW6NISHQ6FCClIiIi4iQ/dMiYiISBZavx6+/PLmdsmSClIiIi4kQzNTly5dYuXKleTJkweTyXTb4xISEvDy8qJHjx73XKCIiEiu9P330K0bJCWBnx+0bGl0RWmyWCyEh4cTFRWFn58fAQEBumdaRHKNDIWpmJgYnnnmGQrc8jyL6Oho8uXL5whXNpuNmJgYmjdvrjAlIiJyN9atg+7dISEBAgOhaVOjK0pTaGgoIcOGcez4cce+CuXLM3PWLIKCggysTEQka2RomZ+Xlxcmk4nLly87Pmw2G3/99Zdj+8CBAwBs3brVKQWLiIjkaGvX2mekEhLsgWrZMvD0NLqqVEJDQwkODua+kqWJmPUhMd+sI2LWh9xXsjTBwcGEhoYaXaKIiNNlKEzdaWlfRo4RERGRNKxebQ9QiYkQFARLl7pkkLJYLIQMG0bnhk1YOe5NGlevRV4fXxpXr8XKcW/SuWEThoeEYLFYjC5VRMSp1IBCRETEFezdaw9QiYnw6KPw1Vfg4WF0VWkKDw/n2PHjjO7ZFze3lP+UcHNzY1SPPhw9dozw8HCDKhQRyRp31RpdREREMlnt2vDcc3D2LCxe7LJBCiAqKgqA2uUrpvl67fKVUhwnIpJTKUyJiIjgAl3pTCaYMwcsFnB37b+e/fz8AIg8fpTG1Wulej3y+JEUx4mI5FQZ+r/1jbXP4eHh2Gw2wH6PVEREBIUKFQLs7dMBtm/fTqNGjTKzVhEREacwrCvdihWwZIl9JsrT0x6oXDxIAQQEBFChfHmmLF3EynFvpljqZ7VambpsMRUrVCAgIMDAKkVEnC9D/8eOi4vDZrPRokWLFPu7d++e6tju3btz+vTpe6tORETEyW50pevcsAlfvvQatctXJPL4UaYsXURwcDDLly93TqAKDYWePSE5GZo3h5deyvz3cBKz2czMWbMIDg6m2xtjGNWjD7XLVyLy+BGmLlvM6h0RLF++XM+bEpEcL0Nhqly5cpw7d448efKkuuH0BpvNRnJyMteuXcuUAkVERJzl313pbvzddqMrXbc3xjA8JITAwMDMDQbffGMPUhYL9OkDQ4Zk3rmzSFBQEMuXLydk2DCahtysv2KFCs4LoCIiLiZDYcrDw4OiRYum69i8efPeVUEiIiJZ5UZXui9feu22XemahgwhPDycli1bZs6bfv019OplD1JPPAHz50M2ncEJCgoiMDDQ2HvNREQM5PoLs0VERJwky7vSLVsGvXvbg1S/fvDZZ9k2SN1gNpszL2iKiGQzd/WcqUuXLnHp0iWSkpIAiI6OJjExMVMLExERcbZbu9KlJVO70l25AgMH2oPUk0/miCAlIpLbZShMJSUlkZycTLFixShWrBhffvklAEOGDGHt2rVYrVanFCkiIuIMt3al+/ffYZnela5gQfjuOxg8GP7v/xSkRERygHSHqcuXL+Pn54e7uzvVqlUjJiaG7t2789tvv5EnTx48PDyoVKkSvr6+5M+fP80OfyIiIq7kRle61Tsi6PbGGCL2RxITG0vE/ki6vTGG1TsimDFz5r3dAxQTc/PzgAD44AMFKRGRHCLdYSpv3rzkyZMHAG9vb7777js+++wzXnzxRXx8fPDw8MDLy4ujR49y4MAB9u3bx/79+51WuIiISGa40ZVu75lTNA0ZQv7gR2gaMoTIs6fvvSvdokVQuTL88UfmFSwiIi4j3Q0o3N3d8fLycnxuMplwc3PDZDLh7u6O2WzG19eXEiVKALBixQqqV6/unKpFREQykVO60n3xhf3eKJvN/vn06ZlXsIiIuIR0hymTyeT4S8VsNlOvXj3i4uIoUaIEO3fuxGw24+HhQc2aNbHZbJQsWZLNmzc7rXAREZHMlKld6T7/HJ56yh6knnsO3norc84rIiIuJUOt0U+ePEn79u05cOAAL7zwAgC+vr5UrVqVVatWERsby7fffovFYsFkMjmlYBEREZe2YAE8/bQ9SD3/vP0eqds86F5ERLK3DIWpggULMmTIEF577TVeeOEFLBYLNpuNiIgI/vrrL06fPs3p06cBexekqlWrOqVoERERlzR/PgwYYA9SgwfD+++DfrkoIpJjpftXZTabDR8fHwIDAylYsCAAZ8+e5eOPP8ZkMjFixAj8/f35+OOP+eijj/j888+dVbOIiIjrsVrty/tsNhgyREFKRCQXSPfMVHJyMgkJCY7Pb3xcvnwZi8WC1WolKSmJRYsWOa1YERERl+XmZn+O1Pz58OKLClIiIrlAusNUbGws169fByAxMZFSpUrh7e1NjRo1SExMJDk5mWvXrqVoIRsaGpr5FYuIiLiS3buhfn375/nywdChxtYjIiJZJt3L/PLly8fOnTsB+/K+0NBQ4uLiWLBgAdevXycxMZERI0bQpk0b2rRpQ/PmzZ1WtIiIiEuYNw8aNIDJk42uREREDJDumSk3NzcqVqxIcnIygwcPBnA8d6p79+5Uq1aNzp07O6dKERERVzN3rr3JBMDFi/Z7pbS0T0QkV8lQNz+wP7B3/PjxKfZ16dIl0woSERFxeR98AP97RAjDhsGMGQpSIiK5UIYefHHw4EHOnz8PQHx8PC1atODcuXNOKUxERMQlvf/+zSA1fLiClIhILpbumamYmBgaNGjAr7/+SrFixfD29uaXX37h6tWrJCcnpzreYrFw7do1atSokakFi4iIGOa99242mHj1VZg2TUFKRCQXS3eYypcvHw0bNuTChQuOfW5ublSvXh2bzZbiWJPJhM1mw2QyYbFYMq9aERERI90ITiNHwpQpClIiIrlchu6ZatasGUeOHOGhhx5y7Dt//ryjEcWtLBYLsbGx916hiIiIq3jhBXv3viZNFKRERCRjYapGjRpERkY6tk0mE/ny5cPDwyPN4/Pnz39v1YmIiBjtiy+gUycoXNi+3bSpsfWIiIjLyFCYKlmyJMOGDeOnn37CZrORkJBAu3bt8PX1pXDhwtSqVYsHH3yQNm3aYNJv7EREJLubMQNGjLDPRm3bBj4+RlckIiIuJENh6r777mPevHn4+Pjg5uaGzWYjMTGR+Ph4Ll++zOHDhxk1ahQXL15kwoQJ9OvXz1l1i4iIONf06fYmEwCdO4O3t7H1iIiIy0l3mDpx4gRTp05l7ty5AAwfPpwTJ044XrfZbHz99dcArF27loEDB/Lbb78xe/bsTC5ZRETEyd56y95kAmD8eJgwwdByRETENaU7THl6evLtt986wtS2bdvo1q0bfn5+WCwWnnvuOcexHTt2ZMuWLRw/fjzzKxYREXGmqVNh9Gj75xMm2MOUiIhIGtIdpkqWLEn9+vU5dOgQVapUwWQyERQURNWqVbFYLDz//PMpjq9cuTKVK1fO9IJFRESc5r33bgapSZNg3Dhj6xEREZeWoXumAgICePvtt3nwwQc5d+4cy5Yto3Tp0ri7u2Oz2fj111+pWLEiRYsWdVa9IiIiztOhA5QqBYMGwdixRlcjIiIuLkNhqlGjRoSHhxMeHk5AQAAHDx4kMjKS2NhYmjZtSv/+/Tl27BhFixalS5cuvPTSS1SpUsVZtYuIiGSuKlVg796bbdBFRETuIENhqmXLlrRs2fKOx1gsFrZs2cK8efMoUqTIvdQmIiLifFOmQP368Mgj9m0FKRERSacMhan0MJvNtGnThjZt2mT2qUVERDLXhAkwcSJ4ecGBA1ChgtEViYhINuKWkYMTEhLo0aMHly5duu0x165d47HHHmPPnj33XJyIiIhT2Gz2Ln0TJ9q3J09WkBIRkQzLUJhyd3fnm2++wc3N/mX//PMPo0aNSnHM7t27iYqKonv37plXpYiISGa5EaQmTbJvz5wJw4cbW5OIiGRLGVrmZzabsdlseP/vKfC//vor7733HgkJCcyaNQuwd/xbvXo1RYoUwWKxYDabM79qERGRu2Gz2dudv/mmfXvWLHjlFWNrEhGRbCtDM1NgD1Tu7vYM1r17d3bs2MGaNWvo1asXFosFgIIFC2IymRzbIiIiLmH58ptB6p13FKREROSepDtM2Ww2atasidVqpWHDhkRFRXHhwgVq1qxJREQEBw4coF+/fgCcOXMGm83mCF0iIiIuISgI+vaFd9+Fl182uhoREcnm0p12rFYrc+fOpW3btsyePRt3d3fKlStHwYIFAYiNjWXPnj1s3LiRuLg4/P39HfdWiYiIGMZms3+4uYHZDAsXgslkdFUiIpIDpDtMmc1mWrRogclkolmzZsTFxbFixQry5MmD6V9/KZlMJvz9/TO9WBERkQyx2WDECDh/Hj77zB6mFKRERCSTZGgd3t9//w3AkSNHKF26NE2bNiVfvnxOKUxEROSe2Gz2Ln3/a5BEv36gZyCKiEgmytA6vO7du5OcnEzTpk1Zt24djRo14tNPP+XEiRO3/RAREclyNhsMG3YzSH30kYKUiIhkugzNTO3duxd3d3f++ecfPD09SUhI4Pnnn+fatWuAvUkF2Jf52Ww2dfQTEZGsZ7PZu/TNnm3fnjcPBg40tiYREcmRMtwhwmazkZCQAECvXr0IDw+nYMGCvPHGG1y+fJnLly8TFRXFkSNH2LVrV6YXLCIicls2m71L340g9fHHClIiIuI0GZqZSkhIwGazce3aNce9UnXq1GHp0qV07NiRFi1a0KxZM6cUKiIi8p/27bMv6TOZ4JNPYMAAoysSEZEcLENhytPTk/3791O8ePEU+9u2bcvixYtp0qRJphYnIiKSIbVrwzff2Lv3PfWU0dWIiEgOl6EwZTKZqFatWpqvPfbYY5lSkIiISIZYrXDuHJQsad/u3NnYekREJNfIUJj6559/0vUgXrPZTLFixfTQXhERcS6rFQYPhjVrYMsW0DMORUQkC6U7TNlsNipWrEjBggW5fPkyhQoV4urVqxQoUMBxzI0ufgBlypRh9+7dmV+xiIgI2IPU88/b740ymWDnToUpERHJUumeOjKZTFSvXp2///6bYsWKcf78efz9/Tl//jznz5/n9OnTDB061LHdqlUrLly44MzaRUQkt7Ja4bnn7EHKzQ0WLoSePY2uSkREcpkMrcMzmUyOjxvb0dHRVKxYEQ8PD95//33HsbNmzaJo0aKZW62IiIjVCs8+C59+ejNI9e1rdFUiIpILZeieqdjYWLZt20ZiYiI//vgjNpuN/Pnzc+3aNd5++22SkpJ4++23sVqtxMTE8OabbzqrbhERyY2sVnjmGZg/3x6kFi2CXr2MrkpERHKpdIcpq9VKmTJlmDNnDg8++CBTp06lbt269pO4uxMXFwdAXFwcNpuN5ORk51QsIiK517VrsHu3PUgtXgyPP250RSIikoulO0y5ubnx/fff4+np6diXmJgIQLFixRg/fjyLFi1i/PjxmV+liIgIQP78sHEj/PILdOpkdDUiIpLLpfueqStXrpA/f35KlCiBh4cHJUuWpGrVqgDs378fT09Pjh49SuPGjVm4cKHTChYRkVzGYrEHqBuKFFGQEhERl5DuMOXh4UG1atU4cOAAbm5unDt3jgIFCpCUlETp0qVJTEykVKlSzJo1i48//pjevXs7s24REckNLBbo3x/atYO5c42uRkREJIUMNaBIq5tfUlISo0ePJikpidjYWJo2bcqGDRv4/vvvnVKwiIjkEsnJ8OSTsGQJuLtD8eJGVyQiIpJChh7ae+HCBebNm4fVamXOnDlcuHCBTz/9FIC5c+cybtw45syZg8Vi4fLly3Tv3t1phYuISA6WnAz9+sGXX9qD1NKlEBRkdFUiIiIppDtMmUwmunbtyunTpxk0aBCHDh3i0Ucf5dChQymOs9lsJCYmEhMTk+nFiohILpCcbH9u1NKl9iD19dfQrZvRVYmIiKSS7jCVJ08ePvroI2fWIiIiuZ3VCn36wLJl4OFhD1KBgUZXJSIikqYM3TMlIiLiVG5uULOmPUgtXw5duxpdkYiIyG2lO0xZLBZGjBhBwYIF//NYk8lElSpVeFwPUxQRkYwaP97+MN5q1YyuRERE5I7SHaYSExO5fPkysbGxjm5+t3Pu3DkmTJhA69atKa7uSyIicidJSTB1KoSEQJ489n0KUiIikg2k+zlTPj4+zJ8/n9atW1OyZEn8/PxSfJQsWZLixYszd+5cpk+fTtGiRTl79uwdz3n27Fl69+5N4cKFKVu2LJMmTcJqtQKwdu1aatWqhbe3Nw0bNmTHjh23PU9ycjIjRoygaNGi5M+fnwEDBnDt2rX0XpqIiBglMRF69rTPRj36KNhsRlckIiKSbhm+Z+qPP/7g4sWLqfbbbDaSkpIAKF26NMeOHcPHx+eO5woMDKRcuXKsW7eOmJgYQkJC8PT0pGvXrgQFBfH666/TsWNHlixZwsMPP0xkZCSlS5dOdZ4JEyawdOlSvvjiC/LmzcuwYcN46qmn+PrrrzN6eSIiklUSE+1d+1auBC8vePll+I+VDyIiIq4kQ2Hqk08+oWrVqrd93dPTk/j4eLp3706DBg148803b3vsxYsX2b59O6tWraJEiRIAjB49mrfeeoujR4/SpUsXRo8eDUC9evX49ddfmT17Nm+//XaK8yQmJjJnzhy+/PJLHnnkEQCWLVtG5cqV+fPPP6lZs2ZGLlFERLKAKSkJ8+OPw+rV9iC1ahU8/LDRZYmIiGRIhsLUSy+9RHBwMFevXmX79u20a9eO7du3U6pUKQoXLsxff/3FTz/9RP78+Rk7duwdz1WoUCGqV6/O5MmTmTx5MtHR0cydO5fChQsTHh7O66+/nuL4vn378v7776c6z++//47VaqVDhw6OfRUrVqRp06Zs2LBBYUpExNUkJPDg22/j9uuv4O1tD1Lt2xtdlYiISIZlKEwVKFCAhQsXcvDgQZ599lm++OILnn32WR555BHuv/9+AgMDeemll6hYsSJms/mO53Jzc2Pp0qU8+OCDjpBUrFgxwsLCaN68OZUrV05xfOXKlTly5Eiq85w4cYIKFSqker/bHS8iIsYyDxqE36+/YvP2xvTtt9CundEliYiI3JUMham4uDi++OILTp06xblz51i4cCGHDh3Cx8eHY8eOYbFYmDBhAo0aNeLFF1+847liYmLo2bMn7du3JyQkhEuXLjFlyhTOnTtHXFwcvr6+KY4vVKgQ169fT7Omfx974/jo6Og03zshIYGEhATH9o3jkpKSHPd95RQ3rienXVd2o3FwDRoH15A8eDCsW4dpwQLMLVvau/lJltLPgmvQOLgGjYNrcKVxyEgN6Q5TCQkJtGjRgtWrV+Pm5kb9+vVZt24dfn5+nD9/nvPnzxMQEMCAAQPo06cPu3bt4rPPPrttG/XPPvsMs9nMihUrcHe3l1G9enWaNm2KzWYjPj4+xfFXrlxJMzT5+PikOvbG8Xnz5k3zvadOncrEiRNT7Q8LC0vzPXKCDRs2GF2CoHFwFRoH47nNnYvVYoG1a40uJVfTz4Jr0Di4Bo2Da3CFcYiNjU33sekOU15eXixfvpzAwEAee+wxnnrqKSIjIwGoXbs2//d//0fr1q2pWLEiW7ZsYdq0aXd8HtXBgwdp1aqVI0gB1KxZE3d3d2w2G0eOHKFBgwaO1w4fPkylSpVSnadcuXIcO3YMq9WKm5tbiuO7d++e5nuPGjWKYcOGObajo6MpW7Ys7du3J3/+/On9lmQLSUlJbNiwgXbt2uHh4WF0ObmWxsE1aBwMEh+PuX9/rC++iK1ZM42DC9AYuAaNg2vQOLgGVxqH261uS0uGlvkNGjSIs2fPEhgYSHJyMn379qVdu3Y8//zzhIaGMnToUPz8/Gjfvj0dO3a847n8/f357rvvUuw7fPgwFy9epH379nz77bcEBwc7Xlu6dClt27ZNdZ569eoBsGXLFlq3bg3AqVOn2LZtGx988EGa7+3l5YWXl1eq/R4eHoYPnrPk5GvLTjQOrkHjkIXi4iA4GMLCcPv5ZzhyBP73vdc4GE9j4Bo0Dq5B4+AaXGEcMvL+6X5oL+DokFe4cGF+/vlnrFYr06ZNw9/fnzVr1nDx4kUmTZrE7t272bt37x3P1b9/f/bt28fgwYPZvn07q1evpmvXrgQGBjJr1iy+/vprZs6cye+//864ceOIiIjg5ZdfBuwP9PXz82P37t14enoydOhQBg4cSFhYGD/99BM9evSgW7du1K5dOyOXJyIimSkuDgIDISwM8uSBpUvhP54/KCIikp1kaGbq6aefdnz+0EMPsWvXrhRd9Ly9venduze9e/cmMTHxjucqUqQIYWFhvPzyy7Ro0YLixYvTvXt3Jk+eTL58+fjmm28YPnw4Y8aMoU6dOoSFhVGmTBkAkpOTiYuLw2q1AvaH9sbHx9OrVy+SkpIIDg5m9uzZGbk0ERHJTLGx9iC1caM9SK1bBwEBRlclIiKSqdIdpv755x/q1KnDpUuXiI+PZ9u2bSnuUbohKSmJhx9+mBdeeIEKFSo4Hryblvr167N169Y0X+vYseNtlwp27dqVK1eu3LwId3dmzJjBjBkz0ns5IiLiLLGx0LUrbNoEefPag1Tz5kZXJSIikunSHaYKFiyYYhaqS5cuPPDAA/z+++/Uq1ePXbt20aBBAyIjI1m2bBnr1q1j+/btTilaRERc2Ntv3wxS338PzZoZXZGIiIhTpPueKQ8PD0fnPW9vb8qUKUN4eDgVKlQgPDycUqVKER4ejru7O9OmTeOjjz6iVKlSTitcRERc1KhR0KuXgpSIiOR4Gbpn6uLFiwQGBvLAAw849t1of37jT7PZzMqVK8mXL18mlikiIulhsVgIDw8nKioKPz8/AgICUqwqcJr4ePDyApPJ/ueSJc5/TxEREYOle2bKZrPh4+ND69atOXnyJDabLc3jrFYr7733HmfPns20IkVE5L+FhoZS2d+fVq1a0bt3b1q1akVlf39CQ0Od+8bXrkH79vDKK3CbvxtERERyonSHqcTERMxmMy+99BLz5s3jypUrzJo1iwsXLjBr1iwuX77MrFmzSEpK4u+//+aFF15wZt0iInKL0NBQgoODua9kaSJmfUjMN+uImPUh95UsTXBwsPMCVUwMPPIIhIfD/Plw/Lhz3kdERMQFpTtMxcXFUb9+fQDi4+N54oknOHjwIL169eLChQs888wznDt3jgEDBvDhhx+yZ88e1qxZ47TCRUTEzmKxEDJsGJ0bNmHluDdpXL0WeX18aVy9FivHvUnnhk0YHhKCxWLJ3De+EaS2bYMCBWDDBqhQIXPfQ0RExIWlO0y5u7tToEAB9u/fj4+PD++88w6tW7fmww8/5Oeff6Z///5MmzaNGTNm4O3tzYQJE1i0aJEzaxcRESA8PJxjx48zumffVI+scHNzY1SPPhw9dozw8PDMe9PoaOjQAX766WaQatgw884vIiKSDWSoNfrq1asJDw+nQ4cOPPHEE/z11188/vjjdO7c2fFA3Rt69uzJQw89lOkFi4hISlFRUQDULl8xzddrl6+U4rh7diNIRURAwYL2IHVLYyIREZHcIt0zU2azmQIFCnDy5Enq1q3LI488wpo1a1iyZAlPPfUUfn5+5M+f3/FRuXLl2zapEBGRzOPn5wdA5PGjab4eefxIiuPu2bZtsH07FCoEGzcqSImISK6V7jBltVqx2WyYTCY++eQTnnvuOUaNGkWPHj3Yu3dvio/ff/+dYsWKsXr1amfWLiIiQEBAABXKl2fK0kVYrdYUr1mtVqYuW0zFChUICAjInDfs2BEWLbIHqfvvz5xzioiIZEPpXuZ35coVYmJi8PT05Ntvv8X/f+123dzcKF++fKrjJ02axH333ZepxYqISGpms5mZs2YRHBxMtzfGMKpHH2qXr0Tk8SNMXbaY1TsiWL58+b09b+rKFYiLgxuzW716ZUrtIiIi2Vm6w1ShQoU4ffo0JpOJatWqAdCoUSMq3KZzU4cOHTKlQBER+W9BQUEsX76ckGHDaBoyxLG/YoUKLF++nKCgoLs/+ZUr9udIXb0KmzdDqVL3XrCIiEgOkO4wZTKZKFKkSIp95cuXT3NWSkREsl5QUBCBgYGEh4cTFRWFn58fAQEB9zYjdfmyPUjt3AlFisDFiwpTIiIi/5PuMCUiIq7PbDbTsmXLzDnZpUvQrh3s2gVFi8KmTaDl2yIiIg4KUyIiktqlS9C2LezebQ9SP/ygICUiIvIv6e7mJyIiucTFi9CmjT1IFStmv09KQUpERCQVhSkREUkpIQGuX4fixe1BqnZtoysSERFxSVrmJyIiKZUqZQ9R0dFQo4bR1YiIiLgszUyJiAicPw/ffXdzu3RpBSkREZH/oDAlIpLbnT9vv0eqWzdYvtzoakRERLINhSkRkdzs3Dlo3Rr27oUSJdRoQkREJAN0z5SISG51I0jt23fzPqmqVY2uSkREJNvQzJSISG509iy0amUPUqVLw5YtClIiIiIZpJkpEZHc5soVe5Dav/9mkKpc2eiqREREsh2FKRGR3KZAAWjbFmJi7Ev7FKRERETuisKUiEgOYrFYCA8PJyoqCj8/PwICAjCbzSkPMplg9mwYO9b+YF4RERG5K7pnSkQkhwgNDaWyvz+tWrWid+/etGrVisr+/oSGhsLp0zB0KCQk2A82mRSkRERE7pFmpkREcoDQ0FCCg4Pp3LAJX770GrXLVyTy+FGmLF3E0EcfpZ2fH/mioiApCebONbpcERGRHEFhSkQkm7NYLIQMG0bnhk1YOe5N3Nzsiw4aV6/FykEvc+b3XeSLisJWvjymV181uFoREZGcQ8v8RESyufDwcI4dP87onn0dQQqA8+dwG/UKpRLiOQpsnzYNKlY0rE4REZGcRmFKRCSbi4qKAqB2+VuC0rmz8NpLEHUKa/GStASO2myG1CciIpJTKUyJiGRzfn5+AEQeP2rfYbXCpNFw5jSULMXugUM4cctxIiIikjkUpkREsrmAgAAqlC/PlKWLsFqt4OYGg16CSpWxTn2HiRvWUbFCBQICAowuVUREJEdRmBIRyebMZjMzZ81i9faf6fbGGCL2RxJTsTIRg16i20ezWb0jghkzZ6Z+3pSIiIjcE3XzExHJAYLq1+eivz+9TxylacgQx/6KFSqwfPlygoKCDKxOREQkZ1KYEhHJ7o4cgVatKHTiBGubNGHr4sVEnTmDn58fAQEBmpESERFxEoUpEZHs7PBhaNUKTp6EqlUxLV9Oy1KljK5KREQkV1CYEhHJrg4fhpYt4Z9/oFo12LwZ1LFPREQky6gBhYhIdvT33zeDVPXqsGWLgpSIiEgWU5gSEcmOxo2zB6kaNewzUiVLGl2RiIhIrqNlfiIi2dEnn0CePPDmm1CihNHViIiI5EoKUyIi2cXFi1CkiP3zvHnh00+NrUdERCSX0zI/EZHs4MABuO8+mDzZ6EpERETkfxSmRERc3YED9vbnUVGwbBnExhpdkYiIiKAwJSLi2vbvt3ftO3MG6tSBH34AX1+jqxIREREUpkREXNeff9qD1NmzULcubNoERYsaXZWIiIj8j8KUiIgr2rfPHqTOnYN69RSkREREXJDClIiIK/r5Zzh/HurXtwepG138RERExGWoNbqIiCt69ln7c6Q6dIDChY2uRkRERNKgmSkREVexbx9cunRzu3dvBSkREREXpjAlIuIK9uyBFi2gbduUgUpERERclsKUiIjRfv8dWreGixfBwwPc9L9mERGR7EB/Y4uIGGn3bnuQunQJGjWCsDAoWNDoqkRERCQdFKZERIyyaxe0aQOXL0PjxrB+PRQoYHRVIiIikk7q5iciYoQbQerKFWjSBL7/HvLnN7oqERERyQCFKRERI+TLB76+ULMmrFunICUiIpINKUyJiBihShUID4dixezBSkRERLId3TMlIpJVtm+3z0LdUKmSgpSIiEg2ppkpEZGs8Msv8PDDEB8PmzZB8+ZGVyQiIiL3SDNTIiLOFhEB7dtDdLS9a1+9ekZXJCIiIplAYUpExJl+/tk+IxUTAy1bwtq1kDev0VWJiIhIJlCYEhFxlp9+uhmkWrWC1ashTx6jqxIREZFMojAlIuIM+/dDhw5w7Rq0bq0gJSIikgOpAYWIiDNUrQrdukFUFHz7rf2ZUiIiIpKjKEyJiDiD2QwLFkBiIvj4GF2NiIiIOIGW+YmIZJatW+H558FisW+bzQpSIiIiOZhmpkREMsOWLdCpE8TGQrVq8MorRlckIiIiTqaZKRGRe/XDD9Cxoz1IdegAgwYZXZGIiIhkAYUpEZF7sWkTdO4McXHwyCOwYgV4extdlYiIiGQBhSkRkbu1cePNINWxo4KUiIhILqMwJSJyN65cgeBgiI+33ysVGgpeXkZXJSIiIllIYUpE5G4ULAhLltgD1TffKEiJiIjkQurmJyKSEUlJ4OFh/7xjR/uHiIiI5EqamRIRSa9166BGDTh82OhKRERExAUoTImIpMfatdCtmz1IzZpldDUiIiLiAhSmRET+y+rV0L07JCbCo4/Cu+8aXZGIiIi4AIUpEZE7+e47CAqyB6ngYPjyy5v3TImIiEiupjAlInI7335rn4lKSoIePezd+xSkRERE5H8UpkRE0mK1wpQp9iDVsycsXqwgJSIiIikoTImIpMXN7f/bu/O4qOr9j+NvdlEEF0xIcUMFU69bpqaU5HLdUiMqQ7Nss67lRvnLtLTM0lzajKxotSyVSEst03LBcsmrVii2EWaKWy4gmzBzfn/MdZRYRATOMLyejwePZr7nzJnPmS/H4d33nO+RVq2Spk6VPvhAcudOEgAAID/CFABc6I8/zj+uW1eaMYMgBQAACkWYglOwWCzasGGDPvroI23YsEEWi8XsklAZxcVJISFSTIzZlQAAgEqAMIVKLz4+Xs2DgxUeHq6oqCiFh4ereXCw4uPjzS5Nki3obd68WZK0efNmgp6jWrZMGjbMdo3Utm2SYZhdEQAAcHCEKVRq8fHxioyMVNuABtoyP0bpn3yhLfNj1DaggSIjI00PVOeC3sCBAyVJAwcOdKigh/9ZulS6/XbJYpFGjpTefltycTG7KgAA4OAIU6i0LBaLoidO1KBrumn5EzPVNbS1fLyrq2toay1/YqYGXdNNj0RHmzYSdGHQW/fsfEnSumfnO0zQw/98/LEUFWULUnfdZQtSbm5mVwUAACoB08JUSkqKXFxcCv154YUXCm0PDAxUVlZWodvbtGlTgfVXrlxZwXuFipSQkKCU/fv1+G0j5Oqa/1fZ1dVVk28drj9SUpSQkFDhtf0z6HVu2UqS1LllK4cIevifjz6Shg+3BalRo6TYWIIUAAAoMdOmqGrQoIGSkpLytU2ZMkUWi0V33323+vfvb283DEP9+vXThAkT5O3tXej2EhMT1bNnT7322mv2tqCgoPIpHg4hNTVVktSmcdNCl7dp3CzfehXpXND7aNz/ydXVVZYLrr85F/SujR6jhIQE9ezZs8Lrw//8/rvtflL33CO98YZtOnQAAIASMi1MeXh4KDQ01P784MGDWr16tb777jv5+fnJz8/PviwuLk5nz57V6NGji9xeYmKi2rVrl2+bcG6BgYGSpMT9f6hraOsCyxP3J+dbryI5ctDDBaZOlf71L2nQIIIUAAC4ZA7z18OsWbPUt29fdejQIV+7YRh6+umnNWnSpCJHpSRbmAoJCSnvMuFAwsLC1KRxYz275ANZrdZ8y6xWq55b+qGaNmmisLCwCq/twqBXGDODXlV3xY4d0pkz5xsGDyZIAQCAUnGIvyAOHTqk2NhYTZ8+vcCy+Ph4HTt2TA888ECx29izZ4+mTZumWrVqqVevXtq7d285VQtH4ebmpnnz52vl9i0aOmOKtiQlKj0zU1uSEjV0xhSt3L5Fc+fNk5sJ18A4ctCrylzef19dZ86U25AhUhHXXwIAAJSUaaf5XehyR6XS0tJ03333qXfv3vL29lZsbKx69eqlffv25Ttd8JycnBzl5OTke70k5ebmKjc3t4z2yjGc2x9n269zbrzxRsXFxenxyZPVa+oj9vbGjRopLi5ON954o2n7Pm/+fN1xxx26ZfZTGh9xm9Q0UFt/SdKL8Uv09U+7tWjRIlmt1gJhC+XD5f335XbffXIxDOWFhMji6mq7pxQqnLP/u1QZ0AeOgX5wDPSDY3CkfriUGlwMw9w7Ux46dEjNmzfX5s2b1bFjx3zL4uPj9Z///Ed//PFHsWHqnwzDULt27TRhwgSNGjWqwPLp06frqaeeKtC+ePFiVa9e/dJ3AoBDa7Rundq/+qpcDEN/9OunH++/n1P7AABAoTIzMxUVFaXTp0/L19e32HVND1Njx45VSkqKPvvss3zthmGoQ4cOGjlypCZOnHjJ242MjFT79u01derUAssKG5kKCgrS8ePHL/qBVTa5ublau3at+vTpIw8PD7PLqZIsFou+++47paenq2bNmrr22mtNOfWwqnJ55x25PfCAXAxDuaNHa3W/furTty/Hg4n4d8l89IFjoB8cA/3gGBypH9LS0uTv71+iMGXqaX6pqamKjY0t9D5Ay5cv1+HDh/Xggw8Wu43s7Gy1bt1aixcvVpcuXSTZ0uTWrVt1++23F/oaLy8veXl5FWj38PAwvfPKizPvm6Pz8PBQWFiYVq9erbCwMPqhIr33nnRuFtCHHpLmzZO++ILjwUHQD+ajDxwD/eAY6AfH4Aj9cCnvb+p5LrNmzVKvXr3UqVOnfO3nrpV69NFHCz29b9euXQoMDNTq1atVrVo1de/eXaNGjdKaNWu0adMmDR48WLVr19aQIUMqalcAOKJ27aQ6daSxY6WXX5ZcXMyuCAAAOBFTw1Rubq6mTZtWoP3UqVNq0qRJkaNSVqtV2dnZysvLkyTFxMTouuuu04gRIzRw4ED5+vrqiy++kLu7Q8yvAcAs7dtLu3ZJL75IkAIAAGXO1LQRExNTaHvt2rX16aefFvm6Tp066eTJk/bnPj4+WrhwoRYuXFjmNQKoZN58U2rVSurRw/a8USNz6wEAAE6LoRsAziMmRhozRvLxkX74QWrWzOyKAACAE2NuYADO4dVXbUFKkh54QGra1Nx6AACA0yNMAaj8XnnFNlufJE2aJD3/PNdIAQCAckeYAlC5vfyybbY+Sfq//5NmzSJIAQCACkGYAlB5rVghjRtnezx5svTccwQpAABQYZiAAkDl1a+fNHCgbQr0GTMIUgAAoEIRpgBUPoZhC05eXtLy5ZKbG0EKAABUOE7zA1C5zJkjTZhgC1SS5O5OkAIAAKZgZApA5fH887ZJJiSpf3/p3/82tx4AAFClMTIFoHKYNet8kHrqKYIUAAAwHSNTDsZisSghIUGpqakKDAxUWFiY3NzczC4LMNdzz0mPP257PGOGNHWqufUAAACIkSmHEh8fr+bBwQoPD1dUVJTCw8PVPDhY8fHxZpcGmGfmzPNB6plnCFIAAMBhEKYcRHx8vCIjI9U2oIG2zI9R+idfaMv8GLUNaKDIyEgCFaqmPXukJ5+0PX72WWnKFHPrAQAAuABhygFYLBZFT5yoQdd00/InZqpraGv5eFdX19DWWv7ETA26ppseiY6WxWIxu1SgYrVuLS1aZLteavJks6sBAADIhzDlABISEpSyf78ev22EXF3zd4mrq6sm3zpcf6SkKCEhwaQKgQpkGFJa2vnnUVHnJ54AAABwIIQpB5CamipJatO4aaHL2zRulm89wGkZhjRtmtS5s3TokNnVAAAAFIsw5QACAwMlSYn7/yh0eeL+5HzrAU7JMKQnnrDN1vfLL9IXX5hdEQAAQLEIUw4gLCxMTRo31rNLPpDVas23zGq16rmlH6ppkyYKCwszqUKgnBmGbZa+mTNtz+fPl+65x9yaAAAALoIw5QDc3Nw0b/58rdy+RUNnTNGWpESlZ2ZqS1Kihs6YopXbt2juvHncbwrOyTBsU58/+6zt+YsvShMmmFoSAABASXDTXgcRERGhuLg4RU+cqGujx9jbmzZpori4OEVERJhYHVBODEN67DHp+edtz196SRo71tyaAAAASogw5UAiIiI0ZMgQJSQkKDU1VYGBgQoLC2NECs4rLU369FPb41dekR56yNx6AAAALgFhysG4ubmpZ8+eZpcBVAw/P2n9eunrr6WRI82uBgAA4JJwzRSAimUY0s6d5583aECQAgAAlRJhCkDFMQwpOtp2H6mPPjK7GgAAgMvCaX4AKoZh2Gbpe+kl2/O0NHPrAQAAuEyEKQDlzzCkceNsk0xI0htvSPfdZ25NAAAAl4kwBaB8GYb08MPSq6/anr/5pnTvvebWBAAAUAYIUwDKj2HYpjuPiZFcXKTYWOnuu82uCgAAoEwQpgCULzc3W5B66y1p1CizqwEAACgzhCkA5cfFxTbhRFSU1LWr2dUAAACUKaZGB1C2rFbptdeknBzbcxcXghQAAHBKhCkAZcdqlUaPlv7zH2nYMNs1UwAAAE6K0/wAlA2rVbr/ftu1Ua6uUmSkbVQKAADASRGmAFw+q9U23fk779iC1KJFtuukAAAAnBhhCsDlsVhsQerdd21B6sMPbaf4AQAAODmumQJwecaOtQUpNzdp8WKCFAAAqDIIUwAuz+23S7Vq2YLUbbeZXQ0AAECF4TQ/AJenRw/pjz9sgQoAAKAKYWQKwKXJy5PGjJF++OF8G0EKAABUQYQpACWXlyeNHCnFxEj9+kkZGWZXBAAAYBpO8wNQMnl50h13SB9/LLm7S6+9JtWoYXZVAAAApiFMAbi4vDxp+HBp6VLJw0NatkwaMsTsqgAAAExFmAJQvNxcW5BatswWpOLipMGDza7KVBaLRQkJCUpNTVVgYKDCwsLk5uZmdlkAAKCCcc0UgOLNmmULUp6eUnx8lQ9S8fHxah4crPDwcEVFRSk8PFzNg4MVHx9vdmkAAKCCEaYAFG/CBKlPH1uQGjTI7GpMFR8fr8jISLUNaKAt82OU/skX2jI/Rm0DGigyMpJABQBAFUOYAlCQxXL+sY+PtGaNNHCgefU4AIvFouiJEzXomm5a/sRMdQ1tLR/v6uoa2lrLn5ipQdd00yPR0bJc+NkBAACnRpgCkN/Zs9LNN0szZpxvc3Exrx4HkZCQoJT9+/X4bSPk6pr/n05XV1dNvnW4/khJUUJCgkkVAgCAikaYAnBeTo4UGSmtWCHNnCklJ5tdkcNITU2VJLVp3LTQ5W0aN8u3HgAAcH6EKQA254LU559L1apJn30mNWtmdlUOIzAwUJKUuP+PQpcn7k/Otx4AAHB+hCkAtiB1883SypXng1TfvmZX5VDCwsLUpHFjPbvkA1mt1nzLrFarnlv6oZo2aaKwsDCTKgQAABWNMAVUddnZUkSEtGqVLUh9/rlt9j7k4+bmpnnz52vl9i0aOmOKtiQlKj0zU1uSEjV0xhSt3L5Fc+fN435TAABUIdy0F6jq1q6VVq+WvL1tQapXL7MrclgRERGKi4tT9MSJujZ6jL29aZMmiouLU0REhInVAQCAikaYAqq6G2+UYmKkkBDphhvMrsbhRUREaMiQIUpISFBqaqoCAwMVFhbGiBQAAFUQYQqoirKybKf31a5te/7gg+bWU8m4ubmpZ8+eZpcBAABMxjVTQFWTlSUNGWI7ne/ECbOrAQAAqLQIU0BVkpkpDR5su07ql1+kX381uyIAAIBKi9P8gKoiM9N2fdQ330g+PtIXX0hduphdFQAAQKVFmAKqgowMW5Bav94WpL78Uure3eyqAAAAKjXCFODsMjKkQYOkDRukmjVtQeraa82uCgAAoNIjTAHO7tgx27VRNWtKa9ZI3bqZXREAAIBTIEwBzq5JE9vpfSdOcI0UAABAGSJMAc7ozBlp1y4pLMz2vEULc+sBAABwQkyNDjib9HSpf3+pd2/bjH0AAAAoF4QpwJmkpUn9+kmbN0ve3pK/v9kVAQAAOC1O8wOcxbkgtWWLVKuW7ca8V19tdlUAAABOizAFOIPTp21BautWqXZtad06qWNHs6sCAABwaoQpoLJLT5f+/W9p2zaCFAAAQAXimimgsqte3TZbX5060tdfE6QAAAAqCCNTQGXn5ia9+660f7/UrJnZ1QAAAFQZjEwBldHJk9LTT0sWi+25mxtBCgAAoIIxMgVUNidPSn36SP/9r/T339JLL5ldEQAAQJXEyBRQmZw4YbsZ73//a7uH1L33ml0RAABAlcXIFFBZ/P23LUjt3i3Vqyd9843Upo3ZVQEAAFRZjEwBlcGFQeqKK6T16wlSAAAAJiNMAY7OapUGDrQFqfr1bUGqdWuzqwIAAKjyCFOAo3N1lZ58Umrc2BakrrrK7IoAAAAgrpkCKocBA6Sff5a8vMyuBAAAAP/DyBTgiI4elfr1k3799XwbQQoAAMChEKYAR3PkiBQeLq1ZI40YIRmG2RUBAACgEIQpwJEcOSLdcIO0d6905ZXSokWSi4vZVQEAAKAQhCnAURw+bBuR2rtXatBA2rBBatnS7KoAAABQBMIU4AhSU21BKilJatjQFqRatDC7KgAAABSDMAU4ggkTpH37pKAgW5Bq3tzsigAAAHARTI0OOIKYGCkrS3rhBalZM7OrAQAAQAkQpgCzZGVJ3t62x3XqSCtWmFsPAAAALgmn+QFm+OsvqV0724gUAAAAKiXTwlRKSopcXFwK/dm1a5ckqVmzZvnaIyMjC91WXl6eHn30Ufn7+8vX11f33HOPzpw5U5G7A5TcgQNSz562G/LOnStlZJhdEQAAAErBtNP8GjRooKSkpHxtU6ZMkcViUYcOHZSRkaGUlBRt2bJFtWrVkiT5+voWuq3p06dryZIlWrRokXx8fDRx4kSNGjVKy5YtK+/dAC7NgQNSnz5ScrLUtKltsokaNcyuCgAAAKVgWpjy8PBQaGio/fnBgwe1evVqfffdd5KkPXv2yM/PT127di12O2fPntXLL7+sjz76SP3795ckLV26VM2bN9fevXt11VVXld9OAJfA+9gxuZ8LUs2aSevXS40amV0WAAAASslhrpmaNWuW+vbtqw4dOkiSEhMT1bIENyzdvXu3rFar+vXrZ29r2rSprr32Wq1du7bc6gUuyf796j51qlySk6XgYNuIFEEKAACgUnOI2fwOHTqk2NhY+6iUZAtTe/bsUe3atVW/fn1FR0frvvvuK/DaP//8U02aNJGbm1u+9ubNmys5ObnQ98vJyVFOTo79eVpamiQpNzdXubm5ZbFLDuPc/jjbflU2xooVqnHkiKzBwbKsXSsFBEj0SYXjeHAM9IP56APHQD84BvrBMThSP1xKDQ4Rpv45KiXZRpfeeustNWvWTDt37lR0dLR8fX1122235XttVlaWqlevXmCbtWvXtoekf3ruuef01FNPFWj/6quvCt2WM2CUzmTNm6vpvfcqtVs3Zf/4o/Tjj2ZXVKVxPDgG+sF89IFjoB8cA/3gGByhHzIzM0u8rulh6tyo1ObNm/O1P/zww/bHnTt3Vnp6umJiYgqEKW9vb2VnZxfY7qlTp+Tj41Poe06ePFkTJ060P09LS1NQUJD69u1b5CQXlVVubq7Wrl2rPn36yMPDw+xyqpb9+6W6dSUfH1s/SPSDyTgeHAP9YD76wDHQD46BfnAMjtQPRQ3IFMb0MDVr1iz17t1bHTt2LHa90NBQLVy4sEB7o0aNlJKSIqvVKlfX85eA/f7777rpppsK3ZaXl5e8vLwKtHt4eJjeeeXFmffNISUnSzfcYJuxb9Uq6X+/b/SDY6AfHAP9YD76wDHQD46BfnAMjtAPl/L+pk5AkZqaqtjYWE2bNi1f+7hx4/TII4/ka/v666/VqlWrAtto3769JGnDhg32toMHD2rz5s3q3bt3mdcMXNTvv0vXX2+bBv3IEYl7ngEAADglU0emZs2apV69eqlTp0752gcPHqz+/fsrKChIPXr00OrVq/Xqq69q48aNkqTVq1frnnvu0erVq9WhQweNHTtW999/v2JiYlSjRg1NmjRJQ4cOVZs2bczYLVRlv/0mhYdLf/0lhYbapj9nsgkAAACnZGqYys3NLTAqJUm9evXSO++8oxkzZmjSpEkKCQnR0qVL1a1bN0lSXl6esrKyZLVaJdlu2pudna3bb79dubm5ioyM1EsvvVSh+wLo119tQergQalVK1uQql/f7KoAAABQTkwNUzExMUUuGz58uIYPH17ossGDB+vUqVP25+7u7po7d67mzp1b1iUCJfPLL7YgdeiQdNVV0jffEKQAAACcnMPctBeo1LKypOxsqXVrRqQAAACqCNNn8wOcQrt20oYNthB1xRVmVwMAAIAKQJgCSispSTpxQure3fa8bVtz6wEAAECF4jQ/oDT27rVdI9Wvn7R9u9nVAAAAwASEKeBSnQtSR45IwcFSs2ZmVwQAAAATEKaAS7Fnj9Szp3T0qNS+vfT115K/v9lVAQAAwARcM+VgLBaLEhISlJqaqsDAQIWFhcnNzc3ssiBJiYnSDTdIx45JHTpIa9dKdeuaXRUAAABMwsiUA4mPj1fz4GCFh4crKipK4eHhah4crPj4eLNLw2+/2U7tO3ZM6thRWreOIAUAAFDFEaYcRHx8vCIjI9U2oIG2zI9R+idfaMv8GLUNaKDIyEgCldmCgqSuXaVOnWxBqk4dsysCAACAyQhTDsBisSh64kQNuqablj8xU11DW8vHu7q6hrbW8idmatA13fRIdLQsFovZpVZdXl5SXJwtSNWubXY1AAAAcACEKQeQkJCglP379fhtI+Tqmr9LXF1dNfnW4fojJUUJCQkmVVhF7d4tTZ0qGYbtuZeXVKuWmRUBAADAgTABhQNITU2VJLVp3LTQ5W0aN8u3HirArl1S7962m/LWqyeNG2d2RQAAAHAwjEw5gMDAQElS4v4/Cl2euD8533ooZzt3Sr162YJUly7SXXeZXREAAAAcEGHKAYSFhalJ48Z6dskHslqt+ZZZrVY9t/RDNW3SRGFhYSZVWIX897+2IHXypG3Cia++kvz8zK4KAAAADogw5QDc3Nw0b/58rdy+RUNnTNGWpESlZ2ZqS1Kihs6YopXbt2juvHncb6q87dhhO7Xv1CmpWzdpzRrJ19fsqgAAAOCguGbKQURERCguLk7REyfq2ugx9vamTZooLi5OERERJlZXBZw+LfXrZwtS3btLX3wh1axpdlUAAABwYIQpBxIREaEhQ4YoISFBqampCgwMVFhYGCNSFcHPT3r5ZemNN6TPPydIAQAA4KIIUw7Gzc1NPXv2NLuMqsMwJBcX2+OoKGnYMMmVs18BAABwcfzViKpr61bpmmukQ4fOtxGkAAAAUEL85YiqacsWqW9f26QTTzxhdjUAAACohAhTqHq+/dYWpNLTpfBw27VSAAAAwCUiTKFq2bzZNmvfmTPSDTdIK1dKNWqYXRUAAAAqIcIUqo6EhPNBqlcv26x91aubXRUAAAAqKcIUqgarVRo/XsrIsN2YlyAFAACAy0SYQtXg6moLUPffL332meTtbXZFAAAAqOQIU3Bux4+ff3zlldLrrxOkAAAAUCYIU3Be33wjNW0qLV5sdiUAAABwQoQpOKevv5YGDrRNNrFkiWQYZlcEAAAAJ0OYgvNZt04aNEjKzrYFqqVLJRcXs6sCAACAkyFMwbl89ZV04422IDVokPTJJ5KXl9lVAQAAwAkRpuA81qyRBg+2BanBg6W4OIIUAAAAyg1hCs5j3TopJ0caMkRatowgBQAAgHLlbnYBQJl5/nmpVStpxAjJ09PsagAAAODkGJlC5bZ1q200SrJNMnH33QQpAAAAVAjCFCqvlSul66+XIiOls2fNrgYAAABVDGEKldPnn0sREbYQVa0aU58DAACgwhGmUPmsWCHdfLOUmyvdcou0eLHk4WF2VQAAAKhiCFOoXJYvtwWo3Fzp1lsJUgAAADANYQqVx4VBatgw6cMPJXcmpAQAAIA5+EsUlYe/v+3eUbfcIr3/PkEKAAAApuKvUVQePXpI27ZJISEEKQAAAJiO0/zg2OLjpd27zz9v3ZogBQAAAIfAX6UoMYvFooSEBKWmpiowMFBhYWFyc3MrvzdculSKipL8/KQdO6SmTcvvvQAAAIBLxMgUSiQ+Pl7Ng4MVHh6uqKgohYeHq3lwsOLj48vnDZcssQUpi0W68UapUaPyeR8AAACglAhTuKj4+HhFRkaqbUADbZkfo/RPvtCW+TFqG9BAkZGRZR+oPvrofJAaNUp66y2pPEfAAAAAgFIgTKFYFotF0RMnatA13bT8iZnqGtpaPt7V1TW0tZY/MVODrummR6KjZbFYyuYNFy+WRoyQrFbp7rul2FiCFAAAABwSYQrFSkhIUMr+/Xr8thFydc3/6+Lq6qrJtw7XHykpSkhIuPw3+/JL6Y47bEHq3nulN9+UXPkVBQAAgGNiAgoUKzU1VZLUpnHhkz+0adws33qXpUcPqXt3KTRUWriQIAUAAACHRphCsQIDAyVJifv/UNfQ1gWWJ+5PzrfeZfHxsY1OVatGkAIAAIDD4y9WFCssLExNGjfWs0s+kNVqzbfMarXquaUfqmmTJgoLCyvdG7z3njRjxvnn1asTpAAAAFApMDKFYrm5uWne/PmKjIzU0BlTNPnW4WrTuJkS9yfruaUfauX2LYqLiyvd/abeeUe65x7JMKROnaQBA8p+BwAAAIByQpjCRUVERCguLk7REyfq2ugx9vamTZooLi5OERERl77Rt9+2TTJhGNKYMVL//mVYMQAAAFD+CFMokYiICA0ZMkQJCQlKTU1VYGCgwsLCSjciFRsr3Xef7fHDD0svvSS5uJRtwQAAAEA5I0yhxNzc3NSzZ8/L28gbb0ijR9sejx0rvfgiQQoAAACVElf6o+IkJUkPPGB7PG4cQQoAAACVGiNTqDitWkmvvCIlJ0tz5xKkAAAAUKkRplD+zp6VPD1tj8eMKX5dAAAAoJLgND+UrwULpG7dpBMnzK4EAAAAKFOEKZSfl1+2zda3c6f04YdmVwMAAACUKcIUysdLL9kmmZCkxx6THnrI3HoAAACAMkaYQtl74QVp/Hjb48mTpWefZbIJAAAAOB3CFMrW/PnSxIm2x1OmSDNnEqQAAADglAhTKDtpabZRKUl64glpxgyCFAAAAJwWU6Oj7Pj6SuvXSytW2EanCFIAAABwYoxM4fIlJ59/3Ly5FB1NkAIAAIDTI0zh8syaJbVqJa1ebXYlAAAAQIUiTKH0nn3WNlvf2bPSDz+YXQ0AAABQoQhTKJ1nnrHN1nfu8eTJ5tYDAAAAVDDCFC7d00/bZuuTbKNT50IVAAAAUIUwmx8uzfTp0lNP2R4/95z02GOmlgMAAACYhTCFkrNaz8/cN3u2NGmSufUAAAAAJiJMoeRcXaV33pFuu00aONDsagAAAABTcc0UimcYUlycZLHYnru5EaQAAAAAEaZQHMOwTTRxyy3SqFG25wAAAAAkcZofimIYtln6nnvO9rxjR8nFxdyaAAAAAAdCmEJBhmG7b9Ts2bbnL70kjR1rbk0AAACAgyFMIT/DsE13/vzztuevvCI99JC5NQEAAAAOiDCF/KZMOR+kFiyQxowxtx4AAADAQTEBBfLr0UPy8pJefZUgBQAAABSDkSnkN2CA9OuvUlCQ2ZUAAAAADo2RqarOMKSnnrIFqHMIUgAAAMBFEaaqMsOQxo+Xpk+XevWSMjLMrggAAACoNDjNr6oyDNt05wsW2O4fNW2aVKOG2VUBAAAAlQZhqioyDNt05zExtiAVGyvdfbfZVQEAAACVCmGqqrFabUHqtddsQeqtt6RRo8yuCgAAAKh0TLtmKiUlRS4uLoX+7Nq1S4mJiQoPD5e3t7dCQ0P19ttvF7u9TZs2FdjOypUrK2hvKpE5c84HqXfeIUgBAAAApWTayFSDBg2UlJSUr23KlCmyWCxq3ry5QkNDNWDAAM2ePVs//fSTxo8frxo1aui2224rdHuJiYnq2bOnXnvtNXtbELPSFXTffVJcnPTww9LIkWZXAwAAAFRapoUpDw8PhYaG2p8fPHhQq1ev1nfffaf3339f9erV0xtvvCEXFxddc801SktL04IFC4oNU+3atcu3TfyPYZx/XKeOtGWL5M4ZngAAAMDlcJip0WfNmqW+ffuqQ4cOysvL06hRo+Ti4mJf3rJlSx06dKjI1ycmJiokJKQiSq1crFa1i4mR6wUjdgQpAAAA4PI5xF/Vhw4dUmxsrL777jtJ0rhx4wqss3LlSl199dVFbmPPnj2aNm2aJk+erE6dOumVV17RVVddVei6OTk5ysnJsT9PS0uTJOXm5io3N/dydsWxWK1yue8+NVm7VsY33yi3Tx+peXOzq6qSzv1eOdXvVyVEPzgG+sF89IFjoB8cA/3gGBypHy6lBhfDuPAcMHOMHTtW+/fv14oVKwpdvmbNGg0ZMkTbtm1Tu3btCixPS0vTs88+q969e8vb21uxsbH68ssvtW/fPvn5+RVYf/r06XrqqacKtC9evFjVq1e//B1yBBaLOrz6qhp9840MV1f9d/x4HbzuOrOrAgAAABxaZmamoqKidPr0afn6+ha7rulh6tChQ2revLk2b96sjh07Fli+Z88ede/eXU8++aQmTpxYom0ahqF27dppwoQJGlXIbHWFjUwFBQXp+PHjF/3AKgWLRW733y/XRYtkuLlpx4QJav3UU/Lw8DC7siorNzdXa9euVZ8+fegHE9EPjoF+MB994BjoB8dAPzgGR+qHtLQ0+fv7lyhMmX6a36xZs9S7d+9Cg9Thw4c1YMAARURElDhISZKLi4tatmypgwcPFrrcy8tLXl5eBdo9PDxM77zLZrFI99wjLVokubnJ8v77OlSjhto7w745Aaf4HXMC9INjoB/MRx84BvrBMdAPjsER+uFS3t/UCShSU1MVGxuradOmFViWkZGhQYMGqUWLFnr99deL3EZ2draCg4O1bds2e1tmZqa2bt2qVq1alUvdDm3lSnuQ0kcfybjlFrMrAgAAAJySqWFq1qxZ6tWrlzp16pSv3WKxaNiwYTp48KBmzpyp33//Xfv27dO+fftktVq1a9cuBQYGavXq1apWrZq6d++uUaNGac2aNdq0aZMGDx6s2rVra8iQISbtmYmGDJFmzJA+/lgiSAEAAADlxtTT/HJzcwsdlRo3bpxWrlwpSeratWu+ZSdPnpTValV2drby8vIkSTExMXrkkUc0YsQIZWdnq0+fPnr33XflXlWmAM/Lk3JypBo1bM+nTjW3HgAAAKAKMDVtxMTEFNq+YMECLViwoMjXderUSSdPnrQ/9/Hx0cKFC7Vw4cIyr9Hh5eVJI0ZIqanSqlWSj4/ZFQEAAABVgsPctBelkJcnDR8uLVkibdki/fe/ZlcEAAAAVBmEqcoqN1eKipKWLpU8PKRPPpGuv97sqgAAAIAqo4pcVORkcnOl22+3BShPT9t/Bw0yuyoAAACgSiFMVTa5udKwYVJ8vC1IxcdLAweaXRUAAABQ5RCmKpv9+6WNG21B6tNPpQEDzK4IAAAAqJIIU5VN8+bS11/bZu/r18/sagAAAIAqiwkoKoOzZ6Uffzz/vF07ghQAAABgMsKUo8vJkSIjpWuvlTZvNrsaAAAAAP9DmHJkOTnSzTdLn38uWSxSVpbZFQEAAAD4H66ZclTZ2bYgtXq15O1tC1S9epldFQAAAID/IUw5ouxsKSJC+uILW5BauVK64QazqwIAAABwAcKUo8nOlm66SfryS1uQWrVKCg83uyoAAAAA/8A1U47GxUVyd5eqV7ed4keQAgAAABwSI1OOxstLiouT9u6VOnQwuxoAAAAARWBkyhF5eRGkAAAAAAdHmAIAAACAUiBMAQAAAEApEKYAAAAAoBQIUwAAAABQCoQpAAAAACgFwhQAAAAAlAJhCgAAAABKgTAFAAAAAKVAmAIAAACAUiBMAQAAAEApEKYAAAAAoBQIUwAAAABQCoQpAAAAACgFwhQAAAAAlAJhCgAAAABKgTAFAAAAAKVAmAIAAACAUiBMAQAAAEApEKYAAAAAoBQIUwAAAABQCoQpAAAAACgFwhQAAAAAlAJhCgAAAABKgTAFAAAAAKVAmAIAAACAUiBMAQAAAEApEKYAAAAAoBQIUwAAAABQCoQpAAAAACgFwhQAAAAAlAJhCgAAAABKgTAFAAAAAKXgbnYBjsAwDElSWlqayZWUvdzcXGVmZiotLU0eHh5ml1Nl0Q+OgX5wDPSD+egDx0A/OAb6wTE4Uj+cywTnMkJxCFOS0tPTJUlBQUEmVwIAAADAEaSnp8vPz6/YdVyMkkQuJ2e1WnXo0CHVrFlTLi4uZpdTptLS0hQUFKQDBw7I19fX7HKqLPrBMdAPjoF+MB994BjoB8dAPzgGR+oHwzCUnp6uK6+8Uq6uxV8VxciUJFdXVzVs2NDsMsqVr6+v6b+YoB8cBf3gGOgH89EHjoF+cAz0g2NwlH642IjUOUxAAQAAAAClQJgCAAAAgFIgTDk5Ly8vTZs2TV5eXmaXUqXRD46BfnAM9IP56APHQD84BvrBMVTWfmACCgAAAAAoBUamAAAAAKAUCFMAAAAAUAqEKQAAAAAoBcJUJZOSkiIXF5dCf3bt2qXExESFh4fL29tboaGhevvtt4vd3qZNmwpsZ+XKlRW0N5XXxfpBkpo1a5avPTIystBt5eXl6dFHH5W/v798fX11zz336MyZMxW5O5VWcf3wwgsvFNoeGBiorKysQrfH8VB6R44cUVRUlOrUqaOgoCA9/fTTslqtkqTVq1erdevWqlatmq655hpt3769yO1wPJRecX2QkJCgq6++WtWrV1f79u0v+nv9/vvvFzgWEhMTK2I3Kr3i+iEvL09eXl75PtdHHnmk0O2cOXNGd999t3x9feXv769HH31UeXl5FbkrlVpR/TB9+vRCvxs6dOigoqYR4HgovQMHDigiIkK1a9dWcHCwXnnlFfsyZ/lu4Ka9lUyDBg2UlJSUr23KlCmyWCxq3ry5QkNDNWDAAM2ePVs//fSTxo8frxo1aui2224rdHuJiYnq2bOnXnvtNXtbUFBQue6DMyiuHzp06KCMjAylpKRoy5YtqlWrliQVeQO66dOna8mSJVq0aJF8fHw0ceJEjRo1SsuWLSvv3aj0iuuHu+++W/3797e3G4ahfv36acKECfL29i50exwPpTdkyBA1atRIX3zxhdLT0xUdHS1PT08NHjxYERERevLJJzVgwAAtXrxY//73v5WYmKgGDRoU2A7HQ+kV1QdRUVHq37+/xo8fr9dee02bNm1SZGSk1q9fr27duhW6rcTERA0fPlxTp061tzVr1qyidqVSK6ofHnvsMf3yyy9yd3fXDz/8YF+/bt26hW7ngQce0E8//aTPP/9cOTk5evDBByVJc+bMqZD9qOyK6oeHHnpIw4YNs6+XmZmp66+/XtOmTZOLi0uh2+J4KJ2cnBz169dPbdu21Zdffqnk5GSNHTtWPj4+6tKli/N8Nxio1P766y+jWrVqxs6dO40FCxYY7dq1M6xWq335/PnzjR49ehT5+gcffNAYN25cBVTq3C7sB8MwjG3bthm1atW66OtycnKMmjVrGitXrrS3JScnG66ursaePXvKrV5n9c9+uNCyZcuMgIAAIzMzs8jXczyUzvHjxw1JxuHDh+1tH3/8sdGhQwfj/vvvNyIjI/Ot37NnT+PRRx8tsB2Oh9Irrg8eeeQRY/DgwfnWHzt2rDFixIgit9e/f3/jhRdeKK9ynVZx/WAYhrFkyRKjXbt2F93OwYMHDVdXVyMxMdHetmHDBsPT09M4efJkWZftdC7WDxeaM2eO0b59+3x/O/0Tx0PpfP3110ZAQIBx9uxZe9vrr79udO3a1am+GzjNr5KbNWuW+vbtqw4dOigvL0+jRo3K939WWrZsqUOHDhX5+sTERIWEhFREqU7twn6QbJ9ry5YtL/q63bt3y2q1ql+/fva2pk2b6tprr9XatWvLrV5n9c9+OMcwDD399NOaNGlSkaNSEsdDadWuXVuhoaF65plndPr0aR04cECvvfaa6tSpo4SEBN1888351h8xYkShv98cD6VXXB+4u7srKioq3/p8N5SP4vpBKvnnunnzZrVo0UKtW7e2t1133XWqX7++Nm7cWG71O4uL9cM5mZmZmjNnjp588skiR6UkjofSOnPmjLy9veXh4WFv8/Pz05EjR5zru8HsNIfSO3jwYJH/F/6cBx54wLj11luLXF6nTh2jXr16hp+fn3HDDTc4RMKvbArrhwkTJhg1atQwatWqZYSEhBhvvPFGoa9dtmyZ0bp16wLtd911lzF27Nhyq9kZFXc8xMXFXXRUyjA4Hi7HDz/8YHh6ehqSDElGvXr1jF27dhk1atQwvv/++3zrbtiwwfD19S2wDY6Hy1NUHxSmX79+xqRJkwpddvr0aUOSUb9+faNOnTrG0KFDjQMHDpRj5c6luH646aabDD8/P8PPz8/417/+ZSxfvrzQbcyZM8cYOHBggfaePXsa8+fPL8/ynUZJjoe5c+dedFSK46H0jh49avj6+hrTpk0zzpw5YyQmJhqhoaHGHXfc4VTfDYxMVWJF/V/4c9asWaN33nlHjz/+eKHL09LSdN9992nx4sVatWqVGjVqpF69eun06dPlWbbTKawfmjZtqrfeektfffWVJkyYoOjoaC1ZsqTAa7OyslS9evUC7bVr11ZGRka51u1sLndUiuOh9NLT03Xbbbepb9++Wr9+vT755BM1atRIR48eLfR3vKjfb46H0iuuD/7pzTff1NatWzVu3LhCt3Xs2DHNmDFDH3/8seLj45Wbm6sBAwYw+UEJXKwfOnbsqHfffVdfffWVhg8frltvvVVbt24tsB2OhctTkuMhKyurRKNSHA+lV69ePS1evFgLFiyQj4+P2rRpo19//VXR0dHO9d1gdppD6Rw8eNDw9vY2/vvf/xa6PDEx0fDz8zPmzZtX4m1arVajbdu2xttvv11WZTq9i/XDOXPmzDGuu+66Au3Lli0z2rZtW6B91KhRxsMPP1xmdTq74vrhk08+MerXr3/RUal/4ngouRdffNFo3bq1kZuba2/bs2eP4efnZ7i4uBTol40bNxo1a9YssB2Oh9Irrg9Onz5tb/vmm28MT09PIy4ursTbzszMNPz9/Y1vvvmmTGt2RiXth3PGjBljjBw5skD7nDlzjBtvvLFAe3h4+CV9r1dVJemHefPmFbjOvCQ4Hi5dXl6e8cMPPxj+/v7G+PHjDcMwjBo1ajjNdwMjU5XUrFmz1Lt3b3Xs2LHAssOHD2vAgAGKiIjQxIkTS7xNFxcXtWzZUgcPHizLUp1acf1wodDQ0EI/10aNGiklJcU+be45v//+OzMFXYKi+sEo4ahUYTgeSu7nn39WeHi43N3PTxB71VVXyd3dXYZhKDk5Od/6Rf1+czyUXnF9cG7muL179yoiIkJTpkwpcK1Ccby9vdW4cWOOhRIoST9cqLjvhn8eNxLHQkldrB+ysrL0/PPPX3RUqjAcD5fOzc1NsbGxqlmzpp555hlJhf+OV9bvBsJUJZSamqrY2FhNmzatwLKMjAwNGjRILVq00Ouvv17kNrKzsxUcHKxt27bZ2zIzM7V161a1atWqXOp2NkX1w7hx4wrcN+Trr78u9HNt3769JGnDhg32toMHD2rz5s3q3bt3mdfsjIo7HpYvX67Dhw/bpxQuCsfD5QkODtZPP/2Ur+3333/X33//rb59++qzzz7Lt2zJkiWF/n5zPJRecX3QsGFD+/9kGzJkiJ588skit7N//34FBQXl+0MxNTVVe/fu5VgogeL64cUXX9SLL76Yb1lR3w09evTQvn379Pvvv9vbtm7dqtTUVF1//fXlUrszudjxsHDhQtWvX1833XRTsdvheCgb27dvV0xMjN58803VqFFDkm1CFaf5bjB7aAyXbuzYscagQYMKtOfl5RmDBg0yAgICjK1btxpJSUn2H4vFYuzcudMICAgwVq1aZRiGYdxxxx1Gq1atjC+//NLYuHGj0atXL6NNmzb5hsVRtKL6Yd26dYaHh4fx4osvGjt27DCefvppw8PDw/juu+8MwzCMVatWGQEBAfaJEqZMmWIEBwcba9asMTZv3mxce+21RkRERIXuS2VWVD9YrVajffv2xty5cwt9HcdD2Tl+/Ljh7+9vPPjgg8bWrVuNzz//3LjqqquMIUOGGImJiUa1atWMuXPnGrt27TKmTp1q+Pr62i/g5ngoG8X1QUZGhnH11VcbrVq1Mn788Uf798Ivv/xiGEbBPrjuuuuM7t27Gxs3bjTWrFljdOjQwejXr5+Zu1dpFNcPb731llGzZk3jvffeM7Zv326MHTvW8Pb2NpKTkw3DsE0ZHRQUZBw8eNAwDMMYPny4cfXVVxubNm0y1q5da4SEhBgTJ040c/cqjeL6ITMz0wgICCjyVFeOh7KVm5trtGvXzrj77rvztTvTdwNhqhJ68MEHC8yAYhi2c6/1v1lr/vlz8uRJY8eOHUatWrWMFStWGIZhGOnp6cbo0aMNf39/w8fHx7jpppuYoeYSFNUPhmEYH3zwgRESEmJ4enoabdu2NT799FP7shUrVhh+fn7Gjh07DMOw/UMTHR1t1KlTx6hZs6YxatQoIy0trSJ2wSkU1Q8nTpwwhg4damRkZBT6Oo6HsrVz507juuuuM7y8vIygoCBj7Nix9t/jVatWGa1atTK8vLyMzp07G1u3brW/juOh7BTWB6dOnTIGDx5c6PeCn5+fYRgF++Dw4cPGrbfeavj5+Rm1atUy7rrrLu5tdAmKOxbmz59vNG7c2PDy8jK6du1qJCQk2F+3YMECo169evZ/d9LT04277rrLqFmzplG3bl0jOjo63/16ULyi+iE5OdkYNmxYkddKcTyUrZMnTxb5mTnLd4OLYRiGSYNiAAAAAFBpcc0UAAAAAJQCYQoAAAAASoEwBQAAAAClQJgCAAAAgFIgTAEAAABAKRCmAAAAAKAUCFMAAAAAUAqEKQAAAAAoBcIUAKDM7Nu3T7t37y7x+seOHdOpU6cuut6ZM2eUnp6uM2fO6MyZMzp58qQMw5DFYsm3ntVqVUnuRZ+Xlyer1VqiGlNTU7V///5Cl6WlpeV7brFYdOrUKZ09e7bA9q1Wq86ePasTJ06U6H1Lymq1Ki8vr0y3CQAoGRejJN86AAD8Q1JSkv7880+5u7vLzc1NkhQbG6t9+/Zp7ty5ks7/od+4cWMZhqG2bduqbt26OnXqlN544w0dO3ZMH3zwgbZv366cnBwdO3ZMLi4uMgxDV1xxhWrUqCFJGj16tD777DPVrVtXki20paWlacCAAfrzzz9VvXp1e3tycrIaNWpkDy/VqlWTJLVp00affvqpWrRooY0bN+qBBx5QUlKSJFu4ysvLs6+7fv16bdu2TQkJCdq5c6cGDx6sp59+Wj/99JMOHz6spKQkffvtt9q2bZt27typVq1aSZKSk5N19dVXq3r16vLy8lJ2drZOnTqlhg0bymKxKCcnRxkZGUpNTZWXl5f9szx79qz+/PNPeXt72z/LcwzDUE5OjmrWrGnff8kW3Nzc3JSVlSUfHx8dOXJE/v7+9vZGjRpp9uzZuv3228u24wEAdoQpAECpTJ06VZs2bdJ1111X7Hrr169Xnz59NGLECPXu3VvJyckKDAzUvn37NHToUCUlJSk3N1fdunXT1q1b1ahRI/3000/65ZdfFBwcLEl66KGHFBgYqNGjR0uSQkJCdOTIEQ0cOFAPP/ywevToIUkKDg7WDz/8oIYNG2rfvn32kOPq6iqr1ZovqFgsFnu7JN18882Ki4uTJA0cOFABAQF69NFHFRoaKkn69NNPNXr0aI0aNUohISFq1qyZ/P39Va9ePdWvX1+5ubny8PDIt+/Lly/XggULtG7dunztubm5cnd3l4uLiyTbCN0VV1xR7Of45ptv6t5777U/nzNnjhYsWKDAwEB9//336ty5s1JTUzVmzBiNHz9etWrV0rFjx+yBFABQ9tzNLgAAUDnVr19fw4YN02uvvSZXV1d5eHjoxIkTcnV1Va1atZSbm6u8vDxFRUXlG4X54Ycf9K9//UuHDh3SgQMHFBcXp9jYWPXp00cZGRlauHChoqKi7EHqnCeffFLTpk2TJPvpfS4uLho5cqQ8PT0lSSdPnrSvHxwcrL/++ks+Pj7y8vJSw4YN9e233yo4OFjffvutxo0bp23btslisSg7OzvfaXm1a9dW586d7UFKkry9vdWyZUvNnj270M9j5syZiomJUf369eXp6Sl3d3edOnVKhw8fVteuXWWxWJSXl6fs7Gz9/PPPOnr0qPz9/SXJHnjWr1+vnj17Fth2rVq18oWipKQkJSYm6vrrr1dERIRuv/12PfbYY4qPj9fevXsVGxur1q1b21+TkZEhNzc3+8gbAKBsEKYAAJfs559/1v79+1WtWjUdO3ZMI0eOVJ06dbRu3Tp5eXkpLCxMJ06c0Ntvv63MzEwdP37c/toNGzZo6NChio6O1pNPPqmZM2dq+/bteuONNzRv3jw9//zzeuihhwq857x58zR+/HhJsocQSYqPj7cHkAvbPTw81KBBA/vz119/XQ0bNlR2drZatWqlVatW2UPeudMEz3Fzc9Pzzz+vd999V4ZhqHv37urXr1+hn0VWVpa8vb0lSSNHjlRERIQOHTokd3fbV+yCBQu0YMEC7d69W4Zh6MYbb1TNmjXzbcPV9eKXMJ8bxZKkU6dO6cCBA5KkHTt2yGKxaMeOHfrrr79ktVq1c+dOHThwQA0bNtTBgwcVEBCg5cuXq0uXLhd9HwBAyTEBBQDgklWvXl0tW7ZUSEiIPD09FRQUpCZNmqhWrVqqXbu2mjRpoqCgIHl5eSk0NFShoaE6fPiwJNvI1OnTp3Xddddp9erVqlevnh5++GFVq1ZNd955p7766ivdeeedBd5z9uzZatOmjdq0aSMvLy+dPXtWvr6+Gj16tP09iprM4qOPPtKUKVOUl5enzZs3q3HjxvZT8uLj4+3B5ByLxaK77rpL7777roYOHao///xThmHou+++U7Vq1ew/np6e6tu3rySpY8eO6tKli06ePKnU1FSlpqbaR7uysrJ09OhRHTlyRFarVe+8806BQHUpunXrpv/85z8KCgrSmTNnJNkm6QgKCtLIkSOVmpqqZ555RsnJyapVq5ZSU1MJUgBQDhiZAgBcsqCgIN1///2SbGHkvffek6urq1xcXOTi4qIXXnhBeXl56tixo+644w5J0m+//SZJmjBhgvr376/ff/9djz/+uFauXClPT0+NGzdOGRkZqlu3ru688049+eSTCgkJsb/n//3f/+nee++Vp6en/bS+pUuXyjAMnT59WrVq1co3MnXOjz/+qNGjR2vOnDny8/NTjRo15OfnpyuuuEJ79+7VHXfcoYceeijf6Xu5ublq0KCBQkNDFRgYKMk2SUSPHj301VdfKSMjQ/7+/kpKSlKtWrUkSYMHD5Yk3Xnnnfb20aNHq3r16vrll1/08ccfy2q1qnv37rrrrrsK/VzDw8NL3AdHjhzRzp07VaNGDVksFm3dulUZGRny8vLSlVdeqR07duiWW25RQEBAibcJALg0jEwBAEpt/fr1+u2339SyZUu1bNlSLVq0UPPmzdWiRQuFhIRo//79+uabb/K9pl27dmrRooXGjBmjpKQkbdq0SXfeeaeGDRumO+64Q+vWrVNmZqZ+/fXXAu/34YcfqkWLFnJ3d1ebNm0UEBCgevXqqV27doXWt27dOvXs2VPp6en697//Len86XJ///23hg4dqnvvvbfAdVCZmZlyd3fPN4V6dna2qlevrmrVqtlPD/Tx8bGHlc8++0yjRo2Sj4+Punfvrn/961/asmWLWrZsqe+//17dunVTly5dFBsbq+HDhxc6ivbJJ5/YR7Uu/PH19S2wbkZGhjp27KhHHnlEnp6eeuSRR9SuXTu1bdtWK1eu1M8//6zExMR8130BAMoWI1MAgFJzcXHRn3/+mW/K7gv9+eefhd7PydfXV+Hh4Vq3bp26dOliDyfnpgG/5ZZbNGjQoAKvGzVqlEaPHi13d3clJiZq+vTpqlatmh577DHl5ubmW3fp0qWKiorS9OnT9cQTT+RblpWVpV69eql9+/Z64YUXCrzP6dOndffdd+uee+6RYRgaOnSoTp48qTp16hT5WYSEhOimm26Sl5eX3N3d5erqqjlz5qhFixYaMmSIrFarLBaLcnNz803ZfqE6deoUOpJ04fVS5/Tp00d169bVc889p7vuuktnzpxRr1691KlTJwUFBenw4cN6++23LzrbIgCg9AhTAIDL4u/vr8jIyEKXHTx4sEDb9ddfr5SUFL311ltq2LCh5s6dq5ycHDVp0kRnz57Vt99+q2uuuabQ7QUGBqp69eqyWq1q3ry5/Qa48+fP18MPP5xv3YiICK1fv15t27YtEKbS0tIUGhqqRYsWFTr5w/Hjx/Xtt9+qa9eukmz3y5o8ebJat25d5OcQEhKi9evXa86cOapRo4Y8PT3122+/KSUlRd99953Onj2rrKwsZWdnKzk52T5BRWkcPHhQ/fr1U/Xq1fX333/LarVq8+bNOnz4sHr06KFPP/1UI0aM0OzZs4ucfRAAcPk4zQ8AcFnc3Nzk4+NT6M+F93XKy8uTJM2dO1d79uzR0aNHFRkZqRUrVtjXSUlJ0bBhw/TBBx/ke49zt0T8+++/9fHHH+vqq6/Wb7/9prFjx2rSpEk6evRogcDk7u6usLCwQmv29/fXRx99ZJ+EYtOmTUpPT7fXmZKSombNmtnXd3V11ddff63OnTsX+1nk5eWpbdu2+vHHHxUSEqLly5drxYoVSk9P1w8//KBNmzbp6NGjBYLUuf07ceKEDh8+XODnn7eEbNCggQ4fPqzg4GANGzZM69atU+/evTVmzBh9+umnkmyB0c3NTX/88UexNQMASo+RKQBAqbm7u8vHx0cLFixQbm6ufYrw48ePq2bNmvL29rafwnf27FlJUufOnfX999+rT58+evnllzV06FDt3r1brq6uatasmTZu3KguXbroiiuu0I033mh/rcViUWZmpiZNmqQHH3xQki2E/PM0wgsDnCTl5OTke+7i4qLs7GwdPnxYgYGBOnXqlCZPnqyAgAB98skn2rhxo+rWrZvvJrqrV6/W8ePH1atXrxJ/Nufqslgs9jBktVoLHZE6FzRvvvnmIrdX2H68/PLLeuaZZ3TFFVfI1dVVb7/9ts6ePatZs2bpm2++0XPPPaf+/ftrxowZeuihhy5rNAwAUBD/qgIALpnValVSUpL+/vtv9erVSx999JG6d++u9957T9WqVdOECRO0cuVKNWnSRNu3b1dgYKBOnz5tf33nzp21b98+BQQE6OTJk+rfv799gojmzZtr165datSokX39tLQ0nTx5Ul9++aWCgoLss+FlZWXp7Nmzslqtio6O1pVXXql69erlqzUzMzPf8+DgYNWvX19XXnmlXFxcZBiGGjVqpFdeeUWStHDhQnuIk6Rff/1V9913n5555hl7UDt30+Bz/z3nwsDj6ekpq9UqFxcXBQQEKDExUTfddJNuuOGGAp/nmTNnVL9+fcXHx+vaa68tsDwsLCzfjY8l6YknntDChQvVpEkTLVu2TD4+Plq8eLFeeeUV5ebmau3atapfv768vLw0e/ZsRURE5PtMAQCXz8X457kDAACUwIMPPqjjx4+rZ8+euvHGGwv9Q/3HH3/UokWLFBwcrAceeKDIbZ0+fVp+fn6XVc/Ro0dVr169ApM17N69Wx06dNAff/yhJk2a2Nvz8vKUl5cnNzc3++l+km1U7e+//7ZPy75u3TqtWLHCHrYkKTU1VVdeeaUSExOLvY7qQucCaEnXv5hDhw7JYrEoKCgoX/vmzZvVqVMn+yihlP/GwgCAskOYAgAAAIBSYAIKAAAAACgFwhQAAAAAlAJhCgAAAABKgTAFAAAAAKVAmAIAAACAUiBMAQAAAEApEKYAAAAAoBQIUwAAAABQCv8Ph+9ky1W1lVsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 繪製實際值與預測值的比較圖\n",
    "plt.figure(figsize=(10, 10))\n",
    "    \n",
    "# 轉換為 numpy 數組以便繪圖\n",
    "y_test_np = y_test_tensor.cpu().numpy().flatten()\n",
    "test_pred_np = test_predictions.cpu().numpy().flatten()\n",
    "    \n",
    "# 繪製散點圖\n",
    "plt.scatter(y_test_np, test_pred_np, color='lightpink', edgecolor='black', label='預測 vs 實際')\n",
    "    \n",
    " # 繪製理想線 (y=x)\n",
    "min_val = min(y_test_np.min(), test_pred_np.min())\n",
    "max_val = max(y_test_np.max(), test_pred_np.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='理想線 (y=x)')\n",
    "    \n",
    "plt.xlabel('實際開花所需日數')\n",
    "plt.ylabel('預測開花所需日數')\n",
    "plt.title('預測 vs 實際')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('final_model_predictions_feature11.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d477a136-fcf7-4fa6-b4a0-050854caa361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Data_Analysis]",
   "language": "python",
   "name": "conda-env-Data_Analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
